---
title: "Lecture 13: Introduction to Regularized Adjusted Plus-Minus (RAPM)"
format: html
---

## Introduction

The purpose of this demo is to walk through the basics of building a __regularized adjusted plus-minus (RAPM) model__ to estimate the impact of basketball players when they are on the court, while adjusting for the quality of their teammates and opponents. We will use a dataset that is already in the wide design matrix form with indicator columns for every player that was observed during the regular season. You can find the script (`init_nba_rapm_data.R`) for initializing this dataset on Canvas using the [`hoopR` package](https://hoopr.sportsdataverse.org/).

The following code chunk reads in the wide data (assuming it is in the correct directory):

```{r}
#| warning: false
#| message: false
library(tidyverse)

# Load the data
nba_rapm_data <- read_csv(here::here("data/nba_2324_season_rapm_data.csv.gz"))
nba_rapm_data
```

In this dataset, we have 31885 unique shifts/stints with 572 players represented by the indicator variables (+1 if on court for home team, -1 if on court for away team, and 0 if not on court). Additional context is captured by the following variables:

| Variable | Description |
|----|-------------|
| `game_id` |	Unique game ID |
| `stint_id` |	Unique identifier within a game for a stint for particular combination of home and away lineup (in appearance of order, where 1 is the first stint in the game) |
| `n_pos` |	Number of possessions (combined for both home and away) during the observed stint |
| `home_points` |	Number of points scored by the home team during the stint |
| `away_points` |	Number of points scored by the away team during the stint |
| `minutes` |	Length of the stint in terms of minutes played |
| `margin` | Common response for RAPM models defined as: (`home_points` - `away_points`) / `n_pos` * 100 |

## Adjusted Plus-Minus (APM)

We'll first consider the classic [Rosenbaum (2004)](https://www.82games.com/comm30.htm) __adjusted plus-minus (APM)__ model, which is **weighted** least-squares where:

+ Response variable is the score differential with respect to home team, i.e., `home_points - away_points`

+ Weights are the number of posessions during the shift/stint, i.e., `n_pos`

The following code chunk fits this initial model (note this will take a bit to run::

```{r}
# First compute the score differential response:
nba_rapm_data <- nba_rapm_data |>
  mutate(score_diff = home_points - away_points)

# Now for ease, create a dataset that only has the response and player columns:
nba_apm_model_data <- nba_rapm_data |>
  dplyr::select(-c(game_id, stint_id, n_pos, home_points, away_points, minutes,
                   margin))

# Fit the model (notice we do not include an intercept term)
rosenbaum_model <- lm(score_diff ~ 0 + ., data = nba_apm_model_data,
                      weights = nba_rapm_data$n_pos)
```


We're not going to view the summary of this model since it is a bit of a mess. Instead, we'll take advantage of the [`broom` package](https://broom.tidymodels.org/index.html) to view the coefficients:

```{r}
library(broom)
rosenbaum_coef <- tidy(rosenbaum_model)
rosenbaum_coef
```

Obviously, in this current form we have no idea, we have no idea which player is which. Fortunately for you, there is a table on Canvas with the names of the players to join using these IDs in the `term` column: 

```{r}
nba_player_table <- read_csv(here::here("data/nba_2324_player_table.csv"))
nba_player_table
```

You'll notice that this matches the number of rows as the `rosenbaum_coef` table. But we first need to modify the `term` column by removing the back-tick symbols and then converting the IDs to numeric values before joining:

```{r}
rosenbaum_coef <- rosenbaum_coef |>
  # First convert the term column to numeric:
  mutate(term = as.numeric(str_remove_all(term, "`"))) |>
  # Now join the player names:
  left_join(nba_player_table, by = c("term" = "player_id"))
rosenbaum_coef
```

Who are the top players based on this approach?

```{r}
rosenbaum_coef |>
  slice_max(estimate, n = 10)
```

And the worst players?

```{r}
rosenbaum_coef |>
  slice_min(estimate, n = 10)
```

These look like pretty extreme values, with the most extreme values observed by players that have limited playing time (upon searching their stats online). Before we think about how to address these issues, let's look at what happens if we make a slight tweak to our model by using the `margin` variable as the response instead:

```{r}
# Now for ease, create a dataset that only has the response and player columns:
nba_margin_apm_model_data <- nba_rapm_data |>
  dplyr::select(-c(game_id, stint_id, n_pos, home_points, away_points, minutes,
                   score_diff))

# Fit the model (notice we do not include an intercept term)
rosenbaum_margin_model <- lm(margin ~ 0 + ., data = nba_margin_apm_model_data)

# Get the coefficients and join player names:
rosenbaum_margin_coef <- tidy(rosenbaum_margin_model) |>
  # First convert the term column to numeric:
  mutate(term = as.numeric(str_remove_all(term, "`"))) |>
  # Now join the player names:
  left_join(nba_player_table, by = c("term" = "player_id"))

# View top 10:
rosenbaum_margin_coef |>
  slice_max(estimate, n = 10)
```

Notice the difference in magnitude now for the coefficient estimates compared to the score differential model. This is because the response is on the scale of points per 100 possessions.

Before we dive into fixing the issues covered in lecture, let's take a look at the distribution of the coefficients for the players:

```{r}
rosenbaum_margin_coef |>
  ggplot(aes(x = estimate)) +
  geom_histogram() +
  labs(x = "APM estimate", y = "Count") +
  theme_bw()
```

__What do you notice about this distribution?__

## Regularized Adjusted Plus-Minus (RAPM)

In order to address the common issues facing APM models, we can fit a RAPM model using ridge regression. The go-to approach for fitting ridge (as well as lasso and elastic-net models) is with the [`glmnet` package](https://glmnet.stanford.edu/articles/glmnet.html). The following code chunk demonstrates how we can easily fit a ridge regression model with the RAPM design matrix. In order to tune the penalty $\lambda$, we will use the built-in cross-validation code with the `cv.glmnet()` function:

```{r}
# First we need to grab the X and convert to a matrix:
player_matrix <- nba_margin_apm_model_data |>
  dplyr::select(-margin) |>
  as.matrix()

# Next we load the package (assuming it's installed)
library(glmnet)

# Fit ridge (alpha = 0) w/ 10 fold CV, no intercept and no standardization
fit_ridge_cv <- cv.glmnet(player_matrix, nba_margin_apm_model_data$margin, 
                          alpha = 0, intercept = FALSE, standardize = FALSE)

# View the penalty selection:
plot(fit_ridge_cv)
```

We can easily plot the path of the ridge regression shrinkage, to see how the coefficients are pulled towards 0 as the penalty increases. The following code chunk shows this full path:

```{r}
plot(fit_ridge_cv$glmnet.fit, xvar = "lambda")
```

Using the `broom` package again, we can again make a tidy table of the coefficients for each player:

```{r}
tidy_ridge_coef <- tidy(fit_ridge_cv$glmnet.fit)
tidy_ridge_coef
```

If you look closely, this returns 100 rows for each player in the data - because it is returning the coefficient for each player at each value of the `lambda` penalty. We can filter to the values for the optimal choice of `lambda` based on the cross-validation results, and then join our player names as before:

```{r}
# Filter to the min lambda CV and join the player names:
rapm_ridge_coef <- tidy_ridge_coef |>
  filter(lambda == fit_ridge_cv$lambda.min) |>
  # Convert term to numeric:
  mutate(term = as.numeric(term)) |>
  # Now join the player names:
  left_join(nba_player_table, by = c("term" = "player_id"))

# View top 10:
rapm_ridge_coef |>
  slice_max(estimate, n = 10) |>
  dplyr::select(term, player_name, estimate)
```

Considering JokiÄ‡ won the MVP last season, this list definitely passes the eye test (it's honestly amazing how well this works for basketball data). For context, let's view the bottom 10:

```{r}
rapm_ridge_coef |>
  slice_min(estimate, n = 10) |>
  dplyr::select(term, player_name, estimate)
```

And finally, let's view the RAPM coefficient distribution (for comparison against the APM coefficients):

```{r}
rapm_ridge_coef |>
  ggplot(aes(x = estimate)) +
  geom_histogram() +
  labs(x = "RAPM estimate", y = "Count") +
  theme_bw()
```



