[
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#agenda",
    "href": "lectures/17-multilevel-heterogeneity.html#agenda",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Agenda",
    "text": "Agenda\nWhat have you seen so far?\n\nMultilevel models\nBayesian statistics\n\n\nToday\n\nMultilevel modeling with variance heterogeneity\nbrms package\nNote: Demo materials are within these slides (not in a separate file as usual)\n\n\n\nKey takeaways\n\nThe process of developing a model\nA real application of multilevel modeling and Bayesian inference\n\nHopefully you’ll find this useful (e.g., for future projects)"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#snap-timing-in-american-football",
    "href": "lectures/17-multilevel-heterogeneity.html#snap-timing-in-american-football",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Snap timing in American football",
    "text": "Snap timing in American football"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#snap-timing-in-american-football-1",
    "href": "lectures/17-multilevel-heterogeneity.html#snap-timing-in-american-football-1",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Snap timing in American football",
    "text": "Snap timing in American football"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#defining-snap-timing-small-delta_i-t_itextsnap-t_itextmotion",
    "href": "lectures/17-multilevel-heterogeneity.html#defining-snap-timing-small-delta_i-t_itextsnap-t_itextmotion",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Defining snap timing: \\(\\ \\ \\ \\small \\delta_i = t_i^{\\text{snap}}-t_i^{\\text{motion}}\\)",
    "text": "Defining snap timing: \\(\\ \\ \\ \\small \\delta_i = t_i^{\\text{snap}}-t_i^{\\text{motion}}\\)"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#example-play",
    "href": "lectures/17-multilevel-heterogeneity.html#example-play",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Example play",
    "text": "Example play"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#why-do-we-care-about-snap-timing",
    "href": "lectures/17-multilevel-heterogeneity.html#why-do-we-care-about-snap-timing",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Why do we care about snap timing?",
    "text": "Why do we care about snap timing?\n\nOur main quantity of interest is the variability in snap timing\n\nAcross different plays, the offense does not snap the ball at the same time after a receiver goes in motion\n\n\n\n\nQB skill: synchronizing the snap with motion\n\n\n\n\nIf the snap timing is consistent/predictable, defenders can anticipate the snap and time their actions to disrupt the play\n\n\n\n\nHigher variability in snap timing can be beneficial — prevents defenses from predicting when the snap will occur"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#data",
    "href": "lectures/17-multilevel-heterogeneity.html#data",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Data",
    "text": "Data\n\nPlay-level information (each row is a play, with various attributes, including the snap timing frame_between)\nSummarized from player tracking data provided by the NFL Big Data Bowl 2025 (first 9 weeks of the 2022 NFL season)\n\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_light(base_size = 15))\nplays_snap_timing &lt;- read_csv(\"https://github.com/qntkhvn/timing/raw/refs/heads/main/scripts/plays_snap_timing_demo.csv.gz\")\nglimpse(plays_snap_timing)\n\n\nRows: 2,253\nColumns: 13\n$ gameId                     &lt;dbl&gt; 2022090800, 2022090800, 2022090800, 2022090…\n$ playId                     &lt;dbl&gt; 212, 236, 438, 550, 569, 617, 818, 1030, 22…\n$ nflId                      &lt;dbl&gt; 47879, 52536, 53678, 42489, 42489, 44985, 4…\n$ passer_player_id           &lt;chr&gt; \"00-0034857\", \"00-0034857\", \"00-0026498\", \"…\n$ passer_player_name         &lt;chr&gt; \"J.Allen\", \"J.Allen\", \"M.Stafford\", \"J.Alle…\n$ defensiveTeam              &lt;chr&gt; \"LA\", \"LA\", \"BUF\", \"LA\", \"LA\", \"LA\", \"BUF\",…\n$ frame_between              &lt;dbl&gt; 9, 9, 7, 9, 25, 9, 16, 27, 2, 2, 3, 15, 15,…\n$ down                       &lt;dbl&gt; 2, 3, 1, 2, 3, 1, 3, 3, 2, 1, 1, 2, 2, 3, 2…\n$ play_clock_at_motion       &lt;dbl&gt; 10.9, 9.9, 15.7, 8.9, 9.5, 9.9, 16.6, 8.7, …\n$ posteam_timeouts_remaining &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ position                   &lt;chr&gt; \"TE\", \"WR\", \"WR\", \"WR\", \"WR\", \"WR\", \"B\", \"W…\n$ n_motion_since_line_set    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ motion_cluster             &lt;dbl&gt; 1, 3, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 4, 4, 2…"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#modeling-the-play-level-snap-timing-with-a-distribution",
    "href": "lectures/17-multilevel-heterogeneity.html#modeling-the-play-level-snap-timing-with-a-distribution",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Modeling the play-level snap timing with a ??? distribution",
    "text": "Modeling the play-level snap timing with a ??? distribution\n\n\nCode\nplays_snap_timing |&gt; \n  ggplot(aes(frame_between)) +\n  geom_histogram(bins = 40, fill = \"gray90\", color = \"gray30\") +\n  labs(x = \"Frames between motion and ball snap\",\n       y = \"Frequency\")"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#modeling-the-play-level-snap-timing-with-a-gamma-distribution-small-delta_i-sim-textsfgammamu_i-alpha_i",
    "href": "lectures/17-multilevel-heterogeneity.html#modeling-the-play-level-snap-timing-with-a-gamma-distribution-small-delta_i-sim-textsfgammamu_i-alpha_i",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Modeling the play-level snap timing with a Gamma distribution: \\(\\ \\ \\ \\small \\delta_i \\sim \\textsf{Gamma}(\\mu_i, \\alpha_i)\\)",
    "text": "Modeling the play-level snap timing with a Gamma distribution: \\(\\ \\ \\ \\small \\delta_i \\sim \\textsf{Gamma}(\\mu_i, \\alpha_i)\\)\n\nParameterized by mean \\(\\mu\\) and shape \\(\\alpha &gt; 0\\) \\[f_Y(y; \\mu, \\alpha) = \\frac{(\\alpha / \\mu)^\\alpha}{\\Gamma(\\alpha)} y^{\\alpha-1} \\exp\\left(-\\frac{\\alpha y}{\\mu}\\right), \\quad y \\ge 0\\] for which \\(\\mathbb E(Y)=\\mu\\) and \\(\\textsf{Var}(Y)=\\mu^2 / \\alpha\\)\nGamma regression is a distributional regression (modeling overall shape of distribution)\nFit separate models for both parameters \\(\\mu\\) and \\(\\alpha\\) and see how the overall distribution shifts based on different covariates"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#from-usual-to-alternative-parameterization",
    "href": "lectures/17-multilevel-heterogeneity.html#from-usual-to-alternative-parameterization",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "From usual to alternative parameterization",
    "text": "From usual to alternative parameterization\n\nRecall the usual parameterization of a Gamma distribution with 2 parametersshape \\(\\alpha &gt; 0\\) and scale \\(\\theta &gt; 0\\)\n\n\\[\n\\begin{aligned}\nY &\\sim \\textsf{Gamma}(\\alpha, \\theta)\\\\\nf_Y(y; \\alpha, \\theta) &= \\frac{1}{\\Gamma(\\alpha) \\theta^ \\alpha}y^{\\alpha-1}\\exp\\left(-\\frac{y}{\\theta}\\right)\n\\end{aligned}\n\\] with \\(\\mathbb E(Y) =\\mu = \\alpha \\theta\\) and \\(\\textsf{Var}(Y) = \\alpha \\theta^2\\)\n\nTherefore, to reparameterize, simply set \\(\\theta = \\mu / \\alpha\\)\n(Another example: Beta regression)"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#modeling-the-mean-parameter-with-covariates-player-and-team-random-effects",
    "href": "lectures/17-multilevel-heterogeneity.html#modeling-the-mean-parameter-with-covariates-player-and-team-random-effects",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Modeling the mean parameter with covariates + player and team random effects",
    "text": "Modeling the mean parameter with covariates + player and team random effects\n\\[\n\\begin{aligned}\n\\log\\mu_i&=\\gamma_0+\\boldsymbol{\\beta X_i}+b_{q[i]}+b_{m[i]}+b_{d[i]}\\\\\nb_q&\\sim\\textsf{Normal}(0,\\sigma^2_q)\\\\\nb_m&\\sim\\textsf{Normal}(0,\\sigma^2_m)\\\\\nb_d&\\sim\\textsf{Normal}(0,\\sigma^2_d)\\\\\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\\\\n\\boldsymbol X =\n\\small\n\\{ &\\text{down},\\\\\n& \\text{play clock at motion},\\\\\n& \\text{timeouts remaining (offense)},\\\\\n& \\text{motion players since lineset},\\\\\n& \\text{position},\\\\\n& \\textcolor{blue}{\\text{motion type}} \\}\\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#modeling-the-shape-parameter-with-random-intercept-for-qb",
    "href": "lectures/17-multilevel-heterogeneity.html#modeling-the-shape-parameter-with-random-intercept-for-qb",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Modeling the shape parameter with random intercept for QB",
    "text": "Modeling the shape parameter with random intercept for QB\n\\[\n\\begin{aligned}\n\\log\\alpha_i&=\\psi_0+u_{q[i]}\\\\\nu_q&\\sim\\textsf{Normal}(0,\\tau^2_q)\\\\\n\\end{aligned}\n\\]\n\nRecall that the shape parameter \\(\\alpha\\) is proportional to the variance of a Gamma distribution\nThis allows us to estimate the differences in snap timing variability among NFL quarterbacks"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#full-model",
    "href": "lectures/17-multilevel-heterogeneity.html#full-model",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Full model",
    "text": "Full model\n\nImplemented in a Bayesian framework\nUncertainty quantification for all model parameters with posterior distributions\n\n\n\n\\[\n\\begin{aligned}\n\\delta_i&\\sim\\textsf{Gamma}(\\mu_i,\\alpha_i)\\\\\n\\\\\n\\log\\mu_i&=\\gamma_0+\\boldsymbol{\\beta X_i}+b_{q[i]}+b_{m[i]}+b_{d[i]}\\\\\nb_q&\\sim\\textsf{Normal}(0,\\sigma^2_q)\\\\\nb_m&\\sim\\textsf{Normal}(0,\\sigma^2_m)\\\\\nb_d&\\sim\\textsf{Normal}(0,\\sigma^2_d)\\\\\n\\\\\n\\log\\alpha_i&=\\psi_0+u_{q[i]}\\\\\nu_q&\\sim\\textsf{Normal}(0,\\tau^2_q)\\\\\n\\end{aligned}\n\\]\n\n\\[\n\\begin{aligned}\n\\\\\n\\\\\n\\\\\n\\sigma_q &\\sim \\textsf{half-}t_3\\\\\n\\sigma_m &\\sim \\textsf{half-}t_3\\\\\n\\sigma_d &\\sim \\textsf{half-}t_3\\\\\n\\\\\n\\\\\n\\\\\n\\tau_q &\\sim \\textsf{half-}t_3\\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#what-is-brms",
    "href": "lectures/17-multilevel-heterogeneity.html#what-is-brms",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "What is brms?",
    "text": "What is brms?\n\n\n\nInterface to Stan\nlme4-like formula syntax\nThis means you don’t have to write actual Stan programs\nSupports a wide range of models\nWebsite: paulbuerkner.com/brms"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#brms-syntax",
    "href": "lectures/17-multilevel-heterogeneity.html#brms-syntax",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "brms syntax",
    "text": "brms syntax\n\nlme4 versionbrms version\n\n\n\n# data from previous demo\n# https://ryurko.github.io/cmu-sportsanalytics-spring25/demos/09-random-effects-uncertainty.html\nlibrary(lme4)\nnfl_passing_glmer &lt;- glmer(complete_pass ~ air_yards + (1 | passer_name_id) + \n                             (1 | receiver_name_id) + (1 | defteam),\n                           family = binomial, \n                           data = nfl_passing_data)\n\n\n\n\nlibrary(brms)\nnfl_passing_brm &lt;- brm(complete_pass ~ air_yards + (1 | passer_name_id) + \n                         (1 | receiver_name_id) + (1 | defteam),\n                       family = bernoulli, \n                       data = nfl_passing_data,\n                       iter = 5000,\n                       warmup = 2500,\n                       chains = 4,\n                       cores = 4,\n                       backend = \"cmdstanr\",\n                       seed = 3)\n\nRecommendation:\n\nUse the cmdstanr backend for Stan (instead of the default rstan)\nFirst install cmdstanr (see this link) and then run cmdstanr::install_cmdstan()"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#fitting-multilevel-model-for-snap-timing",
    "href": "lectures/17-multilevel-heterogeneity.html#fitting-multilevel-model-for-snap-timing",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Fitting multilevel model for snap timing",
    "text": "Fitting multilevel model for snap timing\n\nNeed to specify model formula both for mean and shape parameter(use brmsformula() or bf())\n\n\n\n\nCode\nlibrary(brms)\nsnap_timing_brm &lt;- brm(\n  brmsformula(\n    # mean level\n    frame_between ~ \n      factor(down) + play_clock_at_motion + factor(posteam_timeouts_remaining) + \n      position + n_motion_since_line_set + factor(motion_cluster) + \n      (1 | passer_player_id) + (1 | nflId) + (1 | defensiveTeam),\n    # shape level\n    shape ~ (1 | passer_player_id)\n  ),\n  family = Gamma(link = \"log\"),\n  data = plays_snap_timing,\n  iter = 5000,\n  warmup = 2500,\n  chains = 4,\n  seed = 3,\n  cores = 4,\n  backend = \"cmdstanr\"\n)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 4 Iteration:    1 / 5000 [  0%]  (Warmup) \nChain 1 Iteration:    1 / 5000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 5000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 5000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 5000 [  2%]  (Warmup) \nChain 2 Iteration:  200 / 5000 [  4%]  (Warmup) \nChain 1 Iteration:  100 / 5000 [  2%]  (Warmup) \nChain 2 Iteration:  300 / 5000 [  6%]  (Warmup) \nChain 4 Iteration:  100 / 5000 [  2%]  (Warmup) \nChain 1 Iteration:  200 / 5000 [  4%]  (Warmup) \nChain 2 Iteration:  400 / 5000 [  8%]  (Warmup) \nChain 3 Iteration:  100 / 5000 [  2%]  (Warmup) \nChain 1 Iteration:  300 / 5000 [  6%]  (Warmup) \nChain 2 Iteration:  500 / 5000 [ 10%]  (Warmup) \nChain 4 Iteration:  200 / 5000 [  4%]  (Warmup) \nChain 3 Iteration:  200 / 5000 [  4%]  (Warmup) \nChain 1 Iteration:  400 / 5000 [  8%]  (Warmup) \nChain 2 Iteration:  600 / 5000 [ 12%]  (Warmup) \nChain 4 Iteration:  300 / 5000 [  6%]  (Warmup) \nChain 3 Iteration:  300 / 5000 [  6%]  (Warmup) \nChain 1 Iteration:  500 / 5000 [ 10%]  (Warmup) \nChain 2 Iteration:  700 / 5000 [ 14%]  (Warmup) \nChain 4 Iteration:  400 / 5000 [  8%]  (Warmup) \nChain 3 Iteration:  400 / 5000 [  8%]  (Warmup) \nChain 1 Iteration:  600 / 5000 [ 12%]  (Warmup) \nChain 2 Iteration:  800 / 5000 [ 16%]  (Warmup) \nChain 4 Iteration:  500 / 5000 [ 10%]  (Warmup) \nChain 3 Iteration:  500 / 5000 [ 10%]  (Warmup) \nChain 1 Iteration:  700 / 5000 [ 14%]  (Warmup) \nChain 4 Iteration:  600 / 5000 [ 12%]  (Warmup) \nChain 2 Iteration:  900 / 5000 [ 18%]  (Warmup) \nChain 1 Iteration:  800 / 5000 [ 16%]  (Warmup) \nChain 3 Iteration:  600 / 5000 [ 12%]  (Warmup) \nChain 4 Iteration:  700 / 5000 [ 14%]  (Warmup) \nChain 2 Iteration: 1000 / 5000 [ 20%]  (Warmup) \nChain 4 Iteration:  800 / 5000 [ 16%]  (Warmup) \nChain 1 Iteration:  900 / 5000 [ 18%]  (Warmup) \nChain 3 Iteration:  700 / 5000 [ 14%]  (Warmup) \nChain 2 Iteration: 1100 / 5000 [ 22%]  (Warmup) \nChain 3 Iteration:  800 / 5000 [ 16%]  (Warmup) \nChain 4 Iteration:  900 / 5000 [ 18%]  (Warmup) \nChain 1 Iteration: 1000 / 5000 [ 20%]  (Warmup) \nChain 2 Iteration: 1200 / 5000 [ 24%]  (Warmup) \nChain 3 Iteration:  900 / 5000 [ 18%]  (Warmup) \nChain 4 Iteration: 1000 / 5000 [ 20%]  (Warmup) \nChain 1 Iteration: 1100 / 5000 [ 22%]  (Warmup) \nChain 2 Iteration: 1300 / 5000 [ 26%]  (Warmup) \nChain 4 Iteration: 1100 / 5000 [ 22%]  (Warmup) \nChain 3 Iteration: 1000 / 5000 [ 20%]  (Warmup) \nChain 1 Iteration: 1200 / 5000 [ 24%]  (Warmup) \nChain 2 Iteration: 1400 / 5000 [ 28%]  (Warmup) \nChain 4 Iteration: 1200 / 5000 [ 24%]  (Warmup) \nChain 1 Iteration: 1300 / 5000 [ 26%]  (Warmup) \nChain 3 Iteration: 1100 / 5000 [ 22%]  (Warmup) \nChain 2 Iteration: 1500 / 5000 [ 30%]  (Warmup) \nChain 4 Iteration: 1300 / 5000 [ 26%]  (Warmup) \nChain 1 Iteration: 1400 / 5000 [ 28%]  (Warmup) \nChain 3 Iteration: 1200 / 5000 [ 24%]  (Warmup) \nChain 2 Iteration: 1600 / 5000 [ 32%]  (Warmup) \nChain 4 Iteration: 1400 / 5000 [ 28%]  (Warmup) \nChain 1 Iteration: 1500 / 5000 [ 30%]  (Warmup) \nChain 3 Iteration: 1300 / 5000 [ 26%]  (Warmup) \nChain 2 Iteration: 1700 / 5000 [ 34%]  (Warmup) \nChain 4 Iteration: 1500 / 5000 [ 30%]  (Warmup) \nChain 1 Iteration: 1600 / 5000 [ 32%]  (Warmup) \nChain 3 Iteration: 1400 / 5000 [ 28%]  (Warmup) \nChain 4 Iteration: 1600 / 5000 [ 32%]  (Warmup) \nChain 2 Iteration: 1800 / 5000 [ 36%]  (Warmup) \nChain 1 Iteration: 1700 / 5000 [ 34%]  (Warmup) \nChain 3 Iteration: 1500 / 5000 [ 30%]  (Warmup) \nChain 4 Iteration: 1700 / 5000 [ 34%]  (Warmup) \nChain 2 Iteration: 1900 / 5000 [ 38%]  (Warmup) \nChain 1 Iteration: 1800 / 5000 [ 36%]  (Warmup) \nChain 4 Iteration: 1800 / 5000 [ 36%]  (Warmup) \nChain 3 Iteration: 1600 / 5000 [ 32%]  (Warmup) \nChain 2 Iteration: 2000 / 5000 [ 40%]  (Warmup) \nChain 4 Iteration: 1900 / 5000 [ 38%]  (Warmup) \nChain 1 Iteration: 1900 / 5000 [ 38%]  (Warmup) \nChain 3 Iteration: 1700 / 5000 [ 34%]  (Warmup) \nChain 2 Iteration: 2100 / 5000 [ 42%]  (Warmup) \nChain 4 Iteration: 2000 / 5000 [ 40%]  (Warmup) \nChain 1 Iteration: 2000 / 5000 [ 40%]  (Warmup) \nChain 3 Iteration: 1800 / 5000 [ 36%]  (Warmup) \nChain 2 Iteration: 2200 / 5000 [ 44%]  (Warmup) \nChain 4 Iteration: 2100 / 5000 [ 42%]  (Warmup) \nChain 1 Iteration: 2100 / 5000 [ 42%]  (Warmup) \nChain 3 Iteration: 1900 / 5000 [ 38%]  (Warmup) \nChain 2 Iteration: 2300 / 5000 [ 46%]  (Warmup) \nChain 4 Iteration: 2200 / 5000 [ 44%]  (Warmup) \nChain 1 Iteration: 2200 / 5000 [ 44%]  (Warmup) \nChain 3 Iteration: 2000 / 5000 [ 40%]  (Warmup) \nChain 2 Iteration: 2400 / 5000 [ 48%]  (Warmup) \nChain 4 Iteration: 2300 / 5000 [ 46%]  (Warmup) \nChain 1 Iteration: 2300 / 5000 [ 46%]  (Warmup) \nChain 3 Iteration: 2100 / 5000 [ 42%]  (Warmup) \nChain 4 Iteration: 2400 / 5000 [ 48%]  (Warmup) \nChain 2 Iteration: 2500 / 5000 [ 50%]  (Warmup) \nChain 2 Iteration: 2501 / 5000 [ 50%]  (Sampling) \nChain 1 Iteration: 2400 / 5000 [ 48%]  (Warmup) \nChain 3 Iteration: 2200 / 5000 [ 44%]  (Warmup) \nChain 4 Iteration: 2500 / 5000 [ 50%]  (Warmup) \nChain 4 Iteration: 2501 / 5000 [ 50%]  (Sampling) \nChain 1 Iteration: 2500 / 5000 [ 50%]  (Warmup) \nChain 1 Iteration: 2501 / 5000 [ 50%]  (Sampling) \nChain 3 Iteration: 2300 / 5000 [ 46%]  (Warmup) \nChain 2 Iteration: 2600 / 5000 [ 52%]  (Sampling) \nChain 3 Iteration: 2400 / 5000 [ 48%]  (Warmup) \nChain 4 Iteration: 2600 / 5000 [ 52%]  (Sampling) \nChain 1 Iteration: 2600 / 5000 [ 52%]  (Sampling) \nChain 2 Iteration: 2700 / 5000 [ 54%]  (Sampling) \nChain 3 Iteration: 2500 / 5000 [ 50%]  (Warmup) \nChain 3 Iteration: 2501 / 5000 [ 50%]  (Sampling) \nChain 4 Iteration: 2700 / 5000 [ 54%]  (Sampling) \nChain 1 Iteration: 2700 / 5000 [ 54%]  (Sampling) \nChain 2 Iteration: 2800 / 5000 [ 56%]  (Sampling) \nChain 3 Iteration: 2600 / 5000 [ 52%]  (Sampling) \nChain 4 Iteration: 2800 / 5000 [ 56%]  (Sampling) \nChain 1 Iteration: 2800 / 5000 [ 56%]  (Sampling) \nChain 2 Iteration: 2900 / 5000 [ 58%]  (Sampling) \nChain 3 Iteration: 2700 / 5000 [ 54%]  (Sampling) \nChain 4 Iteration: 2900 / 5000 [ 58%]  (Sampling) \nChain 1 Iteration: 2900 / 5000 [ 58%]  (Sampling) \nChain 2 Iteration: 3000 / 5000 [ 60%]  (Sampling) \nChain 3 Iteration: 2800 / 5000 [ 56%]  (Sampling) \nChain 4 Iteration: 3000 / 5000 [ 60%]  (Sampling) \nChain 1 Iteration: 3000 / 5000 [ 60%]  (Sampling) \nChain 2 Iteration: 3100 / 5000 [ 62%]  (Sampling) \nChain 3 Iteration: 2900 / 5000 [ 58%]  (Sampling) \nChain 4 Iteration: 3100 / 5000 [ 62%]  (Sampling) \nChain 1 Iteration: 3100 / 5000 [ 62%]  (Sampling) \nChain 2 Iteration: 3200 / 5000 [ 64%]  (Sampling) \nChain 4 Iteration: 3200 / 5000 [ 64%]  (Sampling) \nChain 3 Iteration: 3000 / 5000 [ 60%]  (Sampling) \nChain 1 Iteration: 3200 / 5000 [ 64%]  (Sampling) \nChain 2 Iteration: 3300 / 5000 [ 66%]  (Sampling) \nChain 4 Iteration: 3300 / 5000 [ 66%]  (Sampling) \nChain 3 Iteration: 3100 / 5000 [ 62%]  (Sampling) \nChain 1 Iteration: 3300 / 5000 [ 66%]  (Sampling) \nChain 2 Iteration: 3400 / 5000 [ 68%]  (Sampling) \nChain 4 Iteration: 3400 / 5000 [ 68%]  (Sampling) \nChain 3 Iteration: 3200 / 5000 [ 64%]  (Sampling) \nChain 1 Iteration: 3400 / 5000 [ 68%]  (Sampling) \nChain 2 Iteration: 3500 / 5000 [ 70%]  (Sampling) \nChain 4 Iteration: 3500 / 5000 [ 70%]  (Sampling) \nChain 3 Iteration: 3300 / 5000 [ 66%]  (Sampling) \nChain 1 Iteration: 3500 / 5000 [ 70%]  (Sampling) \nChain 2 Iteration: 3600 / 5000 [ 72%]  (Sampling) \nChain 4 Iteration: 3600 / 5000 [ 72%]  (Sampling) \nChain 3 Iteration: 3400 / 5000 [ 68%]  (Sampling) \nChain 1 Iteration: 3600 / 5000 [ 72%]  (Sampling) \nChain 2 Iteration: 3700 / 5000 [ 74%]  (Sampling) \nChain 4 Iteration: 3700 / 5000 [ 74%]  (Sampling) \nChain 3 Iteration: 3500 / 5000 [ 70%]  (Sampling) \nChain 1 Iteration: 3700 / 5000 [ 74%]  (Sampling) \nChain 4 Iteration: 3800 / 5000 [ 76%]  (Sampling) \nChain 2 Iteration: 3800 / 5000 [ 76%]  (Sampling) \nChain 3 Iteration: 3600 / 5000 [ 72%]  (Sampling) \nChain 1 Iteration: 3800 / 5000 [ 76%]  (Sampling) \nChain 4 Iteration: 3900 / 5000 [ 78%]  (Sampling) \nChain 2 Iteration: 3900 / 5000 [ 78%]  (Sampling) \nChain 3 Iteration: 3700 / 5000 [ 74%]  (Sampling) \nChain 4 Iteration: 4000 / 5000 [ 80%]  (Sampling) \nChain 1 Iteration: 3900 / 5000 [ 78%]  (Sampling) \nChain 2 Iteration: 4000 / 5000 [ 80%]  (Sampling) \nChain 3 Iteration: 3800 / 5000 [ 76%]  (Sampling) \nChain 4 Iteration: 4100 / 5000 [ 82%]  (Sampling) \nChain 1 Iteration: 4000 / 5000 [ 80%]  (Sampling) \nChain 2 Iteration: 4100 / 5000 [ 82%]  (Sampling) \nChain 3 Iteration: 3900 / 5000 [ 78%]  (Sampling) \nChain 4 Iteration: 4200 / 5000 [ 84%]  (Sampling) \nChain 1 Iteration: 4100 / 5000 [ 82%]  (Sampling) \nChain 2 Iteration: 4200 / 5000 [ 84%]  (Sampling) \nChain 3 Iteration: 4000 / 5000 [ 80%]  (Sampling) \nChain 4 Iteration: 4300 / 5000 [ 86%]  (Sampling) \nChain 1 Iteration: 4200 / 5000 [ 84%]  (Sampling) \nChain 2 Iteration: 4300 / 5000 [ 86%]  (Sampling) \nChain 3 Iteration: 4100 / 5000 [ 82%]  (Sampling) \nChain 4 Iteration: 4400 / 5000 [ 88%]  (Sampling) \nChain 1 Iteration: 4300 / 5000 [ 86%]  (Sampling) \nChain 2 Iteration: 4400 / 5000 [ 88%]  (Sampling) \nChain 3 Iteration: 4200 / 5000 [ 84%]  (Sampling) \nChain 4 Iteration: 4500 / 5000 [ 90%]  (Sampling) \nChain 1 Iteration: 4400 / 5000 [ 88%]  (Sampling) \nChain 2 Iteration: 4500 / 5000 [ 90%]  (Sampling) \nChain 3 Iteration: 4300 / 5000 [ 86%]  (Sampling) \nChain 4 Iteration: 4600 / 5000 [ 92%]  (Sampling) \nChain 1 Iteration: 4500 / 5000 [ 90%]  (Sampling) \nChain 2 Iteration: 4600 / 5000 [ 92%]  (Sampling) \nChain 3 Iteration: 4400 / 5000 [ 88%]  (Sampling) \nChain 4 Iteration: 4700 / 5000 [ 94%]  (Sampling) \nChain 1 Iteration: 4600 / 5000 [ 92%]  (Sampling) \nChain 2 Iteration: 4700 / 5000 [ 94%]  (Sampling) \nChain 3 Iteration: 4500 / 5000 [ 90%]  (Sampling) \nChain 4 Iteration: 4800 / 5000 [ 96%]  (Sampling) \nChain 1 Iteration: 4700 / 5000 [ 94%]  (Sampling) \nChain 2 Iteration: 4800 / 5000 [ 96%]  (Sampling) \nChain 3 Iteration: 4600 / 5000 [ 92%]  (Sampling) \nChain 4 Iteration: 4900 / 5000 [ 98%]  (Sampling) \nChain 1 Iteration: 4800 / 5000 [ 96%]  (Sampling) \nChain 2 Iteration: 4900 / 5000 [ 98%]  (Sampling) \nChain 3 Iteration: 4700 / 5000 [ 94%]  (Sampling) \nChain 4 Iteration: 5000 / 5000 [100%]  (Sampling) \nChain 4 finished in 95.6 seconds.\nChain 1 Iteration: 4900 / 5000 [ 98%]  (Sampling) \nChain 2 Iteration: 5000 / 5000 [100%]  (Sampling) \nChain 2 finished in 96.5 seconds.\nChain 3 Iteration: 4800 / 5000 [ 96%]  (Sampling) \nChain 1 Iteration: 5000 / 5000 [100%]  (Sampling) \nChain 1 finished in 97.8 seconds.\nChain 3 Iteration: 4900 / 5000 [ 98%]  (Sampling) \nChain 3 Iteration: 5000 / 5000 [100%]  (Sampling) \nChain 3 finished in 99.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 97.3 seconds.\nTotal execution time: 99.7 seconds."
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#model-diagnostics",
    "href": "lectures/17-multilevel-heterogeneity.html#model-diagnostics",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\n\n\n\nCode\n# view trace plots\n# mcmc_plot(snap_timing_brm, type = \"trace\")\n# summary(rhat(snap_timing_brm))\nhist(rhat(snap_timing_brm))\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# summary(neff_ratio(snap_timing_brm))\nhist(neff_ratio(snap_timing_brm))"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#model-summary",
    "href": "lectures/17-multilevel-heterogeneity.html#model-summary",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Model summary",
    "text": "Model summary\n\nprint(snap_timing_brm, digits = 3, priors = TRUE)\n\n Family: gamma \n  Links: mu = log; shape = log \nFormula: frame_between ~ factor(down) + play_clock_at_motion + factor(posteam_timeouts_remaining) + position + n_motion_since_line_set + factor(motion_cluster) + (1 | passer_player_id) + (1 | nflId) + (1 | defensiveTeam) \n         shape ~ (1 | passer_player_id)\n   Data: plays_snap_timing (Number of observations: 2253) \n  Draws: 4 chains, each with iter = 5000; warmup = 2500; thin = 1;\n         total post-warmup draws = 10000\n\nPriors:\nIntercept ~ student_t(3, 2.8, 2.5)\nIntercept_shape ~ student_t(3, 0, 2.5)\n&lt;lower=0&gt; sd ~ student_t(3, 0, 2.5)\n&lt;lower=0&gt; sd_shape ~ student_t(3, 0, 2.5)\n\nMultilevel Hyperparameters:\n~defensiveTeam (Number of levels: 32) \n              Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\nsd(Intercept)    0.029     0.020    0.001    0.073 1.000     5050     5785\n\n~nflId (Number of levels: 356) \n              Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\nsd(Intercept)    0.153     0.030    0.092    0.211 1.000     2535     3882\n\n~passer_player_id (Number of levels: 54) \n                    Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS\nsd(Intercept)          0.093     0.032    0.027    0.156 1.000     2333\nsd(shape_Intercept)    0.296     0.052    0.204    0.410 1.000     3821\n                    Tail_ESS\nsd(Intercept)           2510\nsd(shape_Intercept)     5712\n\nRegression Coefficients:\n                                  Estimate Est.Error l-95% CI u-95% CI  Rhat\nIntercept                            2.411     0.131    2.158    2.671 1.000\nshape_Intercept                      0.727     0.056    0.616    0.835 1.000\nfactordown2                          0.068     0.035    0.000    0.136 1.001\nfactordown3                          0.192     0.041    0.112    0.272 1.000\nfactordown4                          0.151     0.113   -0.064    0.378 1.000\nplay_clock_at_motion                 0.029     0.003    0.022    0.035 1.001\nfactorposteam_timeouts_remaining1   -0.280     0.129   -0.538   -0.031 1.000\nfactorposteam_timeouts_remaining2   -0.144     0.113   -0.371    0.072 1.000\nfactorposteam_timeouts_remaining3   -0.152     0.109   -0.371    0.058 1.000\npositionTE                           0.530     0.065    0.403    0.659 1.000\npositionWR                           0.319     0.054    0.213    0.425 1.000\nn_motion_since_line_set             -0.021     0.032   -0.083    0.040 1.000\nfactormotion_cluster2                0.040     0.053   -0.065    0.146 1.000\nfactormotion_cluster3                0.560     0.049    0.463    0.656 1.001\nfactormotion_cluster4               -0.029     0.045   -0.116    0.060 1.001\nfactormotion_cluster5               -0.191     0.072   -0.331   -0.048 1.000\nfactormotion_cluster6                0.153     0.063    0.029    0.279 1.000\n                                  Bulk_ESS Tail_ESS\nIntercept                            12300     8765\nshape_Intercept                       7640     7421\nfactordown2                          16010     8283\nfactordown3                          15113     8269\nfactordown4                          18775     7837\nplay_clock_at_motion                 14950     7961\nfactorposteam_timeouts_remaining1    10797     8194\nfactorposteam_timeouts_remaining2    10647     7817\nfactorposteam_timeouts_remaining3    10366     7840\npositionTE                           12489     8771\npositionWR                           12038     7275\nn_motion_since_line_set              17685     8454\nfactormotion_cluster2                13937     8285\nfactormotion_cluster3                16886     8281\nfactormotion_cluster4                16113     8852\nfactormotion_cluster5                16603     8112\nfactormotion_cluster6                17650     8670\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\nTo manually set priors, use the function set_prior()"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#posterior-samples-for-all-model-parameters",
    "href": "lectures/17-multilevel-heterogeneity.html#posterior-samples-for-all-model-parameters",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Posterior samples for all model parameters",
    "text": "Posterior samples for all model parameters\n\nposterior_samples &lt;- as_tibble(snap_timing_brm)\n# names(posterior_samples) # view all parameter names\nposterior_samples\n\n# A tibble: 10,000 × 521\n   b_Intercept b_shape_Intercept b_factordown2 b_factordown3 b_factordown4\n         &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1        2.39             0.735       0.0758          0.164        0.120 \n 2        2.45             0.743       0.0132          0.240        0.138 \n 3        2.51             0.798       0.102           0.188        0.103 \n 4        2.53             0.769       0.0669          0.238        0.0748\n 5        2.58             0.668       0.0704          0.152        0.262 \n 6        2.40             0.694       0.0941          0.279        0.0859\n 7        2.45             0.773       0.00772         0.161        0.121 \n 8        2.64             0.724       0.0477          0.159        0.188 \n 9        2.64             0.763       0.0155          0.227       -0.0208\n10        2.26             0.764       0.0883          0.160        0.0594\n# ℹ 9,990 more rows\n# ℹ 516 more variables: b_play_clock_at_motion &lt;dbl&gt;,\n#   b_factorposteam_timeouts_remaining1 &lt;dbl&gt;,\n#   b_factorposteam_timeouts_remaining2 &lt;dbl&gt;,\n#   b_factorposteam_timeouts_remaining3 &lt;dbl&gt;, b_positionTE &lt;dbl&gt;,\n#   b_positionWR &lt;dbl&gt;, b_n_motion_since_line_set &lt;dbl&gt;,\n#   b_factormotion_cluster2 &lt;dbl&gt;, b_factormotion_cluster3 &lt;dbl&gt;, …"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#posterior-distributions-of-sd-parameters",
    "href": "lectures/17-multilevel-heterogeneity.html#posterior-distributions-of-sd-parameters",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Posterior distributions of sd parameters",
    "text": "Posterior distributions of sd parameters\n\nposterior_samples |&gt; \n  select(contains(\"sd_\")) # only get sd parameters\n\n# A tibble: 10,000 × 4\n   sd_defensiveTeam__Intercept sd_nflId__Intercept sd_passer_player_id__Interc…¹\n                         &lt;dbl&gt;               &lt;dbl&gt;                         &lt;dbl&gt;\n 1                     0.0356                0.163                        0.0790\n 2                     0.0653                0.125                        0.127 \n 3                     0.0574                0.146                        0.0845\n 4                     0.00733               0.156                        0.118 \n 5                     0.0489                0.139                        0.128 \n 6                     0.00648               0.127                        0.110 \n 7                     0.0384                0.180                        0.149 \n 8                     0.0152                0.182                        0.162 \n 9                     0.0151                0.204                        0.143 \n10                     0.0212                0.168                        0.0944\n# ℹ 9,990 more rows\n# ℹ abbreviated name: ¹​sd_passer_player_id__Intercept\n# ℹ 1 more variable: sd_passer_player_id__shape_Intercept &lt;dbl&gt;"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#posterior-distributions-of-sd-parameters-1",
    "href": "lectures/17-multilevel-heterogeneity.html#posterior-distributions-of-sd-parameters-1",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Posterior distributions of sd parameters",
    "text": "Posterior distributions of sd parameters\n\n\nCode\nsd_posteriors &lt;- posterior_samples |&gt; \n  select(contains(\"sd_\")) |&gt; \n  pivot_longer(everything(), \n               names_to = \"term\", \n               values_to = \"estimate\") |&gt; \n  # remove annoying text in these parameter names\n  mutate(term = str_remove(term, \"__Intercept|_Intercept\"))\n\nsd_posteriors |&gt;   \n  ggplot(aes(estimate, color = term)) +\n  geom_density(linewidth = 1.4) +\n  labs(x = \"Estimate\",\n       color = NULL) +\n  scale_color_manual(values = c(\"darkblue\", \"maroon\", \"darkorange\", \"black\")) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2))"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#largest-source-of-variation-is-between-qbs-when-modeling-the-snap-timing-shape",
    "href": "lectures/17-multilevel-heterogeneity.html#largest-source-of-variation-is-between-qbs-when-modeling-the-snap-timing-shape",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Largest source of variation is between QBs when modeling the snap timing shape",
    "text": "Largest source of variation is between QBs when modeling the snap timing shape\n\n\nCode\nsd_posteriors |&gt; \n  group_by(term) |&gt; \n  summarize(posterior_mean = mean(estimate),\n            posterior_sd = sd(estimate),\n            lower_95_ci = quantile(estimate, 0.025),\n            upper_95_ci = quantile(estimate, 0.975))\n\n\n# A tibble: 4 × 5\n  term                       posterior_mean posterior_sd lower_95_ci upper_95_ci\n  &lt;chr&gt;                               &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 sd_defensiveTeam                   0.0287       0.0197     0.00132      0.0730\n2 sd_nflId                           0.153        0.0304     0.0916       0.211 \n3 sd_passer_player_id                0.0931       0.0315     0.0273       0.156 \n4 sd_passer_player_id__shape         0.296        0.0523     0.204        0.410"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#posterior-distributions-of-u_q",
    "href": "lectures/17-multilevel-heterogeneity.html#posterior-distributions-of-u_q",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Posterior distributions of \\(u_q\\)",
    "text": "Posterior distributions of \\(u_q\\)\n\nposterior_samples |&gt; \n  select(contains(\"r_passer_player_id__shape\"))\n\n# A tibble: 10,000 × 54\n   r_passer_player_id__shape[00-…¹ r_passer_player_id__…² r_passer_player_id__…³\n                             &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n 1                           0.410               -0.229                  -0.330 \n 2                           0.268                0.0559                 -0.0502\n 3                           0.148               -0.175                  -0.298 \n 4                           0.149               -0.00825                -0.117 \n 5                           0.653               -0.313                  -0.370 \n 6                           0.255                0.0220                 -0.0831\n 7                           0.234               -0.198                  -0.360 \n 8                           0.349                0.0435                 -0.559 \n 9                           0.289                0.0626                 -0.114 \n10                           0.299               -0.239                  -0.249 \n# ℹ 9,990 more rows\n# ℹ abbreviated names: ¹​`r_passer_player_id__shape[00-0019596,Intercept]`,\n#   ²​`r_passer_player_id__shape[00-0023459,Intercept]`,\n#   ³​`r_passer_player_id__shape[00-0026143,Intercept]`\n# ℹ 51 more variables: `r_passer_player_id__shape[00-0026158,Intercept]` &lt;dbl&gt;,\n#   `r_passer_player_id__shape[00-0026498,Intercept]` &lt;dbl&gt;,\n#   `r_passer_player_id__shape[00-0026625,Intercept]` &lt;dbl&gt;, …"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#higher-posterior-mean-corresponds-to-greater-snap-timing-variability",
    "href": "lectures/17-multilevel-heterogeneity.html#higher-posterior-mean-corresponds-to-greater-snap-timing-variability",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Higher posterior mean corresponds to greater snap timing variability",
    "text": "Higher posterior mean corresponds to greater snap timing variability\n\n\nCode\n# only keep QB with at least 50 pass attempts for analysis\nqb_filtered &lt;- plays_snap_timing |&gt; \n  distinct(gameId, playId, passer_player_id, passer_player_name) |&gt; \n  count(passer_player_id, passer_player_name) |&gt;\n  filter(n &gt;= 50)\n\nqb_shape_estimates &lt;- posterior_samples |&gt; \n  select(contains(\"r_passer_player_id__shape\")) |&gt;\n  pivot_longer(everything(), names_to = \"passer_player_id\", values_to = \"estimate\") |&gt;  \n  # clean up id column\n  mutate(passer_player_id = str_remove_all(passer_player_id, \n                                           \"r_passer_player_id__shape\\\\[|,Intercept\\\\]\")) |&gt; \n  filter(passer_player_id %in% qb_filtered$passer_player_id) |&gt; \n  # get player names\n  left_join(distinct(plays_snap_timing, passer_player_name, passer_player_id)) |&gt; \n  # order players by posterior mean\n  mutate(passer_player_name = fct_reorder(passer_player_name, estimate, .fun = mean))\n\nlibrary(ggridges)\nqb_shape_estimates |&gt; \n  ggplot(aes(estimate, passer_player_name)) +\n  geom_density_ridges(fill = \"lightgray\", rel_min_height = 0.01,\n                      quantile_lines = TRUE, quantile_fun = mean) +\n  labs(x = \"QB shape random effect\", \n       y = NULL)"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#bonus-visualizing-distributions-with-ggdist",
    "href": "lectures/17-multilevel-heterogeneity.html#bonus-visualizing-distributions-with-ggdist",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Bonus: visualizing distributions with ggdist",
    "text": "Bonus: visualizing distributions with ggdist\n\n\nCode\nlibrary(ggdist)\nqb_shape_estimates |&gt; \n  ggplot(aes(estimate, passer_player_name)) +\n  stat_slab(alpha = 0.4, scale = 0.95) +\n  stat_interval(alpha = 0.7) +\n  stat_summary(geom = \"point\", fun = mean, size = 0.8) +\n  scale_color_manual(values = MetBrewer::met.brewer(\"VanGogh3\"),\n                     labels = c(\"95%\", \"80%\", \"50%\")) +\n  labs(x = \"QB shape random effect\", y = NULL, color = \"Credible interval\") +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#higher-snap-timing-variability-is-related-to-facing-less-havoc-created-by-the-defense",
    "href": "lectures/17-multilevel-heterogeneity.html#higher-snap-timing-variability-is-related-to-facing-less-havoc-created-by-the-defense",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Higher snap timing variability is related to facing less havoc created by the defense",
    "text": "Higher snap timing variability is related to facing less havoc created by the defense"
  },
  {
    "objectID": "lectures/17-multilevel-heterogeneity.html#summary",
    "href": "lectures/17-multilevel-heterogeneity.html#summary",
    "title": "Bayesian multilevel modeling in the wild: Beyond homogeneity",
    "section": "Summary",
    "text": "Summary\n\nWe can explicitly model the variance of a response variable\nbrms makes it easy for fitting Bayesian (multilevel) models\nPaper: arxiv.org/pdf/2502.16313\nCode: github.com/qntkhvn/timing\n\n\nFor some reason that I cannot explain, I am fascinated by variability. No, actually I can explain this: I’m a statistician. — DMA"
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "Lecture\nDate\nTitle\nLinks to slides\n\n\n\n\n1\nJan 14\nIntro and Big Ideas in Sports Analytics\nGoogle slides (requires CMU email)\n\n\n2\nJan 16\nBuilding an Expected Goals Model\nGoogle slides (requires CMU email)\n\n\n3\nJan 21\nBuilding an Expected Goals Model (Cont.)\nGoogle slides (requires CMU email)\n\n\n4\nJan 23\nBuilding an Expected Points Model\nGoogle slides (requires CMU email)\n\n\n5\nJan 28\nExpected Points (cont.) and CPOE\nGoogle slides (requires CMU email)\n\n\n6\nJan 30\nCPOE and introduction to multilevel modeling\nGoogle slides (requires CMU email)\n\n\n7\nFeb 4\nVarying intercepts and slopes\nGoogle slides (requires CMU email)\n\n\n8\nFeb 6\nNested and crossed random effects\nGoogle slides (requires CMU email)\n\n\n9\nFeb 11\nModel fitting and random effects\nGoogle slides (requires CMU email)\n\n\n10\nFeb 13\nRandom effects pooling and uncertainty\nGoogle slides (requires CMU email)\n\n\n11\nFeb 18\nIntro to Bayesian thinking\nGoogle slides (requires CMU email)\n\n\n12\nFeb 20\nBeta-Binomial Model and Conjugate Priors\nGoogle slides (requires CMU email)\n\n\n13\nFeb 25\nIntro to Regularized Adjusted Plus-Minus Models\nGoogle slides (requires CMU email)\n\n\n14\nMar 11\nMethods for approximating the posterior\nGoogle slides (requires CMU email)\n\n\n15\nMar 18\nMCMC Cont. and Intro to Stan\nGoogle slides (requires CMU email)\n\n\n16\nMar 20\nBayesian RAPM in Stan\nGoogle slides (requires CMU email)\n\n\n17\nMar 25\n(Bayesian) Multilevel Modeling with Heterogeneity\nQuarto slides",
    "crumbs": [
      "Lectures"
    ]
  },
  {
    "objectID": "demos/03-multinom-logit.html",
    "href": "demos/03-multinom-logit.html",
    "title": "Lecture 4: Multinomial Logistic Regression for Expected Points",
    "section": "",
    "text": "The goal of this demo is to introduce how to fit and evaluate a multinomial logistic regression model in the context of modeling the next scoring event in American football. For this demo, we’ll use an example dataset of NFL play-by-play data from 2013 to 2023. This is initialized with a column including the next score in the half for each play (you can find the script on Canvas, which creates the dataset using nflreadr).\nThe following code chunk reads in the relevant NFL play-by-play dataset (assuming it is in the correct directory) and performs some initial pre-processing relevant for the expected points model:\n\nlibrary(tidyverse)\nnfl_ep_model_data &lt;- read_rds(here::here(\"data/model_nfl_pbp_data.rds\"))\nnfl_ep_model_data &lt;- nfl_ep_model_data |&gt;\n  # Make the No_Score level the reference level:\n  mutate(Next_Score_Half = fct_relevel(Next_Score_Half, \"No_Score\"),\n         # log transform of yards to go and indicator for two minute warning:\n         log_ydstogo = log(ydstogo),\n         # Changing down into a factor variable: \n         down = factor(down))\n\nnfl_ep_model_data\n\n# A tibble: 422,904 × 21\n   game_id     Next_Score_Half Drive_Score_Half play_type game_seconds_remaining\n   &lt;chr&gt;       &lt;fct&gt;                      &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt;\n 1 2013_01_AR… Opp_Touchdown                  4 pass                        3593\n 2 2013_01_AR… Opp_Touchdown                  4 run                         3572\n 3 2013_01_AR… Opp_Touchdown                  4 pass                        3536\n 4 2013_01_AR… Opp_Touchdown                  4 no_play                     3507\n 5 2013_01_AR… Opp_Touchdown                  4 run                         3476\n 6 2013_01_AR… Opp_Touchdown                  4 no_play                     3446\n 7 2013_01_AR… Opp_Touchdown                  4 pass                        3428\n 8 2013_01_AR… Opp_Touchdown                  4 pass                        3424\n 9 2013_01_AR… Opp_Touchdown                  4 punt                        3397\n10 2013_01_AR… Touchdown                      4 run                         3386\n# ℹ 422,894 more rows\n# ℹ 16 more variables: half_seconds_remaining &lt;dbl&gt;, yardline_100 &lt;dbl&gt;,\n#   posteam &lt;chr&gt;, defteam &lt;chr&gt;, home_team &lt;chr&gt;, ydstogo &lt;dbl&gt;, season &lt;int&gt;,\n#   qtr &lt;dbl&gt;, down &lt;fct&gt;, week &lt;int&gt;, drive &lt;dbl&gt;, score_differential &lt;dbl&gt;,\n#   posteam_timeouts_remaining &lt;dbl&gt;, defteam_timeouts_remaining &lt;dbl&gt;,\n#   desc &lt;chr&gt;, log_ydstogo &lt;dbl&gt;"
  },
  {
    "objectID": "demos/03-multinom-logit.html#introduction",
    "href": "demos/03-multinom-logit.html#introduction",
    "title": "Lecture 4: Multinomial Logistic Regression for Expected Points",
    "section": "",
    "text": "The goal of this demo is to introduce how to fit and evaluate a multinomial logistic regression model in the context of modeling the next scoring event in American football. For this demo, we’ll use an example dataset of NFL play-by-play data from 2013 to 2023. This is initialized with a column including the next score in the half for each play (you can find the script on Canvas, which creates the dataset using nflreadr).\nThe following code chunk reads in the relevant NFL play-by-play dataset (assuming it is in the correct directory) and performs some initial pre-processing relevant for the expected points model:\n\nlibrary(tidyverse)\nnfl_ep_model_data &lt;- read_rds(here::here(\"data/model_nfl_pbp_data.rds\"))\nnfl_ep_model_data &lt;- nfl_ep_model_data |&gt;\n  # Make the No_Score level the reference level:\n  mutate(Next_Score_Half = fct_relevel(Next_Score_Half, \"No_Score\"),\n         # log transform of yards to go and indicator for two minute warning:\n         log_ydstogo = log(ydstogo),\n         # Changing down into a factor variable: \n         down = factor(down))\n\nnfl_ep_model_data\n\n# A tibble: 422,904 × 21\n   game_id     Next_Score_Half Drive_Score_Half play_type game_seconds_remaining\n   &lt;chr&gt;       &lt;fct&gt;                      &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt;\n 1 2013_01_AR… Opp_Touchdown                  4 pass                        3593\n 2 2013_01_AR… Opp_Touchdown                  4 run                         3572\n 3 2013_01_AR… Opp_Touchdown                  4 pass                        3536\n 4 2013_01_AR… Opp_Touchdown                  4 no_play                     3507\n 5 2013_01_AR… Opp_Touchdown                  4 run                         3476\n 6 2013_01_AR… Opp_Touchdown                  4 no_play                     3446\n 7 2013_01_AR… Opp_Touchdown                  4 pass                        3428\n 8 2013_01_AR… Opp_Touchdown                  4 pass                        3424\n 9 2013_01_AR… Opp_Touchdown                  4 punt                        3397\n10 2013_01_AR… Touchdown                      4 run                         3386\n# ℹ 422,894 more rows\n# ℹ 16 more variables: half_seconds_remaining &lt;dbl&gt;, yardline_100 &lt;dbl&gt;,\n#   posteam &lt;chr&gt;, defteam &lt;chr&gt;, home_team &lt;chr&gt;, ydstogo &lt;dbl&gt;, season &lt;int&gt;,\n#   qtr &lt;dbl&gt;, down &lt;fct&gt;, week &lt;int&gt;, drive &lt;dbl&gt;, score_differential &lt;dbl&gt;,\n#   posteam_timeouts_remaining &lt;dbl&gt;, defteam_timeouts_remaining &lt;dbl&gt;,\n#   desc &lt;chr&gt;, log_ydstogo &lt;dbl&gt;"
  },
  {
    "objectID": "demos/03-multinom-logit.html#fitting-a-multinomial-logistic-regression-model",
    "href": "demos/03-multinom-logit.html#fitting-a-multinomial-logistic-regression-model",
    "title": "Lecture 4: Multinomial Logistic Regression for Expected Points",
    "section": "Fitting a multinomial logistic regression model",
    "text": "Fitting a multinomial logistic regression model\nIn order to fit a multinomial logistic regression model in R, the easiest way is to use the nnet package with the multinom function. The following code chunk fits this model to the full dataset with the Next_Score_Half variable as the response with the context variables as the predictors:\n\nlibrary(nnet)\ninit_ep_model &lt;- multinom(Next_Score_Half ~ half_seconds_remaining + \n                            yardline_100 + down + log_ydstogo + \n                            log_ydstogo * down + yardline_100 * down, \n                          data = nfl_ep_model_data, maxit = 300)\n\n# weights:  98 (78 variable)\ninitial  value 822933.185674 \niter  10 value 646448.661731\niter  20 value 628562.786640\niter  30 value 616585.530613\niter  40 value 600078.459583\niter  50 value 597249.917485\niter  60 value 568326.053579\niter  70 value 561806.646221\niter  80 value 556313.688644\niter  90 value 555528.854290\niter 100 value 555518.276158\nfinal  value 555518.120956 \nconverged\n\n\nNote the use of maxit = 300 is to provide a sufficient number of steps for model fitting. You’ll notice the printing of iteration steps here because this package is actually the simplest package used for fitting neural networks in R.\nNotice what happens when we use the summary() function on this model (it takes some time to run):\n\nsummary(init_ep_model)\n\nCall:\nmultinom(formula = Next_Score_Half ~ half_seconds_remaining + \n    yardline_100 + down + log_ydstogo + log_ydstogo * down + \n    yardline_100 * down, data = nfl_ep_model_data, maxit = 300)\n\nCoefficients:\n               (Intercept) half_seconds_remaining yardline_100      down2\nField_Goal      -0.2607051            0.004116958 -0.034840581  0.7076165\nOpp_Field_Goal  -3.0189007            0.004293194  0.001137907  0.1443799\nOpp_Safety      -8.9905777            0.004245522  0.058165564 -1.0759002\nOpp_Touchdown   -2.8386923            0.004508825  0.001923287  0.0914707\nSafety          -4.1544215            0.004459871 -0.019844872 -0.8222278\nTouchdown        2.1128586            0.004298760 -0.036028100 -1.0277706\n                    down3      down4 log_ydstogo down2:log_ydstogo\nField_Goal      0.8926587  1.2557561   0.3805016     -0.2836294318\nOpp_Field_Goal  0.2142137  0.3490739   0.1395655     -0.0468113016\nOpp_Safety     -0.4023122  0.8780304  -0.6304597      0.7793959964\nOpp_Touchdown   0.1912419  0.3611854   0.1176799     -0.0008362159\nSafety         -0.7113207 -0.5755544  -0.3702644      0.4053892714\nTouchdown      -1.4807308 -2.8058121  -0.5186325      0.3515486857\n               down3:log_ydstogo down4:log_ydstogo yardline_100:down2\nField_Goal          -0.276146057        -0.1963895      -0.0014910525\nOpp_Field_Goal      -0.053572298        -0.1586719       0.0015471520\nOpp_Safety           0.753610712         0.7305257      -0.0066148761\nOpp_Touchdown       -0.008979889        -0.1477311       0.0008414841\nSafety               0.331151454         0.3681949      -0.0006310041\nTouchdown            0.307635794         0.2487536       0.0002840841\n               yardline_100:down3 yardline_100:down4\nField_Goal           -0.006491710       -0.022099391\nOpp_Field_Goal        0.003617006        0.007415363\nOpp_Safety           -0.012361132       -0.028266233\nOpp_Touchdown         0.002475162        0.006787692\nSafety                0.001022146       -0.001257291\nTouchdown             0.005196036        0.020872169\n\nStd. Errors:\n                (Intercept) half_seconds_remaining yardline_100        down2\nField_Goal     9.973877e-03           2.056382e-05 0.0003265603 9.222868e-03\nOpp_Field_Goal 1.301499e-02           2.164403e-05 0.0003570708 3.525795e-03\nOpp_Safety     3.608208e-05           6.056503e-05 0.0009598729 1.676993e-05\nOpp_Touchdown  1.249336e-02           2.114300e-05 0.0003484688 4.994918e-03\nSafety         2.031640e-04           4.981585e-05 0.0010522061 1.154787e-04\nTouchdown      9.156701e-03           2.042802e-05 0.0003097515 1.026284e-02\n                      down3        down4  log_ydstogo down2:log_ydstogo\nField_Goal     9.165213e-03 4.368126e-03 0.0076911593      0.0084179580\nOpp_Field_Goal 3.705261e-03 2.529465e-03 0.0070133975      0.0086822558\nOpp_Safety     1.585732e-05 1.948469e-05 0.0002905214      0.0001058366\nOpp_Touchdown  4.972851e-03 3.315516e-03 0.0077647303      0.0088275451\nSafety         7.438725e-05 5.127217e-05 0.0007459947      0.0003197118\nTouchdown      1.038676e-02 2.457417e-03 0.0071809004      0.0078822666\n               down3:log_ydstogo down4:log_ydstogo yardline_100:down2\nField_Goal          0.0085571300      0.0099954257       0.0004123602\nOpp_Field_Goal      0.0086850330      0.0095492903       0.0003746628\nOpp_Safety          0.0001036511      0.0000755188       0.0009717132\nOpp_Touchdown       0.0090569632      0.0103499484       0.0003861318\nSafety              0.0002244464      0.0001505608       0.0011547005\nTouchdown           0.0080808936      0.0105894677       0.0003887755\n               yardline_100:down3 yardline_100:down4\nField_Goal           0.0004477493       0.0005864862\nOpp_Field_Goal       0.0003898272       0.0004537012\nOpp_Safety           0.0011035945       0.0013637166\nOpp_Touchdown        0.0004097842       0.0004720251\nSafety               0.0013038376       0.0015717666\nTouchdown            0.0004227704       0.0004995965\n\nResidual Deviance: 1111036 \nAIC: 1111192 \n\n\nYou see the usual type of output (coefficients, standard errors, deviance, AIC), but we see coefficient estimates for each next score outcome (except for the reference level No_Score).\nAlternatively, it can be helpful to visualize the implied relationships between the various features and the outcome probabilities using visualization techniques. In order to do this, we first need to get the fitted probabilities for each scoring event. For a nnet multinomial logistic regression model, we can use the predict() function with type = \"probs\" as an input to return the matrix of probabilities for each event:\n\nnext_score_probs &lt;- predict(init_ep_model, \n                            newdata = nfl_ep_model_data, type = \"probs\") |&gt;\n  as_tibble()\nnext_score_probs\n\n# A tibble: 422,904 × 7\n   No_Score Field_Goal Opp_Field_Goal Opp_Safety Opp_Touchdown  Safety Touchdown\n      &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1 0.000970      0.204         0.157    0.00476          0.279 0.00427     0.350\n 2 0.000864      0.236         0.126    0.00217          0.222 0.00422     0.408\n 3 0.000912      0.234         0.119    0.00167          0.204 0.00445     0.437\n 4 0.000876      0.269         0.0957   0.000879         0.164 0.00398     0.465\n 5 0.00131       0.324         0.139    0.00133          0.236 0.00328     0.295\n 6 0.00132       0.274         0.131    0.00188          0.227 0.00460     0.361\n 7 0.00158       0.261         0.151    0.00282          0.262 0.00463     0.317\n 8 0.00164       0.238         0.184    0.00363          0.320 0.00471     0.247\n 9 0.00173       0.265         0.168    0.00226          0.285 0.00669     0.271\n10 0.00255       0.199         0.170    0.00655          0.291 0.00411     0.327\n# ℹ 422,894 more rows\n\n\nThe following code chunk joins these probabilities to the original dataset, and creates a visual that displays a smooth regression (we’ll cover this later) of the model’s probabilities as a function of certain inputs. Note: these visuals do not represent the exact relationship, but rather just a summary of the relationships. This code was used to generate the figures in my paper.\n\n# Create the facetted version for each events probability based on down:\nnfl_ep_model_data |&gt; \n  # Join the probs:\n  bind_cols(next_score_probs) |&gt;\n  # Only grab a subset of columns\n  dplyr::select(yardline_100, down, No_Score:Touchdown) |&gt;\n  pivot_longer(No_Score:Touchdown,\n               # Name of the column for the outcomes\n               names_to = \"next_score_type\",\n               # Name of the column for the predicted probabilities\n               values_to = \"pred_prob\") |&gt;\n  # Create a score value column to use for the color legend\n  mutate(event_value = case_when(\n                         next_score_type == \"No_Score\" ~ 0,\n                         next_score_type == \"Touchdown\" ~ 7,\n                         next_score_type == \"Field_Goal\" ~ 3,\n                         next_score_type == \"Safety\" ~ 2,\n                         next_score_type == \"Opp_Field_Goal\" ~ -3,\n                         next_score_type == \"Opp_Safety\" ~ -2,\n                         TRUE ~ -7),\n         # Label for down\n         down_label = case_when(\n                        down == 1 ~ \"1st down\",\n                        down == 2 ~ \"2nd down\",\n                        down == 3 ~ \"3rd down\",\n                        TRUE ~ \"4th down\")) |&gt;\n  ggplot(aes(x = yardline_100, y = pred_prob, color = event_value,\n             group = next_score_type)) + \n  geom_smooth(se = FALSE) + \n    ylim(0,1) + \n    facet_wrap(~down_label, ncol = 4) + \n  theme_bw() +\n  labs(x = \"Yards from opponent's end zone\", y = \"Predicted probability\") +\n  scale_color_gradient2(low = \"darkorange4\", mid = \"gray\",\n                        high = \"darkslateblue\", \n                        breaks = c(-7, -3, -2, 0, 2, 3, 7),\n                        labels=c(\" -Touchdown (-7) \", \" -Field Goal (-3) \",\n                                 \" -Safety (-2) \", \" No Score (0) \",\n                                 \" Safety (2) \", \" Field Goal (3) \", \n                                 \" Touchdown (7) \"),\n                        guide = guide_legend(title = NULL, ncol = 7,\n                                             reverse = TRUE,\n                                             override.aes = list(size = 5))) +\n  theme(legend.background = element_rect(fill = \"white\"),\n        axis.title = element_text(size = 18),\n        axis.text.y = element_text(size = 16),\n        axis.text.x = element_text(size = 10),\n        legend.position = \"bottom\",\n        strip.background = element_blank(),\n        strip.text = element_text(size = 18),\n        legend.text = element_text(size = 12))\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nWe can also create a figure that summarizes the relationships between different features with the actual variable of interest: expected points. The first step is to compute the expected points, which we can do using a simple line of code that weights each probability with a point value for the outcome:\n\nnext_score_probs &lt;- next_score_probs |&gt;\n  mutate(ep = Touchdown * 7 + Field_Goal * 3 + Safety * 2 +\n           Opp_Touchdown * -7 + Opp_Field_Goal * -3 + Opp_Safety * -2)\n\nAnd then use a similar approach as before, including historical models, to display the implied relationships:\n\n# Expected points relationships, for the historical models:\n\n# First the Carter model:\ncarter_data &lt;- tibble(\"yardline_100\" = c(95, 85, 75, 65, 55, 45, 35, 25, 15, 5),\n                      \"ep\" = c(-1.245, -.637, .236, .923, 1.538, 2.392, \n                               3.167, 3.681, 4.572, 6.041)) |&gt;\n  mutate(model = \"Carter\")\n\n# and Hidden Game of Football model:\nhgf_data &lt;- tibble(\"yardline_100\" = c(100, 75, 50, 25, 0),\n                   \"ep\" = c(-2, 0, 2, 4, 6)) |&gt;\n  mutate(model = \"Hidden Game of Football\")\n\n# Display our model's results by down and then compare to the historical\n# models from Carter and the Hidden Game of Football:\nnfl_ep_model_data |&gt; \n  bind_cols(next_score_probs) |&gt;\n  # Only grab a subset of columns\n  dplyr::select(yardline_100, down, ep) |&gt;\n  ggplot(aes(x = yardline_100, y = ep,\n             color = as.factor(down))) + \n  geom_smooth(size = 2) + \n  labs(x = \"Yards from opponent's end zone\",\n       y = \"Expected points value\",\n       color = \"Model\") +\n  theme_bw() + \n  scale_y_continuous(limits = c(-4, 6),breaks = seq(-4, 6, 2)) + \n  geom_line(data = bind_rows(carter_data, hgf_data),\n            aes(x = yardline_100, y = ep, color = model),\n            size = 2, linetype = \"dashed\") + \n  geom_point(data = bind_rows(carter_data, hgf_data),\n             aes(x = yardline_100, y = ep, color = model),\n             size = 5, alpha = 0.5) + \n  scale_x_continuous(breaks = seq(from = 5, to = 95, by = 10)) +\n  scale_color_manual(values = c(\"#0000FF\",\n                                \"#5537AA\",\n                                \"#AA6E55\",\n                                \"#FFA500\",\n                                \"seagreen4\",\n                                \"darkred\"),\n                     labels = c(\"Multilogit - 1st down\",\n                                \"Multilogit - 2nd down\",\n                                \"Multilogit - 3rd down\",\n                                \"Multilogit - 4th down\",\n                                \"Carter\",\n                                \"Hidden Game of Football\")) +\n  theme(axis.title = element_text(size = 18),\n        axis.text = element_text(size = 12),\n        legend.text = element_text(size = 8),\n        legend.title = element_text(size = 10),\n        legend.position = \"bottom\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 2329 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "demos/03-multinom-logit.html#cross-validation-calibration",
    "href": "demos/03-multinom-logit.html#cross-validation-calibration",
    "title": "Lecture 4: Multinomial Logistic Regression for Expected Points",
    "section": "Cross-validation calibration",
    "text": "Cross-validation calibration\nSince our goal relies on using the model’s probability estimates, we can evaluate the model similar to the expected goals model: via out-of-sample calibration. The notable difference is that we need to assess how well the model is calibrated for each scoring event. The following code generates the leave-one-year-out cross-validation predictions for each play in the dataset (note that the model fitting steps are printed for each season fold):\n\ninit_loso_cv_preds &lt;- \n  map_dfr(unique(nfl_ep_model_data$season), \n          function(x) {\n            # Separate test and training data:\n            test_data &lt;- nfl_ep_model_data |&gt; filter(season == x)\n            train_data &lt;- nfl_ep_model_data |&gt; filter(season != x)\n            # Fit multinomial logistic regression model:\n            ep_model &lt;- \n              multinom(Next_Score_Half ~ half_seconds_remaining + yardline_100 + down + \n                         log_ydstogo + log_ydstogo * down + yardline_100 * down, \n                       data = train_data, maxit = 300)\n            # Return dataset of class probabilities:\n            predict(ep_model, newdata = test_data, type = \"probs\") |&gt;\n              as_tibble() |&gt;\n              mutate(Next_Score_Half = test_data$Next_Score_Half,\n                     season = x)\n              })\n\n# weights:  98 (78 variable)\ninitial  value 747749.055246 \niter  10 value 581440.350658\niter  20 value 566007.216610\niter  30 value 553092.654185\niter  40 value 538119.354133\niter  50 value 536424.391744\niter  60 value 520828.612116\niter  70 value 511272.480459\niter  80 value 505399.169176\niter  90 value 504210.861998\niter 100 value 504171.076545\niter 110 value 504167.970371\niter 120 value 504167.510171\nfinal  value 504167.490166 \nconverged\n# weights:  98 (78 variable)\ninitial  value 748467.096091 \niter  10 value 582511.589203\niter  20 value 567340.012597\niter  30 value 553488.233716\niter  40 value 537655.594760\niter  50 value 534824.876335\niter  60 value 525502.198924\niter  70 value 512996.713239\niter  80 value 506475.015847\niter  90 value 504965.487881\niter 100 value 504938.379836\nfinal  value 504937.826673 \nconverged\n# weights:  98 (78 variable)\ninitial  value 747873.593495 \niter  10 value 581271.333157\niter  20 value 565846.033579\niter  30 value 553897.370602\niter  40 value 536428.400172\niter  50 value 533324.447646\niter  60 value 519623.381518\niter  70 value 510091.467079\niter  80 value 505678.094433\niter  90 value 504541.138811\niter 100 value 504525.471455\nfinal  value 504525.424807 \nconverged\n# weights:  98 (78 variable)\ninitial  value 748525.473395 \niter  10 value 584430.991679\niter  20 value 569735.869879\niter  30 value 558267.533816\niter  40 value 545227.965954\niter  50 value 542097.115990\niter  60 value 534837.983927\niter  70 value 514739.234466\niter  80 value 507703.178044\niter  90 value 505555.625847\niter 100 value 505532.168333\nfinal  value 505532.108496 \nconverged\n# weights:  98 (78 variable)\ninitial  value 749165.677834 \niter  10 value 586127.439746\niter  20 value 569455.903919\niter  30 value 555673.870004\niter  40 value 537108.662513\niter  50 value 535388.738604\niter  60 value 525520.820192\niter  70 value 510458.157722\niter  80 value 505818.284259\niter  90 value 505018.434102\niter 100 value 505008.890377\nfinal  value 505008.882666 \nconverged\n# weights:  98 (78 variable)\ninitial  value 750086.093335 \niter  10 value 585080.586820\niter  20 value 570595.228537\niter  30 value 555605.385864\niter  40 value 543202.950882\niter  50 value 541039.078280\niter  60 value 527670.700071\niter  70 value 516882.317084\niter  80 value 510327.264273\niter  90 value 507410.311047\niter 100 value 507383.469803\niter 110 value 507382.051725\nfinal  value 507381.972455 \nconverged\n# weights:  98 (78 variable)\ninitial  value 749346.647478 \niter  10 value 586291.599094\niter  20 value 571463.633794\niter  30 value 555251.569408\niter  40 value 540714.413545\niter  50 value 538208.068421\niter  60 value 524922.778076\niter  70 value 511749.141809\niter  80 value 506515.736547\niter  90 value 505678.465320\niter 100 value 505662.467396\nfinal  value 505662.424972 \nconverged\n# weights:  98 (78 variable)\ninitial  value 749852.584117 \niter  10 value 585091.048570\niter  20 value 570487.939148\niter  30 value 554224.337618\niter  40 value 545207.608450\niter  50 value 542998.382583\niter  60 value 523574.947287\niter  70 value 512352.949701\niter  80 value 507690.704984\niter  90 value 506457.363312\niter 100 value 506441.642486\nfinal  value 506441.579198 \nconverged\n# weights:  98 (78 variable)\ninitial  value 745867.360132 \niter  10 value 581916.027979\niter  20 value 566655.115894\niter  30 value 554775.921190\niter  40 value 536693.143905\niter  50 value 534378.950264\niter  60 value 527881.563685\niter  70 value 513033.555210\niter  80 value 505528.391065\niter  90 value 504279.763183\niter 100 value 504257.414205\nfinal  value 504257.309441 \nconverged\n# weights:  98 (78 variable)\ninitial  value 746513.402301 \niter  10 value 585896.386604\niter  20 value 571358.916426\niter  30 value 556119.424347\niter  40 value 541842.753103\niter  50 value 539199.324648\niter  60 value 521593.725464\niter  70 value 510590.617369\niter  80 value 504547.807280\niter  90 value 503510.806223\niter 100 value 503498.307119\nfinal  value 503498.009677 \nconverged\n# weights:  98 (78 variable)\ninitial  value 745884.873323 \niter  10 value 582559.463464\niter  20 value 567597.676369\niter  30 value 553086.905300\niter  40 value 539643.354316\niter  50 value 537190.694757\niter  60 value 530614.346149\niter  70 value 516141.509588\niter  80 value 506361.234224\niter  90 value 503662.111159\niter 100 value 503639.873014\nfinal  value 503639.857722 \nconverged\n\n\nWe can then generate the calibration summary as before, with the caveat we need to do this for each outcome probability. Since the above code returns a dataset with a column for each outcome separately, we need to pivot the dataset from wide to long so that there is a row for each play-outcome combination. We can do this using the useful pivot_longer() function as shown below, with the same summary steps as before:\n\nep_cv_loso_calibration_results &lt;- init_loso_cv_preds |&gt;\n  # First specify which columns to turn into rows\n  pivot_longer(No_Score:Touchdown,\n               # Name of the column for the outcomes\n               names_to = \"next_score_type\",\n               # Name of the column for the predicted probabilities\n               values_to = \"pred_prob\") |&gt;\n  # And then the same steps as before but now with grouping by score outcome:\n  mutate(bin_pred_prob = round(pred_prob / 0.05) * .05) |&gt;\n  group_by(next_score_type, bin_pred_prob) |&gt;\n  summarize(n_plays = n(), \n            n_scoring_event = length(which(Next_Score_Half == next_score_type)),\n            bin_actual_prob = n_scoring_event / n_plays,\n            bin_se = sqrt((bin_actual_prob * (1 - bin_actual_prob)) / n_plays),\n            .groups = \"drop\") |&gt;\n  mutate(bin_upper = pmin(bin_actual_prob + 2 * bin_se, 1),\n         bin_lower = pmax(bin_actual_prob - 2 * bin_se, 0))\n\nAnd then with this dataset we can create calibration plots for each outcome, using similar code as before:\n\nep_cv_loso_calibration_results |&gt;\n  mutate(next_score_type = fct_relevel(next_score_type,\n                                       \"Opp_Safety\", \"Opp_Field_Goal\", \n                                       \"Opp_Touchdown\", \"No_Score\", \"Safety\", \n                                       \"Field_Goal\", \"Touchdown\"),\n  next_score_type = fct_recode(next_score_type, \n                               \"-Field Goal (-3)\" = \"Opp_Field_Goal\",\n                               \"-Safety (-2)\" = \"Opp_Safety\", \n                               \"-Touchdown (-7)\" = \"Opp_Touchdown\",\n                               \"Field Goal (3)\" = \"Field_Goal\", \n                               \"No Score (0)\" = \"No_Score\",\n                               \"Touchdown (7)\" = \"Touchdown\", \n                               \"Safety (2)\" = \"Safety\")) |&gt;\n  ggplot(aes(x = bin_pred_prob, y = bin_actual_prob)) +\n  geom_abline(slope = 1, intercept = 0, color = \"black\", linetype = \"dashed\") +\n  geom_point(size = 0.5) +\n  geom_errorbar(aes(ymin = bin_lower, ymax = bin_upper)) + \n  coord_equal() +   \n  scale_x_continuous(limits = c(0, 1)) + \n  scale_y_continuous(limits = c(0, 1)) + \n  labs(x = \"Estimated next score probability\", \n       y = \"Observed next score probability\") + \n  theme_bw() + \n  theme(strip.background = element_blank(), \n        axis.text.x = element_text(angle = 90)) +\n  facet_wrap(~ next_score_type, ncol = 4)\n\n\n\n\n\n\n\n\nWhat stands out for you when inspecting the different calibration plots?"
  },
  {
    "objectID": "demos/03-multinom-logit.html#recap",
    "href": "demos/03-multinom-logit.html#recap",
    "title": "Lecture 4: Multinomial Logistic Regression for Expected Points",
    "section": "Recap",
    "text": "Recap\n\nIntroduced fitting and interpreting a multinomial logistic regression model\nWalked through steps for performing cross-validation calibration for multiple outcomes"
  },
  {
    "objectID": "demos/01-logit-expected-goals.html",
    "href": "demos/01-logit-expected-goals.html",
    "title": "Lecture 2: Building an Expected Goals Model",
    "section": "",
    "text": "The goal of this demo is to introduce the basic steps of building an expected goals model with logistic regression in R. In this demo, we’ll use a dataset of NHL shot attempts during the 2023-2024 NHL season (accessed via hockeyR) to build an expected goals model for hockey. The code used to create this dataset is available on Canvas. The following code chunk reads in the data (notice the use of the here package for reading in the data) and displays a subset of the data:\n\nlibrary(tidyverse)\n\n# This assumes the dataset is saved within the data folder of the directory this\n# file is loaded in, you can change this depending on where you save the data!\nmodel_nhl_shot_data &lt;- read_csv(here::here(\"data/model_nhl_shot_data.csv\"))\nhead(model_nhl_shot_data)\n\n# A tibble: 6 × 11\n    game_id period shooting_player shooting_team goalie_name goalie_team x_fixed\n      &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;\n1    2.02e9      1 Bryan Rust      Pittsburgh P… Petr Mrazek Chicago Bl…     -51\n2    2.02e9      1 Kevin Korchins… Chicago Blac… Tristan Ja… Pittsburgh…     -55\n3    2.02e9      1 Noel Acciari    Pittsburgh P… Petr Mrazek Chicago Bl…      75\n4    2.02e9      1 Wyatt Kaiser    Chicago Blac… Tristan Ja… Pittsburgh…     -39\n5    2.02e9      1 Alex Vlasic     Chicago Blac… Tristan Ja… Pittsburgh…     -36\n6    2.02e9      1 Marcus Petters… Pittsburgh P… Petr Mrazek Chicago Bl…      32\n# ℹ 4 more variables: y_fixed &lt;dbl&gt;, shot_distance &lt;dbl&gt;, shot_angle &lt;dbl&gt;,\n#   is_goal &lt;dbl&gt;\n\n\nNOTE: For hockey fans, for simplicity we are only considering even-strength shot attempts with a goalie in net that were either goals or saved by the goalie (i.e., not considering shots blocked by non-goalie defenders or shots that missed wide of the net).\nBefore diving into any modeling, we should always start with exploratory data analysis (EDA), and visualize the data! The following figure displays the scatterplot of the shot attempts using the provided x (x_fixed) and y (y_fixed) coordinates, colored by the shot outcome (is_goal):\n\nmodel_nhl_shot_data |&gt;\n  # Make a scatterplot of the shot attempts\n  ggplot(aes(x = x_fixed, y = y_fixed, color = as.factor(is_goal))) +\n  # Make sure to modify the alpha!\n  geom_point(alpha = .25) +\n  labs(x = \"x coordinate\", y = \"y coordinate\", \n       color = \"Shot outcome\") +\n  # Use the ggthemes package for colorblind friendly palette\n  ggthemes::scale_color_colorblind(labels = c(\"Save\", \"Goal\")) +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFrom this figure, we can see a higher density of shots that were goals (indicated by orange color) closer to the two empty spaces along the endpoints of the horizontal line where y = 0 corresponding to the locations of the nets. We also see that the goals tend to be more directly in front of these locations relative to the sides. The figure provides us with some evidence that both the shot distance and angle are likely useful in predicting the probability of a goal."
  },
  {
    "objectID": "demos/01-logit-expected-goals.html#introduction",
    "href": "demos/01-logit-expected-goals.html#introduction",
    "title": "Lecture 2: Building an Expected Goals Model",
    "section": "",
    "text": "The goal of this demo is to introduce the basic steps of building an expected goals model with logistic regression in R. In this demo, we’ll use a dataset of NHL shot attempts during the 2023-2024 NHL season (accessed via hockeyR) to build an expected goals model for hockey. The code used to create this dataset is available on Canvas. The following code chunk reads in the data (notice the use of the here package for reading in the data) and displays a subset of the data:\n\nlibrary(tidyverse)\n\n# This assumes the dataset is saved within the data folder of the directory this\n# file is loaded in, you can change this depending on where you save the data!\nmodel_nhl_shot_data &lt;- read_csv(here::here(\"data/model_nhl_shot_data.csv\"))\nhead(model_nhl_shot_data)\n\n# A tibble: 6 × 11\n    game_id period shooting_player shooting_team goalie_name goalie_team x_fixed\n      &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;\n1    2.02e9      1 Bryan Rust      Pittsburgh P… Petr Mrazek Chicago Bl…     -51\n2    2.02e9      1 Kevin Korchins… Chicago Blac… Tristan Ja… Pittsburgh…     -55\n3    2.02e9      1 Noel Acciari    Pittsburgh P… Petr Mrazek Chicago Bl…      75\n4    2.02e9      1 Wyatt Kaiser    Chicago Blac… Tristan Ja… Pittsburgh…     -39\n5    2.02e9      1 Alex Vlasic     Chicago Blac… Tristan Ja… Pittsburgh…     -36\n6    2.02e9      1 Marcus Petters… Pittsburgh P… Petr Mrazek Chicago Bl…      32\n# ℹ 4 more variables: y_fixed &lt;dbl&gt;, shot_distance &lt;dbl&gt;, shot_angle &lt;dbl&gt;,\n#   is_goal &lt;dbl&gt;\n\n\nNOTE: For hockey fans, for simplicity we are only considering even-strength shot attempts with a goalie in net that were either goals or saved by the goalie (i.e., not considering shots blocked by non-goalie defenders or shots that missed wide of the net).\nBefore diving into any modeling, we should always start with exploratory data analysis (EDA), and visualize the data! The following figure displays the scatterplot of the shot attempts using the provided x (x_fixed) and y (y_fixed) coordinates, colored by the shot outcome (is_goal):\n\nmodel_nhl_shot_data |&gt;\n  # Make a scatterplot of the shot attempts\n  ggplot(aes(x = x_fixed, y = y_fixed, color = as.factor(is_goal))) +\n  # Make sure to modify the alpha!\n  geom_point(alpha = .25) +\n  labs(x = \"x coordinate\", y = \"y coordinate\", \n       color = \"Shot outcome\") +\n  # Use the ggthemes package for colorblind friendly palette\n  ggthemes::scale_color_colorblind(labels = c(\"Save\", \"Goal\")) +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFrom this figure, we can see a higher density of shots that were goals (indicated by orange color) closer to the two empty spaces along the endpoints of the horizontal line where y = 0 corresponding to the locations of the nets. We also see that the goals tend to be more directly in front of these locations relative to the sides. The figure provides us with some evidence that both the shot distance and angle are likely useful in predicting the probability of a goal."
  },
  {
    "objectID": "demos/01-logit-expected-goals.html#simple-logistic-regression-model-of-distance",
    "href": "demos/01-logit-expected-goals.html#simple-logistic-regression-model-of-distance",
    "title": "Lecture 2: Building an Expected Goals Model",
    "section": "Simple logistic regression model of distance",
    "text": "Simple logistic regression model of distance\nWe’ll start with a simple logistic regression model to estimate the goal probability of a shot as just a function of the shot distance (in feet). More specifically, we model the log-odds of a goal with a linear model:\n\\[\n\\log \\Big[ \\frac{Pr(S = 1 |\\ distance)}{Pr(S = 0 |\\ distance)} \\Big] = \\beta_0 + \\beta_1 \\cdot distance\n\\]\nBefore we fit this model, we’ll continue with some basic EDA by visualizing the relationship between the shot outcome (is_goal) and the distance (shot_distance). The following figure displays a stacked histogram of the shot distance by outcome, indicating that the majority of goals occur at much shorter distances. While the majority of shot attempts do not result in a goal, we can imagine that the probability of goal increases as the shot distance decreases.\n\nmodel_nhl_shot_data |&gt;\n  ggplot(aes(x = shot_distance, fill = as.factor(is_goal))) +\n  geom_histogram() + \n  labs(x = \"Shot distance (in feet)\",\n       y = \"Count\", fill = \"Shot outcome\") +\n  ggthemes::scale_fill_colorblind(labels = c(\"Save\", \"Goal\")) +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNext, we’re going to create an empirical logit plot to assess the linearity assumption of the logistic regression model, i.e., to check if the log(odds) is a linear function of distance. To do this, we need to bin the continuous variable of distance and then compute the log(odds) (or equivalently log(goals / saves)) within each bin. The following code chunk uses the cut_number() function to divide the shot_distance variable into bins with approximately equal number of observations. NOTE: Due to the potential for the observed proportion to be 0, in order to avoid log(0) we set a floor of 0.0001 using the pmax() function.\n\nshot_distance_summary &lt;- model_nhl_shot_data |&gt;\n  mutate(dist_bin = cut_number(shot_distance, 10)) |&gt;\n  group_by(dist_bin) |&gt;\n  summarize(goal_p = mean(is_goal),\n            n_shots = n(),\n            dist_midpoint = median(shot_distance),\n            .groups = \"drop\") |&gt;\n  mutate(goal_p = pmax(goal_p, 0.0001),\n         emp_logit = log(goal_p / (1 - goal_p)))\nshot_distance_summary\n\n# A tibble: 10 × 5\n   dist_bin     goal_p n_shots dist_midpoint emp_logit\n   &lt;fct&gt;         &lt;dbl&gt;   &lt;int&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n 1 [1,9.1]     0.134      9822           7.2     -1.86\n 2 (9.1,13.9]  0.107      9848          11.2     -2.12\n 3 (13.9,20.4] 0.0931     9633          17.1     -2.28\n 4 (20.4,27.2] 0.0778     9898          24       -2.47\n 5 (27.2,33.2] 0.0599     9745          30.4     -2.75\n 6 (33.2,39.1] 0.0374     9789          36.2     -3.25\n 7 (39.1,45.9] 0.0232     9640          42.2     -3.74\n 8 (45.9,54.5] 0.0162     9800          50       -4.10\n 9 (54.5,62.6] 0.0156     9908          58.5     -4.14\n10 (62.6,189]  0.00450    9551          69.4     -5.40\n\n\nNext, we can make a simple plot with the empirical logit values along the y-axis against the shot distance (via the midpoints of the bins) on the x-axis. We can use geom_smooth() to fit a flexible trend to help us determine if the relationship is linear or not.\n\nshot_distance_summary |&gt;\n  ggplot(aes(x = dist_midpoint, y = emp_logit)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x = \"Shot distance (midpoint of bins)\",\n       y = \"Empirical logits\") +\n  theme_bw()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThis figure looks reasonable in terms of indicating a linear relationship between the log(odds) of a goal and the shot distance. We see that the log(odds) decreases as the shot distance increases, i.e., the probability of a goal decreases as the shot distance increases.\nWith the assumption of a linear relationship checked off, we’ll now fit the logistic regression model using the glm() function in R. This is the general use function for fitting any generalized linear model (GLM) in R, where you just need to specify the distribution with the family argument. Although in this case we are technically modeling a variable (is_goal) that follows the Bernoulli distribution, we set family = \"binomial\" to fit the logistic regression model (since it’s a Binomial distribution with \\(n = 1\\)).\n\ninit_logit &lt;- glm(is_goal ~ shot_distance, data = model_nhl_shot_data,\n                  family = \"binomial\")\n\nWe can then view the summary of the model including coefficient estimates, deviance, etc. via the summary() function:\n\nsummary(init_logit)\n\n\nCall:\nglm(formula = is_goal ~ shot_distance, family = \"binomial\", data = model_nhl_shot_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.6258  -0.4144  -0.2786  -0.1774   4.1872  \n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -1.4826561  0.0246069  -60.25   &lt;2e-16 ***\nshot_distance -0.0483940  0.0009567  -50.58   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 42736  on 97633  degrees of freedom\nResidual deviance: 39264  on 97632  degrees of freedom\nAIC: 39268\n\nNumber of Fisher Scoring iterations: 6\n\n\nUsing this model, we can create a figure displaying the predicted probability of a goal as a function of shot distance. We view this figure below, with the observed goals and saves marked as points at one and zero respectively. As expected, the probability of a goal is highest for the shortest shots. And we can clearly see that the vast majority of goals are within seventy-five feet, while saved shots span the entire range.\n\nmodel_nhl_shot_data |&gt;\n  mutate(xg = init_logit$fitted.values)  |&gt;\n  ggplot(aes(x = shot_distance)) +\n  geom_jitter(aes(y = is_goal,\n                  color = as.factor(is_goal)), \n              width = 0, height = .01,\n             size = .5, alpha = 0.15) +\n  geom_line(aes(y = xg), color = \"blue\") +\n  ggthemes::scale_color_colorblind(guide = \"none\") +\n  labs(x = \"Shot distance (in feet)\",\n       y = \"Predicted probability of goal (aka expected goals)\") +\n  theme_bw()"
  },
  {
    "objectID": "demos/01-logit-expected-goals.html#likelihood-based-approaches-for-model-evaluation-and-comparison",
    "href": "demos/01-logit-expected-goals.html#likelihood-based-approaches-for-model-evaluation-and-comparison",
    "title": "Lecture 2: Building an Expected Goals Model",
    "section": "Likelihood-based approaches for model evaluation and comparison",
    "text": "Likelihood-based approaches for model evaluation and comparison\nWe begin to assess this fit using traditional approaches based on likelihood criterion. Using the deviance, there are two tests we can consider:\n\nGoodness-of-Fit test: \\(H_0\\): fitted model vs \\(H_A\\): saturated model\nDrop-in-Deviance test: \\(H_0\\): reduced model vs \\(H_A\\): larger model (where reduced model is nested within larger model, e.g., reduced model contains subset of larger model predictors)\n\nWe’ll start with the goodness-of-fit test, which is testing the null hypothesis that the current model under consideration is a good fit. If we have evidence to suggest the null hypothesis is rejected, then we may be observing a lack-of-fit. We can perform this test easily in R using the pchisq() function to compution the appropriate p-value based on the assumption that under the null hypothesis, the residual deviance \\(\\sim \\chi^2\\) distribution with \\(n - p\\) degrees of freedom:\n\n1 - pchisq(init_logit$deviance, init_logit$df.residual)\n\n[1] 1\n\n\nBased on this result, we have insufficient evidence to suggest a lack-of-fit. If the p-value was below an error rate threshold (e.g., 0.05) then we would reject the null, but we would not know what is driving the lack-of-fit. It may be that we’re missing important covariates and interactions, suffering from outliers, or other concerns with the distribution fit. Just because we fail to reject the null hypothesis in this example does NOT mean our model is optimal! There are other ways we will be able to improve this model, and the use of the \\(\\chi^2\\) distribution is just an approximation (not guaranteed to be correct…).\nWe can use drop-in-deviance test to compare the fitted model against the null model (intercept-only), using the same function. Under the null, the difference in the reduced model deviance and larger model deviance follows a \\(\\chi^2\\) distribution with degrees of freedom equal to the difference in the degrees of freedom between the two models. In other words, the degrees of freedom for this test is simply the number of parameters in the larger model that are not in the reduced model. The following code chunk shows how to perform this test using the pchisq function:\n\n1 - pchisq(init_logit$null.deviance - init_logit$deviance, \n           init_logit$df.null - init_logit$df.residual)\n\n[1] 0\n\n\nBased on this p-value, we have evidence in favor of the model with the shot distance variable.\nAnother way we can perform this test is to initially fit an intercept-only model (the null model) and then use the anova() function with test = \"Chisq\" specified to achieve the same result:\n\nnull_logit &lt;- glm(is_goal ~ 1, data = model_nhl_shot_data, family = \"binomial\")\nanova(null_logit, init_logit, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: is_goal ~ 1\nModel 2: is_goal ~ shot_distance\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1     97633      42736                          \n2     97632      39264  1   3471.9 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe can use this same test to compare the fit of a model with another variable, such as shot_angle:\n\ndist_angle_logit &lt;- glm(is_goal ~ shot_distance + shot_angle, \n                        data = model_nhl_shot_data, family = \"binomial\")\nanova(init_logit, dist_angle_logit, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: is_goal ~ shot_distance\nModel 2: is_goal ~ shot_distance + shot_angle\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1     97632      39264                          \n2     97631      38620  1   644.38 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBased on this test, we have sufficient evidence to suggest the larger model with both distance and angle is a better fit than the model with only shot distance.\nThe drop-in-deviance test is only appropriate for evaluating models that are nested within another. It is not an approach we can take for general comparison when considering non-nested models (e.g., two models with distinct, non-overlapping features). However, we can use information criteria measures when comparing non-nested models which consider the model’s likelihood penalized by the number of parameters in some way (i.e., penalty for model complexity). The two common information criterions are:\n\nAkaike Information Criterion (AIC) = \\(-2 \\times\\) log(Lik) \\(+ 2p\\), i.e., the more variables we use the higher the AIC\nBayesian Information Criterion (BIC) = \\(-2 \\times\\) log(Lik) \\(+ p \\log(n)\\), i.e., log of number of observations places greater penalty on each additional variable\n\nIn these forms, for both AIC and BIC, lower values are better.\nBy default, the AIC is reported in the summary() output for GLMs:\n\nsummary(dist_angle_logit)\n\n\nCall:\nglm(formula = is_goal ~ shot_distance + shot_angle, family = \"binomial\", \n    data = model_nhl_shot_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.8111  -0.3907  -0.2648  -0.1798   4.1795  \n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -0.8914673  0.0326450  -27.31   &lt;2e-16 ***\nshot_distance -0.0513284  0.0009580  -53.58   &lt;2e-16 ***\nshot_angle    -0.0146870  0.0006025  -24.38   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 42736  on 97633  degrees of freedom\nResidual deviance: 38620  on 97631  degrees of freedom\nAIC: 38626\n\nNumber of Fisher Scoring iterations: 6\n\n\nYou can also use the AIC() and BIC() functions to return the respective values for a given model:\n\nAIC(dist_angle_logit)\n\n[1] 38625.64\n\n\nThe above output matches the previous summary display. And below we can see how the model with both features has a better BIC than the model with only distance:\n\nBIC(init_logit)\n\n[1] 39287\n\nBIC(dist_angle_logit)\n\n[1] 38654.11"
  },
  {
    "objectID": "demos/01-logit-expected-goals.html#recap",
    "href": "demos/01-logit-expected-goals.html#recap",
    "title": "Lecture 2: Building an Expected Goals Model",
    "section": "Recap",
    "text": "Recap\n\nCovered basics of fitting logistic regression in R using glm()\nEvaluated and compared models using likelihood-based approaches"
  },
  {
    "objectID": "demos/14-intro-stan.html",
    "href": "demos/14-intro-stan.html",
    "title": "Lecture 15: Introduction to Stan",
    "section": "",
    "text": "The purpose of this demo is to demonstrate how to use the Stan probabilistic programming language in R with the rstan package.\nPrior to proceeding through this demo, you need to install the rstan package. PAY ATTENTION! This package is not installed like normal R packages! You need to follow the instructions (depending on your OS) that are available here on GitHub. In order to make sure you have rstan installed correctly, you should be able to run the following line of code directly in your console to fit an example Stan model. It will load up fit, fit2, mod and stancode in your environment but you can remove them after making sure code runs without any errors (note the warning messages you see are fine and expected).\n\nexample(stan_model, package = \"rstan\", run.dontrun = TRUE)\n\nIn this demo, we’ll once again consider the Beta-Binomial model for Caitlin Clark’s FG%. Similar to the posterior_approx.qmd demo, we do not need to read in any data for this demonstration."
  },
  {
    "objectID": "demos/14-intro-stan.html#introduction",
    "href": "demos/14-intro-stan.html#introduction",
    "title": "Lecture 15: Introduction to Stan",
    "section": "",
    "text": "The purpose of this demo is to demonstrate how to use the Stan probabilistic programming language in R with the rstan package.\nPrior to proceeding through this demo, you need to install the rstan package. PAY ATTENTION! This package is not installed like normal R packages! You need to follow the instructions (depending on your OS) that are available here on GitHub. In order to make sure you have rstan installed correctly, you should be able to run the following line of code directly in your console to fit an example Stan model. It will load up fit, fit2, mod and stancode in your environment but you can remove them after making sure code runs without any errors (note the warning messages you see are fine and expected).\n\nexample(stan_model, package = \"rstan\", run.dontrun = TRUE)\n\nIn this demo, we’ll once again consider the Beta-Binomial model for Caitlin Clark’s FG%. Similar to the posterior_approx.qmd demo, we do not need to read in any data for this demonstration."
  },
  {
    "objectID": "demos/14-intro-stan.html#beta-binomial-in-stan",
    "href": "demos/14-intro-stan.html#beta-binomial-in-stan",
    "title": "Lecture 15: Introduction to Stan",
    "section": "Beta-Binomial in Stan",
    "text": "Beta-Binomial in Stan\nAssuming you have the rstan package installed, we can proceed to write-up our first Stan model. There are three main components to each Stan model:\n\ndata: you specify what type of data is used for the model, including info specifying if it’s an integer, real continuous number, are there bounds, etc. For our example, the only data will be the number of successful FG attempts \\(Y\\) out of \\(n = 85\\) trials. This section will also include other relevant information about the data that we’ll see in the Bayesian RAPM Stan demo.\nparameters: what are the parameters of the model? In this example, we only have the \\(\\pi\\) parameter for the Binomial distribution probability of success. You’ll also need to indicate the type and bounds for parameters.\nmodel: This the heart of the Stan code where you write out in code the model likelihood and prior (or more generally, the multilevel data generating process). As you’ll see, the functions for the different distributions effectively look like what you see on wikipedia pages for each distribution. You have the name of the distribution with the parameter inputs.\n\n\nbeta_binomial_model &lt;- \"\n  data {\n    // set-up the data as the number of success from 0 to 85\n    int&lt;lower = 0, upper = 85&gt; Y;\n  }\n  parameters {\n    // define the paramter pi\n    real&lt;lower = 0, upper = 1&gt; pi;\n  }\n  model {\n    // now write out the data-generating process, by sampling from \n    // the Binomial model with n = 85 and then specify the prior for pi\n    Y ~ binomial(85, pi);\n    pi ~ beta(45.9, 68.7);\n  }\n\"\n\nAnd now we’re ready to use rstan for approximating the posterior via simulation. We run the stan() function to do this where we provide it with the model_code, which can be stored in a string like above or as a .stan file. Additionally, we need to provide the input data as a list with names matching the specified data in the model code. The remaining input relates to the Markov chains:\n\nchains tells Stan how many Markov chains to run in parallel, which is useful for speeding up the approximation. Additionally, this will be useful for diagnostics later on.\niter tells Stan how long each (i.e., how many iterations) each Markov chain should. However, you’ll notice in the code chunk below that iter = 5000 * 2. This is because, by default via the warmup argument, the first half of the iterations are warmup or burn-in samples that are ignored. The idea behind this is that the first so many steps in the chain might be unreasonable values for the parameter of interest, so we let it run for a bit before grabbing samples that are hopefully reasonable in approximating the posterior distribution.\nseed for making sure we can replicate the randomness of the simulation results.\n\nThe following code chunk performs a simulation with 5000 iterations across 4 Markov chains, thus resulting in a sample of 20,000 values to approximate the posterior distribution (NOTE: this will take a few minutes to run since Stan effectively needs to compile code that is appropriate for the provided model and data):\n\nlibrary(rstan)\n\nWarning: package 'rstan' was built under R version 4.2.3\n\n\nLoading required package: StanHeaders\n\n\nWarning: package 'StanHeaders' was built under R version 4.2.3\n\n\n\nrstan version 2.32.6 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\nbeta_binomial_sim &lt;- stan(model_code = beta_binomial_model, \n                          data = list(Y = 33), \n                          chains = 4, iter = 5000 * 2, \n                          seed = 2025)\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3e-06 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.012 seconds (Warm-up)\nChain 1:                0.013 seconds (Sampling)\nChain 1:                0.025 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 0 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.013 seconds (Warm-up)\nChain 2:                0.014 seconds (Sampling)\nChain 2:                0.027 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 0 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.012 seconds (Warm-up)\nChain 3:                0.014 seconds (Sampling)\nChain 3:                0.026 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 0 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.013 seconds (Warm-up)\nChain 4:                0.013 seconds (Sampling)\nChain 4:                0.026 seconds (Total)\nChain 4: \n\n\nThe output you see is just an overview of the four parallel Markov chains, with an indication of how long it took for reach chain to run through all iterations. Notice that Stan displays which iterations are Warmup (the first half for each chain) versus those used for Sampling from the posterior.\nJust for reference, the code chunk below shows how to use a .stan file instead of a string for the Stan model code. This file beta_binom.stan is available on Canvas in the demos/week9 folder. You will need to make sure the file path is correctly specified:\n\nbeta_binomial_sim &lt;- stan(file = \"beta_binom.stan\", \n                          data = list(Y = 33), \n                          chains = 4, iter = 5000 * 2, \n                          seed = 2024)\n\nIn general, it is better practice write your Stan code in separate scripts since they can become quite complex (depending on your model)."
  },
  {
    "objectID": "demos/14-intro-stan.html#viewing-the-posterior-simulations",
    "href": "demos/14-intro-stan.html#viewing-the-posterior-simulations",
    "title": "Lecture 15: Introduction to Stan",
    "section": "Viewing the posterior simulations",
    "text": "Viewing the posterior simulations\nSimilar to the manual trace plot we created with the Metropolis-Hastings algorithm, we can create a trace plot for our Stan posterior samples. The easiest way to do this is with the bayesplot package created by the Stan team via the mcmc_trace() function which creates a trace plot with lines for each of the constructed Markov chains:\n\nlibrary(tidyverse)\nlibrary(bayesplot)\n\n# Display the trace plot:\nmcmc_trace(beta_binomial_sim, \n           # What are the parameters? Just pi here\n           pars = \"pi\", \n           # Modify the size of the lines\n           size = 0.5) +\n  # I changed the color scale and modified the theme:\n  scale_color_viridis_d() +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can also view the posterior distribution approximation (by combining the four chains post burn-in samples) via a couple different functions such as mcmc_hist():\n\nmcmc_hist(beta_binomial_sim, pars = \"pi\") + \n  # Add y-axis back\n  yaxis_text(TRUE) + \n  ylab(\"count\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAs well as mcmc_dens(), where the true posterior density is overlaid on top in red:\n\nmcmc_dens(beta_binomial_sim, pars = \"pi\") + \n  yaxis_text(TRUE) + \n  stat_function(fun = dbeta, args = list(78.9, 120.7),\n                color = \"red\") + \n  ylab(\"density\")\n\n\n\n\n\n\n\n\nWe can see that the posterior approximation is pretty close to the true posterior density, with just a slight difference in the center relative to the true red line. Otherwise, this is a pretty solid approximation that we should feel comfortable using.\nWe can easily create a tidy table of the posterior sample using the as.data.frame() function with the parameters we want as input in pars. In this case, we only want the pi parameter (and can ignore the log-posterior values that are reported) and then turn it into a tbl object for ease. By default, this concatenates the samples from the four different Markov chains resulting in a complete table of 20,000 rows:\n\nposterior_sample &lt;- as.data.frame(beta_binomial_sim, pars = \"pi\") |&gt;\n  as_tibble()\n\nposterior_sample\n\n# A tibble: 20,000 × 1\n      pi\n   &lt;dbl&gt;\n 1 0.408\n 2 0.340\n 3 0.367\n 4 0.419\n 5 0.392\n 6 0.323\n 7 0.355\n 8 0.412\n 9 0.379\n10 0.383\n# ℹ 19,990 more rows\n\n\nUsing this sample, we can proceed as before in visualizing the distribution with our own code:\n\nposterior_sample |&gt;\n  ggplot(aes(x = pi)) +\n  geom_histogram(aes(y = after_stat(density))) +\n  stat_function(fun = dbeta, args = list(78.9, 120.7),\n                color = \"red\") + \n  scale_x_continuous(limits = c(0, 1)) +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nAnd also compute relevant quantities about the posterior distribution:\n\n# Compute various summaries of posterior sample:\nposterior_sample |&gt; \n  summarize(posterior_mean = mean(pi), \n            posterior_median = median(pi),\n            # Convenient function for mode:\n            posterior_mode = bayesrules::sample_mode(pi),\n            # 95% credible interval:\n            lower_95 = quantile(pi, 0.025),\n            upper_95 = quantile(pi, 0.975))\n\n# A tibble: 1 × 5\n  posterior_mean posterior_median posterior_mode lower_95 upper_95\n           &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1          0.395            0.395          0.397    0.328    0.465\n\n\n(You can see that the above values are slightly different than the truth that was seen in posterior_approx.qmd.)"
  },
  {
    "objectID": "demos/14-intro-stan.html#diagnostics",
    "href": "demos/14-intro-stan.html#diagnostics",
    "title": "Lecture 15: Introduction to Stan",
    "section": "Diagnostics",
    "text": "Diagnostics\nBefore you use the posterior samples for inference tasks, you should check diagnostics to assess the quality of your posterior simulation. There are a variety of different approaches to this, and we’ll cover just a small number of them in the rest of this demo.\nThe first thing to check is the trace plots of your Markov chains as visualized above. We want trace plots to look like random noise with no discernible patterns, such as the examples in this demo. We’ll discuss problematic traces in lecture.\nSimilar to displaying the trace plots with lines for each Markov chain, we can also compare the distributions for each Markov chain separately with overlaid densities as displayed below:\n\nmcmc_dens_overlay(beta_binomial_sim, pars = \"pi\") +\n  scale_color_viridis_d() +\n  theme_bw()\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\nWe want stability across the separate chains, with each distribution appearing similar to each other. We do not observe any problems in this case, with each Markov chain displaying distributions that clearly overlap with shared characteristics.\nAdditionally, we can also compute the \\(\\hat{R}\\)-ratio to assess if the variability in the parameter values with all Markov chains combined is greater than the variability within each chain:\n\nrhat(beta_binomial_sim, pars = \"pi\")\n\n[1] 1.000432\n\n\nWe would be concerned if this value was noticeably larger than 1 (although 1.05 is considered the threshold for concern). The above value is close enough to 1 to indicate that the simulation is stable - with consistent posterior approximations across the four chains.\nDespite the fact that Markov chain samples are inherently dependent on the previous value, we want them to behave like independent samples to have a better approximation of the posterior distribution. One way to assess this is with an autocorrelation plot, that observes the correlation between the Markov chain values at various sized lags. We can easily view the autocorrelations for each chain using mcmc_acf():\n\nmcmc_acf(beta_binomial_sim, pars = \"pi\")\n\n\n\n\n\n\n\n\nHere we see that the autocorrelation with lag-0 is 1, which is expected since that is just comparing a value with itself. Then with lag-1 the correlation drops to 0.5, and then shortly reaches 0 by just 5 steps in the chain across the four chains. This behavior is ideal, indicating that our samples are fast mixing: the samples are moving around the posterior distribution quickly.\nIn addition to the autocorrelation plots, we can compute the effective sample size ratio which is a ratio between the effective sample size of the chain divided by the actual sample size:\n\nneff_ratio(beta_binomial_sim, pars = \"pi\")\n\n[1] 0.3364141\n\n\nWe would be concerned by a really low value, such as 0.1 which is considered a problematic threshold. In this case, our value is not worrisome and we would be comfortable relying on our posterior samples for inference tasks."
  },
  {
    "objectID": "demos/09-random-effects-uncertainty.html",
    "href": "demos/09-random-effects-uncertainty.html",
    "title": "Lecture 10: Uncertainty about random effects",
    "section": "",
    "text": "The purpose of this demo is to walk through how to access and generate different estimates of uncertainty about the random effects from multilevel models. This will be our last demo with the NFL passing data, as we’ll consider the random effects in the context of modeling completion probability. As a reminder, you can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas in the demos/week3 folder.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;\n\n\nIf you notice, there is an error in this dataset where there are receivers marked as NA_NA. We need to remove these receivers before continuing on:\n\nnfl_passing_data &lt;- nfl_passing_data |&gt;\n  filter(receiver_name_id != \"NA_NA\")"
  },
  {
    "objectID": "demos/09-random-effects-uncertainty.html#introduction",
    "href": "demos/09-random-effects-uncertainty.html#introduction",
    "title": "Lecture 10: Uncertainty about random effects",
    "section": "",
    "text": "The purpose of this demo is to walk through how to access and generate different estimates of uncertainty about the random effects from multilevel models. This will be our last demo with the NFL passing data, as we’ll consider the random effects in the context of modeling completion probability. As a reminder, you can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas in the demos/week3 folder.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;\n\n\nIf you notice, there is an error in this dataset where there are receivers marked as NA_NA. We need to remove these receivers before continuing on:\n\nnfl_passing_data &lt;- nfl_passing_data |&gt;\n  filter(receiver_name_id != \"NA_NA\")"
  },
  {
    "objectID": "demos/09-random-effects-uncertainty.html#random-effects-for-passers-receivers-and-defenses",
    "href": "demos/09-random-effects-uncertainty.html#random-effects-for-passers-receivers-and-defenses",
    "title": "Lecture 10: Uncertainty about random effects",
    "section": "Random effects for passers, receivers, and defenses",
    "text": "Random effects for passers, receivers, and defenses\nFor this demo, we’ll consider the crossed effects model from earlier in the week which involved random intercepts for passers, receivers, and defenses:\n\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nfull_pass_glmm &lt;- glmer(complete_pass ~ air_yards + (1 | passer_name_id) +\n                          (1 | receiver_name_id) + (1 | defteam),\n                        family = binomial, data = nfl_passing_data)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\n\nsummary(full_pass_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: \ncomplete_pass ~ air_yards + (1 | passer_name_id) + (1 | receiver_name_id) +  \n    (1 | defteam)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 40076.5  40118.7 -20033.2  40066.5    34491 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2047 -0.9825  0.5218  0.6349  3.9676 \n\nRandom effects:\n Groups           Name        Variance Std.Dev.\n receiver_name_id (Intercept) 0.01917  0.13846 \n passer_name_id   (Intercept) 0.02349  0.15325 \n defteam          (Intercept) 0.00393  0.06269 \nNumber of obs: 34496, groups:  \nreceiver_name_id, 634; passer_name_id, 136; defteam, 32\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.250184   0.029507   42.37   &lt;2e-16 ***\nair_yards   -0.065060   0.001288  -50.51   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.360\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\n\n\nWe can access the full table of random effects using the broom.mixed package again. The following code chunk extracts the three groups of random effects, as designated by the group column:\n\nlibrary(broom.mixed)\n\nWarning: package 'broom.mixed' was built under R version 4.2.3\n\ngroup_raneff &lt;- tidy(full_pass_glmm, effects = \"ran_vals\")\n# View the dataset\ngroup_raneff\n\n# A tibble: 802 × 6\n   effect   group            level                 term       estimate std.error\n   &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt;                 &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n 1 ran_vals receiver_name_id A.Abdullah_00-0032104 (Intercep…  8.01e-2     0.125\n 2 ran_vals receiver_name_id A.Armah_00-0033296    (Intercep…  1.07e-2     0.138\n 3 ran_vals receiver_name_id A.Bachman_00-0035602  (Intercep…  1.87e-2     0.138\n 4 ran_vals receiver_name_id A.Barner_00-0039793   (Intercep…  2.23e-2     0.131\n 5 ran_vals receiver_name_id A.Beck_00-0034959     (Intercep…  7.95e-4     0.135\n 6 ran_vals receiver_name_id A.Brown_00-0035676    (Intercep…  7.43e-2     0.105\n 7 ran_vals receiver_name_id A.Cooper_00-0031544   (Intercep… -5.12e-2     0.103\n 8 ran_vals receiver_name_id A.Dillon_00-0036265   (Intercep…  5.47e-3     0.133\n 9 ran_vals receiver_name_id A.Dulin_00-0035021    (Intercep… -3.37e-2     0.136\n10 ran_vals receiver_name_id A.Ekeler_00-0033699   (Intercep… -7.71e-2     0.119\n# ℹ 792 more rows\n\n\nThe first type of uncertainty we’ll consider is based on the theoretical model from lecture, which are effectively conditional standard deviation estimates (under the assumptions that the fixed effects and random effect variances are correct). In the group_raneff table above, this corresponds to the std.error column. We can quickly use this dataset to make a panel of plots for each random effect, displaying the estimates +/- one standard error to quickly see how they vary across the groups:\n\ngroup_raneff |&gt;\n  ggplot(aes(x = level, y = estimate)) +\n  geom_point(alpha = 0.5) +\n  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error),\n                alpha = 0.5) +\n  # Add line at 0 on top:\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  facet_wrap(~group, ncol = 3, scales = \"free_x\") +\n  theme_bw() +\n  # Remove the x axis labels and ticks for each group level \n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        panel.grid = element_blank())\n\n\n\n\n\n\n\n\nFrom this, you quickly observe the different levels of variation across the three groups: defteam, passer_name_id, and receiver_name_id, with receiver_name_id displaying the greatest variation. This is consistent with the variance estimate in the summary output of the model. If we wanted to rely on this model and its assumptions, we could use the standard errors to get a sense of which levels of the random effects are noticeably different from 0 (either above or below)."
  },
  {
    "objectID": "demos/09-random-effects-uncertainty.html#bootstrapping-random-effects",
    "href": "demos/09-random-effects-uncertainty.html#bootstrapping-random-effects",
    "title": "Lecture 10: Uncertainty about random effects",
    "section": "Bootstrapping random effects",
    "text": "Bootstrapping random effects\nWe’re now going to proceed to quantify the uncertainty of the random effect estimates using bootstrapping (i.e., resampling). This procedure requires careful recognition of the sources of variability in player and team performances. We can NOT simply resample pass attempts to construct a new dataset. If we think about the course of a football season, the schedule is fixed. In other words, any resampling procedure we consider must preserve the schedule that each player and team plays in each resampled dataset - with the same number of games and opponents. If we naively resampled at the observation level without thinking about this structure, we would observe impossible datasets that do not reflect the target source of variability that we’re interested in.\nInstead, we need to resample the plays that take place within a particular game/match-up between two teams. You can think of this as attempting to replay a game over again and observing different performances and outcomes. But given the nature of football plays, we should not just resample plays within games either! Instead, we want our simulated datasets to capture the wide range of context that different plays can take place in. The simplest way to capture this structure, as well as any dependency between plays, is by resampling collections of plays at the drive level. A single iteration of resampling the dataset involves: going through each game and resampling the drives for each team (to ensure that each team has the same number of drives as observed). There are other ways to resample, this is just one approach that tries to account for the game structure.\nIn order to implement this, we first need to set-up a dataset of the games and drives for each team. One efficient way to do this, is to construct a nested dataset at the game-team-drive level. A nested dataset will contain “one row” for game-team-drive combination, but within that “row” will be all plays corresponding to that game-team-drive. The following code chunk uses the nest() function to collapse the nfl_passing_data into a dataset at this combination level. (NOTE: this may not account for all possible drives in case there are drives without pass attempts - however I’m just being lazy in the set-up of this to only rely on the nfl_passing_data in this demo.) This will make the process of resampling plays much easier:\n\ngame_team_drives &lt;- nfl_passing_data |&gt;\n  # First group by the three variables of interest:\n  group_by(game_id, posteam, drive) |&gt;\n  # Now nest the data\n  nest() |&gt;\n  ungroup()\ngame_team_drives\n\n# A tibble: 10,585 × 4\n   game_id         drive posteam data             \n   &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;   &lt;list&gt;           \n 1 2023_01_ARI_WAS     1 WAS     &lt;tibble [6 × 14]&gt;\n 2 2023_01_ARI_WAS     2 ARI     &lt;tibble [3 × 14]&gt;\n 3 2023_01_ARI_WAS     3 WAS     &lt;tibble [3 × 14]&gt;\n 4 2023_01_ARI_WAS     4 ARI     &lt;tibble [4 × 14]&gt;\n 5 2023_01_ARI_WAS     5 WAS     &lt;tibble [1 × 14]&gt;\n 6 2023_01_ARI_WAS     6 ARI     &lt;tibble [2 × 14]&gt;\n 7 2023_01_ARI_WAS     7 WAS     &lt;tibble [3 × 14]&gt;\n 8 2023_01_ARI_WAS     9 WAS     &lt;tibble [2 × 14]&gt;\n 9 2023_01_ARI_WAS    10 ARI     &lt;tibble [3 × 14]&gt;\n10 2023_01_ARI_WAS    11 WAS     &lt;tibble [3 × 14]&gt;\n# ℹ 10,575 more rows\n\n\nUsing this dataset, we are now ready to bootstrap team drives within games to generate distributions of the passer, receiver, and defense effects. The following code chunk performs this process with \\(B = 100\\) bootstrapped iterations. NOTE: this will take some time to run and I hid the repeated observed warning messages that pop-up when fitting this model!\n\n# Number of bootstrap iterations:\nN_BOOT &lt;- 100\n\nbootstrap_random_effects &lt;-\n  map_dfr(1:N_BOOT,\n          function(boot_i) {\n            \n            # First resample drives by teams within games\n            boot_game_team_drives &lt;- game_team_drives |&gt;\n              group_by(game_id, posteam) |&gt;\n              # Sample with replacement\n              sample_n(n(), replace = TRUE) |&gt;\n              # ungroup and unnest\n              ungroup() |&gt;\n              unnest(cols = data)\n            \n            # Now fit the model\n            boot_glmm &lt;- glmer(complete_pass ~ air_yards + (1 | passer_name_id) +\n                          (1 | receiver_name_id) + (1 | defteam), \n                               data = boot_game_team_drives, \n                          family = binomial)\n            \n            # Store the random effects:\n            boot_raneff &lt;- tidy(boot_glmm, effects = \"ran_vals\")\n\n            # Add a column for the bootstrap iteration and return\n            boot_raneff |&gt;\n              mutate(boot = boot_i)\n          })\n\nWe now have a dataset with 100 estimates for each of the different random effects (potentially fewer than 100 for some passers and receivers that might have been dropped in certain iterations due to their drives not being selected). We can proceed to inspect the distribution of the random effects beyond just computing standard errors. The following code chunk first sets up a dataset with the medians of the bootstrapped values which we’ll then use to select the top passers and receivers, as well as provide the ordering for the factors in relevant graphics displaying the distributions:\n\nbootstrap_summary &lt;- bootstrap_random_effects |&gt;\n  group_by(group, level) |&gt;\n  summarize(med_intercept = median(estimate, na.rm = TRUE),\n            n_sims = n(),\n            .groups = \"drop\")\n\n# Defenses in order:\ndef_table &lt;- bootstrap_summary |&gt;\n  filter(group == \"defteam\") |&gt;\n  mutate(level = fct_reorder(level, med_intercept))\n\n# Table of the top 10 passers\ntop_passers &lt;- bootstrap_summary |&gt;\n  filter(group == \"passer_name_id\") |&gt;\n  slice_max(order_by = med_intercept, n = 10) |&gt;\n  mutate(level = fct_reorder(level, med_intercept))\n\n# Top 10 receivers\ntop_receivers &lt;- bootstrap_summary |&gt;\n  filter(group == \"receiver_name_id\") |&gt;\n  slice_max(order_by = med_intercept, n = 10) |&gt;\n  mutate(level = fct_reorder(level, med_intercept))\n\nNext, we’ll create displays of the top passers, receivers, and all of the defenses using ridge plots (which can be constructed with ggridges - this is a great way to visualize distributions across many levels of a categorical variable). First, we create the plot for the top passers:\n\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.2.3\n\nbootstrap_random_effects |&gt;\n  filter(group == \"passer_name_id\",\n         level %in% top_passers$level) |&gt;\n  # Reorder them by the median order\n  mutate(level = factor(level, levels = levels(top_passers$level))) |&gt;\n  ggplot(aes(x = estimate, y = level)) +\n  # Display the ridges with the median line\n  geom_density_ridges(quantile_lines = TRUE,\n                      quantiles = 0.5,\n                      rel_min_height = 0.01) +\n  labs(x = \"Passer random effect\", y = \"Passer name\") +\n  theme_bw()\n\nPicking joint bandwidth of 0.0261\n\n\n\n\n\n\n\n\n\nAnd then for top receivers:\n\nbootstrap_random_effects |&gt;\n  filter(group == \"receiver_name_id\",\n         level %in% top_receivers$level) |&gt;\n  # Reorder them by the median order\n  mutate(level = factor(level, levels = levels(top_receivers$level))) |&gt;\n  ggplot(aes(x = estimate, y = level)) +\n  # Display the ridges with the median line\n  geom_density_ridges(quantile_lines = TRUE,\n                      quantiles = 0.5,\n                      rel_min_height = 0.01) +\n  labs(x = \"Receiver random effect\", y = \"Receiver name\") +\n  theme_bw()\n\nPicking joint bandwidth of 0.041\n\n\n\n\n\n\n\n\n\nAnd finally for the defenses:\n\nbootstrap_random_effects |&gt;\n  filter(group == \"defteam\") |&gt;\n  # Reorder them by the median order\n  mutate(level = factor(level, levels = levels(def_table$level))) |&gt;\n  ggplot(aes(x = estimate, y = level)) +\n  # Display the ridges with the median line\n  geom_density_ridges(quantile_lines = TRUE,\n                      quantiles = 0.5,\n                      rel_min_height = 0.01) +\n  labs(x = \"Defense random effect\", y = \"Team\") +\n  theme_bw()\n\nPicking joint bandwidth of 0.0139"
  },
  {
    "objectID": "demos/06-varying-ints-slopes.html",
    "href": "demos/06-varying-ints-slopes.html",
    "title": "Lecture 7: Varying intercepts and slopes",
    "section": "",
    "text": "The purpose of this demo is to walk through fitting and interpreting the output of varying intercepts and slopes multilevel models in the context of modeling pass completion probability. We’ll continue to use a dataset corresponding to pass attempts in NFL regular season games during the 2023 and 2024 seasons from last week. You can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas in the demos/week3 folder.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/06-varying-ints-slopes.html#introduction",
    "href": "demos/06-varying-ints-slopes.html#introduction",
    "title": "Lecture 7: Varying intercepts and slopes",
    "section": "",
    "text": "The purpose of this demo is to walk through fitting and interpreting the output of varying intercepts and slopes multilevel models in the context of modeling pass completion probability. We’ll continue to use a dataset corresponding to pass attempts in NFL regular season games during the 2023 and 2024 seasons from last week. You can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas in the demos/week3 folder.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/06-varying-ints-slopes.html#initial-model-varying-intercepts-only",
    "href": "demos/06-varying-ints-slopes.html#initial-model-varying-intercepts-only",
    "title": "Lecture 7: Varying intercepts and slopes",
    "section": "Initial model: varying intercepts only",
    "text": "Initial model: varying intercepts only\nThe first model we will consider is an unconditional means or random intercepts model, i.e., we do not include any predictor variables at either level of the data (pass attempts or QBs).\nIn order to fit this model, we will use the lme4 package. The code chunk below demonstrates how to fit a logistic regression model with random intercepts for QBs using the glmer() function. Note that in the lme4 model syntax, we specify random effects via terms inside parentheses (). In this example, we specify that the model will have random intercepts (or varying intercepts) for QBs via (1 | passer_name_id) where you can think of the 1 denoting an intercept with the | passer_name_id indicating the intercept will vary by passer_name_id. We can display the summary() output for this generalized linear multilevel model (GLMM) in the usual manner:\n\nlibrary(lme4)\ninit_glmm &lt;- glmer(complete_pass ~ (1 | passer_name_id),\n                   family = binomial, data = nfl_passing_data)\n\nsummary(init_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ (1 | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 46485.3  46502.3 -23240.7  46481.3    35985 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.5198 -1.3170  0.6966  0.7439  0.8887 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.02014  0.1419  \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.58502    0.02144   27.29   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFor this model, we do not see the reported effects for the individual QBs (we will return to that later). Instead, we observe the reported variance for the QB distribution (under Random effects as Variance) as well as the usual intercept (under Fixed effects)."
  },
  {
    "objectID": "demos/06-varying-ints-slopes.html#intraclass-correlation-coefficient",
    "href": "demos/06-varying-ints-slopes.html#intraclass-correlation-coefficient",
    "title": "Lecture 7: Varying intercepts and slopes",
    "section": "Intraclass correlation coefficient",
    "text": "Intraclass correlation coefficient\nWhile the above displays the output for a logistic regression model with random intercepts, for comparison we will explore the output for modeling a continuous response: expected points added (EPA). If we decide to assume that the Level One variance of EPA follows a Normal distribution, then we can model the data using the lmer() function instead of glmer() with the same syntax for the random intercepts. Note: the code chunk below sets REML = FALSE to ensure we are using the maximum likelihood estimate, which is something we’ll return to later.\n\nepa_lmm &lt;- lmer(epa ~ (1 | passer_name_id), \n                data = nfl_passing_data, REML = FALSE)\n\nsummary(epa_lmm)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: epa ~ (1 | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n133282.7 133308.1 -66638.3 133276.7    35984 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-8.3024 -0.5206 -0.1421  0.5542  5.6369 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.01431  0.1196  \n Residual                   2.37037  1.5396  \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  0.09255    0.01689    5.48\n\n\nUnlike the logistic regression model, we now have two variance estimates in the Random effects section: one for the QBs and another the Residual which corresponds to the within-QB variability. We can extract the relevant variances from this model using the VarCorr() function in lme4:\n\n# The following is a way to print out both the Variance and Std Dev:\nprint(VarCorr(epa_lmm), comp = c(\"Variance\", \"Std.Dev.\"), digits = 4)\n\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.01431  0.1196  \n Residual                   2.37037  1.5396  \n\n\nFrom this, we can also compute the intraclass correlation coefficient (ICC) for the random intercepts. You could do this manually by just grabbing the variance values from the summary:\n\n0.01431 / (0.01431 + 2.37037)\n\n[1] 0.006000805\n\n\nOr by converting the VarCorr() output to a tibble, which gives us the variances and then provides an easy way to compute the ICC values for each random effect (note the residual ICC row is NOT an ICC value):\n\nVarCorr(epa_lmm) |&gt; \n  as_tibble() |&gt; \n  mutate(icc = vcov / sum(vcov)) |&gt; \n  dplyr::select(grp, icc)\n\n# A tibble: 2 × 2\n  grp                icc\n  &lt;chr&gt;            &lt;dbl&gt;\n1 passer_name_id 0.00600\n2 Residual       0.994  \n\n\nReturning back to model for compleition probability: in order to compute the ICC for the logistic regression model we need to manually compute the ICC based on the variance for errors that following a Logistic distribution with a mean of 0 and variance of \\(\\pi^2 / 3\\). This comes from a latent response model representation of the logistic regression model, which allows us to replace the residual variance from the lmer() model with \\(\\pi^2 / 3\\) for the logistic regression model fit with glmer().\nYou can compute the ICC value for the pass completion probability model manually, based on the summary output:\n\n0.02014 / (0.02014 + (pi^2 / 3))\n\n[1] 0.006084577\n\n\nOr by grabbing the variance term from the model in a way that is similar to the code from before for the lmer() model that relies on using VarCorr():\n\nVarCorr(init_glmm) |&gt;\n  as_tibble() |&gt;\n  # Note the use of sum(vcov) to work later with multiple levels\n  mutate(icc = vcov / (sum(vcov) + (pi^2 / 3))) |&gt;\n  dplyr::select(grp, icc)\n\n# A tibble: 1 × 2\n  grp                icc\n  &lt;chr&gt;            &lt;dbl&gt;\n1 passer_name_id 0.00608"
  },
  {
    "objectID": "demos/06-varying-ints-slopes.html#next-step-including-covariates-and-varying-slopes",
    "href": "demos/06-varying-ints-slopes.html#next-step-including-covariates-and-varying-slopes",
    "title": "Lecture 7: Varying intercepts and slopes",
    "section": "Next step: including covariates and varying slopes",
    "text": "Next step: including covariates and varying slopes\nThe next model to consider is one that accounts for Level One covariates. For instance, we can account for the air yards of the pass attempt in our model as a fixed effect:\n\nair_glmm &lt;- glmer(complete_pass ~ air_yards + (1 | passer_name_id),\n                  family = binomial, data = nfl_passing_data)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\n\nsummary(air_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ air_yards + (1 | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43702.9  43728.3 -21848.4  43696.9    35984 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7393 -1.0676  0.5669  0.6809  3.6699 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.02087  0.1445  \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.070637   0.024260   44.13   &lt;2e-16 ***\nair_yards   -0.059134   0.001196  -49.46   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.406\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\n\n\nCompared to before, we now observe the Fixed effects estimates for the air_yards variable, as well as a slight change in the variance estimate for the QB random intercepts. For comparison purposes, the following code chunk displays the model summary output for the glm() without random intercepts:\n\nair_glm &lt;- glm(complete_pass ~ air_yards,\n               family = binomial, data = nfl_passing_data)\n\nsummary(air_glm)\n\n\nCall:\nglm(formula = complete_pass ~ air_yards, family = binomial, data = nfl_passing_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1115  -1.2496   0.7541   0.8767   2.1930  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.11219    0.01529   72.75   &lt;2e-16 ***\nair_yards   -0.05900    0.00119  -49.57   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46543  on 35986  degrees of freedom\nResidual deviance: 43746  on 35985  degrees of freedom\nAIC: 43750\n\nNumber of Fisher Scoring iterations: 4\n\n\nRelative to the output from the glmer() model, we can see that the fixed effect coefficient estimates change slightly with larger standard errors in the glmer() model.\nInstead of modeling completion probability with varying intercepts, we can instead use varying slopes (aka random slopes) which allows the coefficient for a variable of interest to vary with each QB. This is similar to thinking about the interaction between categorical variables and quantitative variables, except with the assumption that the effect for the levels of a categorical variable follow some distribution.\nIn terms of the lme4 syntax, in order to specify random slopes WITHOUT including random intercepts, you need to use (0 + air_yards | passer_name_id) in the formula - which you can think of saying: vary the slopes for air_yards by passer_name_id but do not touch the intercept term (hence the 0 instead of 1).\nThe following code chunk fits and reports the summary for the random slopes model:\n\nair_slopes_glmm &lt;- glmer(complete_pass ~ 1 + air_yards + (0 + air_yards | passer_name_id),\n                         family = binomial, data = nfl_passing_data)\n\nsummary(air_slopes_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ 1 + air_yards + (0 + air_yards | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43700.2  43725.6 -21847.1  43694.2    35984 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0276 -1.0727  0.5727  0.6774  4.8845 \n\nRandom effects:\n Groups         Name      Variance  Std.Dev.\n passer_name_id air_yards 0.0001159 0.01077 \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.114822   0.015335   72.70   &lt;2e-16 ***\nair_yards   -0.062080   0.001885  -32.94   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.429\n\n\nUnlike the random intercepts model from before, we can no longer report the ICC value with random slopes. However, we can still view the random slopes variance, as well as make comparisons across model fits using the AIC or BIC that are reported near the top of the summary. Relative to the other models, this random slopes model appear to display the best AIC and BIC values (lower is better)."
  },
  {
    "objectID": "demos/06-varying-ints-slopes.html#both-varying-intercepts-and-varying-slopes",
    "href": "demos/06-varying-ints-slopes.html#both-varying-intercepts-and-varying-slopes",
    "title": "Lecture 7: Varying intercepts and slopes",
    "section": "Both: Varying intercepts and varying slopes",
    "text": "Both: Varying intercepts and varying slopes\nNow that we built up fitting of varying intercepts and varying slopes, we can return to the model in our previous demo which consists of both. In terms of the lme4 syntax, we can specify a model with both varying intercepts and slopes with (air_yards | passer_name_id):\n\nair_both_glmm &lt;- glmer(complete_pass ~ air_yards + (air_yards | passer_name_id),\n                       family = binomial, data = nfl_passing_data)\n\nboundary (singular) fit: see help('isSingular')\n\nsummary(air_both_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ air_yards + (air_yards | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43704.2  43746.6 -21847.1  43694.2    35982 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0276 -1.0727  0.5727  0.6774  4.8845 \n\nRandom effects:\n Groups         Name        Variance  Std.Dev. Corr\n passer_name_id (Intercept) 0.0000000 0.00000      \n                air_yards   0.0001159 0.01077   NaN\nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.114817   0.016567   67.29   &lt;2e-16 ***\nair_yards   -0.062080   0.001886  -32.91   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.412\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nCompared to the previous model, we see that bot the AIC and BIC are worse (i.e., higher values). There are supposed to be two variances reported for both the random intercepts and slopes under the Random effects section, along with the estimate for the correlation between the random effects under Corr. However, the variance for the random intercepts is reported to be 0 and the resulting correlation between the intercepts and slopes is missing!\nWe could make the assumption that the correlation between the random effects is zero and explicitly force that in our model (meaning we would not have to estimate one parameter from the last model). In terms of the code syntax, this requires inputting the random effects separately for the intercepts (1 | passer_name_id) and slopes (0 + air_yards | passer_name_id). The code chunk below fits this model with uncorrelated random intercept and slopes:\n\nair_both_indep_glmm &lt;- \n  glmer(complete_pass ~ 1 + (1 | passer_name_id) + air_yards + (0 + air_yards | passer_name_id),\n        family = binomial, data = nfl_passing_data)\n\nsummary(air_both_indep_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: \ncomplete_pass ~ 1 + (1 | passer_name_id) + air_yards + (0 + air_yards |  \n    passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43685.0  43719.0 -21838.5  43677.0    35983 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7454 -1.0687  0.5667  0.6798  4.3269 \n\nRandom effects:\n Groups           Name        Variance  Std.Dev.\n passer_name_id   (Intercept) 1.452e-02 0.120510\n passer_name_id.1 air_yards   7.944e-05 0.008913\nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.083996   0.022897   47.34   &lt;2e-16 ***\nair_yards   -0.060852   0.001741  -34.95   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.384\n\n\nFrom the output, this results in a noticeably different model! The variance for the random intercepts is no longer estimated to be 0 and is now even estimated to be larger than the variance for the random slopes. Notice that the correlation between the random effects is no longer reported, since it is assumed to be 0. We can also see that this model has the best AIC and BIC values among the considered models in this demo. This result should be an indication to you that we often need to be careful with the default implementation of software since they often come with model assumptions that may or may not be ideal."
  },
  {
    "objectID": "demos/06-varying-ints-slopes.html#recap",
    "href": "demos/06-varying-ints-slopes.html#recap",
    "title": "Lecture 7: Varying intercepts and slopes",
    "section": "Recap:",
    "text": "Recap:\n\nYou have seen how to fit multilevel models with varying intercepts and varying slopes, either separately or at the same time. You just need to pay attention to the syntax regarding the random effects in parentheses.\nThe sjstats package is a resource with a variety of other built-in evaluation metrics for lme4 models."
  },
  {
    "objectID": "demos/02-calibration-cv.html",
    "href": "demos/02-calibration-cv.html",
    "title": "Lecture 3: Calibration and Cross-Validation",
    "section": "",
    "text": "The goal of this demo is to walk through the process of evaluating logistic regression predicted probability estimates with calibration, as well as a demonstration of implementing cross-validation. In this demo, we’ll again use a dataset of NHL shot attempts during the 2023-2024 NHL season (accessed via hockeyR) to evaluate an expected goals model for hockey. The following code chunk reads in the data and displays a subset of the data:\n\nlibrary(tidyverse)\n\nmodel_nhl_shot_data &lt;- read_csv(here::here(\"data/model_nhl_shot_data.csv\"))\nhead(model_nhl_shot_data)\n\n# A tibble: 6 × 11\n    game_id period shooting_player shooting_team goalie_name goalie_team x_fixed\n      &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;\n1    2.02e9      1 Bryan Rust      Pittsburgh P… Petr Mrazek Chicago Bl…     -51\n2    2.02e9      1 Kevin Korchins… Chicago Blac… Tristan Ja… Pittsburgh…     -55\n3    2.02e9      1 Noel Acciari    Pittsburgh P… Petr Mrazek Chicago Bl…      75\n4    2.02e9      1 Wyatt Kaiser    Chicago Blac… Tristan Ja… Pittsburgh…     -39\n5    2.02e9      1 Alex Vlasic     Chicago Blac… Tristan Ja… Pittsburgh…     -36\n6    2.02e9      1 Marcus Petters… Pittsburgh P… Petr Mrazek Chicago Bl…      32\n# ℹ 4 more variables: y_fixed &lt;dbl&gt;, shot_distance &lt;dbl&gt;, shot_angle &lt;dbl&gt;,\n#   is_goal &lt;dbl&gt;"
  },
  {
    "objectID": "demos/02-calibration-cv.html#introduction",
    "href": "demos/02-calibration-cv.html#introduction",
    "title": "Lecture 3: Calibration and Cross-Validation",
    "section": "",
    "text": "The goal of this demo is to walk through the process of evaluating logistic regression predicted probability estimates with calibration, as well as a demonstration of implementing cross-validation. In this demo, we’ll again use a dataset of NHL shot attempts during the 2023-2024 NHL season (accessed via hockeyR) to evaluate an expected goals model for hockey. The following code chunk reads in the data and displays a subset of the data:\n\nlibrary(tidyverse)\n\nmodel_nhl_shot_data &lt;- read_csv(here::here(\"data/model_nhl_shot_data.csv\"))\nhead(model_nhl_shot_data)\n\n# A tibble: 6 × 11\n    game_id period shooting_player shooting_team goalie_name goalie_team x_fixed\n      &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;\n1    2.02e9      1 Bryan Rust      Pittsburgh P… Petr Mrazek Chicago Bl…     -51\n2    2.02e9      1 Kevin Korchins… Chicago Blac… Tristan Ja… Pittsburgh…     -55\n3    2.02e9      1 Noel Acciari    Pittsburgh P… Petr Mrazek Chicago Bl…      75\n4    2.02e9      1 Wyatt Kaiser    Chicago Blac… Tristan Ja… Pittsburgh…     -39\n5    2.02e9      1 Alex Vlasic     Chicago Blac… Tristan Ja… Pittsburgh…     -36\n6    2.02e9      1 Marcus Petters… Pittsburgh P… Petr Mrazek Chicago Bl…      32\n# ℹ 4 more variables: y_fixed &lt;dbl&gt;, shot_distance &lt;dbl&gt;, shot_angle &lt;dbl&gt;,\n#   is_goal &lt;dbl&gt;"
  },
  {
    "objectID": "demos/02-calibration-cv.html#creating-a-calibration-plot",
    "href": "demos/02-calibration-cv.html#creating-a-calibration-plot",
    "title": "Lecture 3: Calibration and Cross-Validation",
    "section": "Creating a calibration plot",
    "text": "Creating a calibration plot\nWe’ll start with the simple logistic regression model that is just a function of shot distance (shot_distance):\n\ninit_logit &lt;- glm(is_goal ~ shot_distance, data = model_nhl_shot_data,\n                  family = \"binomial\")\n\nUsing this model, we can get the predicted probabilities for each shot using the predict() function but with type = \"response\" as an input (otherwise the logit values are returned):\n\n# Add a column to the dataset with the predicted probabilities:\nmodel_nhl_shot_data &lt;- model_nhl_shot_data |&gt;\n  mutate(pred_prob = predict(init_logit, newdata = model_nhl_shot_data,\n                             type = \"response\"))\n\nWe can now construct the calibration plot by binning the predicted probabilities followed by computing the proportion estimates and standard errors for each of the bins. There are a number of different ways to construct the bins, the following code represents just one way of doing this process using the round() function. For simplicity, we construct bins using increments of 0.05. There are several steps here so make sure you read through the code comments!\nThe following code chunk first creates a dataset with the relevant values for the calibration plot:\n\ninit_calibration_data &lt;- model_nhl_shot_data |&gt;\n  # First bin the pred probs in increments of 0.05\n  mutate(bin_pred_prob = round(pred_prob / 0.05) * .05) |&gt;\n  # Group by bin_pred_prob:\n  group_by(bin_pred_prob) |&gt;\n  # Calculate the calibration results:\n  summarize(n_shots = n(),\n            # Observed proportion\n            bin_actual_prob = mean(is_goal),\n            # Compute the standard error based on the proportion and # shots\n            bin_se = sqrt((bin_actual_prob * (1 - bin_actual_prob)) / n_shots),\n            .groups = \"drop\") |&gt;\n  # Cap the intervals to be within 0 and 1\n  mutate(bin_upper = pmin(bin_actual_prob + 2 * bin_se, 1),\n         bin_lower = pmax(bin_actual_prob - 2 * bin_se, 0))\ninit_calibration_data\n\n# A tibble: 5 × 6\n  bin_pred_prob n_shots bin_actual_prob   bin_se bin_upper bin_lower\n          &lt;dbl&gt;   &lt;int&gt;           &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1          0      30281          0.0121 0.000629    0.0134    0.0109\n2          0.05   36884          0.0496 0.00113     0.0518    0.0473\n3          0.1    19214          0.0984 0.00215     0.103     0.0941\n4          0.15   11232          0.131  0.00319     0.138     0.125 \n5          0.2       23          0.652  0.0993      0.851     0.454 \n\n\nWe can see fairly large differences in the number of shots across the bins, which leads much wider intervals. Using this dataset, we can now create a calibration plot where we include the y = x line as reference:\n\ninit_calibration_data |&gt;\n  # Display pred probs along x and actual on y\n  ggplot(aes(x = bin_pred_prob, y = bin_actual_prob)) +\n  # Display as points \n  geom_point() +\n  # Add error bars based on standard errors:\n  geom_errorbar(aes(ymin = bin_lower, ymax = bin_upper)) + \n  #geom_smooth(method = \"loess\", se = FALSE) +\n  geom_abline(slope = 1, intercept = 0, \n              color = \"black\", linetype = \"dashed\") +\n  coord_equal() + \n  scale_x_continuous(limits = c(0,1)) + \n  scale_y_continuous(limits = c(0,1)) + \n  labs(x = \"Estimated goal probability\",\n       y = \"Observed goal frequency\") + \n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nYou may also see the number of observations in each bin mapped to the size of the points, but this is effectively already accounted for via the standard error intervals:\n\ninit_calibration_data |&gt;\n  ggplot(aes(x = bin_pred_prob, y = bin_actual_prob)) +\n  # Display as points with number of shots mapped to size\n  geom_point(aes(size = n_shots)) +\n  geom_errorbar(aes(ymin = bin_lower, ymax = bin_upper)) + \n  geom_abline(slope = 1, intercept = 0, \n              color = \"black\", linetype = \"dashed\") +\n  coord_equal() + \n  scale_x_continuous(limits = c(0,1)) + \n  scale_y_continuous(limits = c(0,1)) + \n  labs(size = \"Number of shot attempts\",\n       x = \"Estimated goal probability\",\n       y = \"Observed goal frequency\") + \n  theme_bw() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "demos/02-calibration-cv.html#cross-validation",
    "href": "demos/02-calibration-cv.html#cross-validation",
    "title": "Lecture 3: Calibration and Cross-Validation",
    "section": "Cross-validation",
    "text": "Cross-validation\nAs discussed in lecture, an expected goals model will likely be used to generate values for new shot attempts. This means we will need to take an existing model and generate predictions on new data. The alternative idea is to constantly refit the model after every single shot (or some determined batch) but that’s going to be computationally burdensome and tedious to manage. Instead, we should rely on evaluating the performance of our model based on out-of-sample performance. The most common way to do that is with \\(K\\)-fold cross-validation.\nBecause of the interesting structure of sports data, we can NOT randomly assign shots to folds. Instead, we must preserve the group structure and assign groups of observations together into the folds. For instance, in this example we will randomly assign games to folds thus ensuring that shots within the same game stay together. The following code chunk demonstrates how to first set-up a table containing only the game IDs, with 5-fold assignments and displays how many games are in each fold:\n\nset.seed(1979)\ngame_fold_table &lt;- tibble(game_id = unique(model_nhl_shot_data$game_id)) |&gt;\n  mutate(game_fold = sample(rep(1:5, length.out = n()), n()))\n\n# See how many games are in each fold:\ntable(game_fold_table$game_fold)\n\n\n  1   2   3   4   5 \n280 280 280 280 280 \n\n\nNext, we need to join the fold ids to the modeling data, so that each shot is assigned to a fold based on the game assignment:\n\nmodel_nhl_shot_data &lt;- model_nhl_shot_data |&gt; \n  left_join(game_fold_table, by = \"game_id\")\n\n# See how many shots are in each fold:\ntable(model_nhl_shot_data$game_fold)\n\n\n    1     2     3     4     5 \n19521 19754 19432 19434 19493 \n\n\nAnd finally, we can generate the holdout predictions for every shot attempt by iterating through each game fold. The following code chunk represents one way of generating the cross-validation predictions, but effectively it is just looping through the test folds, fitting the model on the training data, and storing the predictions for the test data:\n\nlogit_cv_preds &lt;- \n  map_dfr(unique(model_nhl_shot_data$game_fold), \n          function(test_fold) {\n            \n            # Separate test and training data:\n            test_data &lt;- model_nhl_shot_data |&gt;\n              filter(game_fold == test_fold)\n            train_data &lt;- model_nhl_shot_data |&gt;\n              filter(game_fold != test_fold)\n            \n            # Train model:\n            logit_model &lt;- glm(is_goal ~ shot_distance, \n                               data = train_data, family = \"binomial\")\n            \n            # Return tibble of holdout results:\n            tibble(test_pred_probs = predict(logit_model, newdata = test_data,\n                                             type = \"response\"),\n                   test_actual = test_data$is_goal,\n                   game_fold = test_fold) \n          })\n\nYou’ll notice that the logit_cv_preds dataset has the same number of rows as the original model dataset. This is because every observation receives a holdout prediction in cross-validation.\nWith the cross-validation predictions, we can now create a hold-out calibration plot using the same steps as before:\n\nlogit_cv_preds |&gt;\n  mutate(bin_pred_prob = round(test_pred_probs / 0.05) * .05) |&gt;\n  # Group by bin_pred_prob:\n  group_by(bin_pred_prob) |&gt;\n  # Calculate the calibration results:\n  summarize(n_shots = n(),\n            bin_actual_prob = mean(test_actual),\n            bin_se = sqrt((bin_actual_prob * (1 - bin_actual_prob)) / n_shots),\n            .groups = \"drop\") |&gt;\n  mutate(bin_upper = pmin(bin_actual_prob + 2 * bin_se, 1),\n         bin_lower = pmax(bin_actual_prob - 2 * bin_se, 0)) |&gt;\n  ggplot(aes(x = bin_pred_prob, y = bin_actual_prob)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = bin_lower, ymax = bin_upper)) + \n  geom_abline(slope = 1, intercept = 0, \n              color = \"black\", linetype = \"dashed\") +\n  coord_equal() + \n  scale_x_continuous(limits = c(0,1)) + \n  scale_y_continuous(limits = c(0,1)) + \n  labs(x = \"Estimated goal probability\",\n       y = \"Observed goal frequency\") + \n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nNOTE: As discussed in lecture, this is slightly different than the usual cross-validation procedure of generating an estimate for a loss (or any objective function) across \\(K\\)-folds (e.g., \\(K = 5\\) estimates of RMSE), then averaging over the \\(K\\)-fold values to generate an estimate of the test loss with standard errors. The reason for this, is because the calibration plot itself is our desired quantity (one could hypothetically compute \\(K\\) estimates for each bin instead).\nWe can use cross-validation to compare and evaluate which set of features are more appropriate. For instance, the following code check generates the cross-validation predictions when using shot distance AND angle:\n\nangle_cv_preds &lt;- \n  map_dfr(unique(model_nhl_shot_data$game_fold), \n          function(test_fold) {\n            \n            # Separate test and training data:\n            test_data &lt;- model_nhl_shot_data |&gt;\n              filter(game_fold == test_fold)\n            train_data &lt;- model_nhl_shot_data |&gt;\n              filter(game_fold != test_fold)\n            \n            # Train model:\n            logit_model &lt;- glm(is_goal ~ shot_distance + shot_angle, \n                               data = train_data, family = \"binomial\")\n            \n            # Return tibble of holdout results:\n            tibble(test_pred_probs = predict(logit_model, newdata = test_data,\n                                             type = \"response\"),\n                   test_actual = test_data$is_goal,\n                   game_fold = test_fold) \n          })\n\nWe can then stack the two datasets of predictions together, with a new column denoting what variables are in included, and then generate side-by-side calibration plots for comparison:\n\nlogit_cv_preds |&gt;\n  mutate(features = \"shot_distance\") |&gt;\n  bind_rows(mutate(angle_cv_preds, features = \"shot_distance + shot_angle\")) |&gt;\n  mutate(bin_pred_prob = round(test_pred_probs / 0.05) * .05) |&gt;\n  # Group by features AND bin_pred_prob:\n  group_by(features, bin_pred_prob) |&gt;\n  # Calculate the calibration results:\n  summarize(n_shots = n(),\n            bin_actual_prob = mean(test_actual),\n            bin_se = sqrt((bin_actual_prob * (1 - bin_actual_prob)) / n_shots),\n            .groups = \"drop\") |&gt;\n  mutate(bin_upper = pmin(bin_actual_prob + 2 * bin_se, 1),\n         bin_lower = pmax(bin_actual_prob - 2 * bin_se, 0)) |&gt;\n  ggplot(aes(x = bin_pred_prob, y = bin_actual_prob)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = bin_lower, ymax = bin_upper)) + \n  geom_abline(slope = 1, intercept = 0, \n              color = \"black\", linetype = \"dashed\") +\n  # Facet by the features:\n  facet_wrap(~features, ncol = 2) +\n  coord_equal() + \n  scale_x_continuous(limits = c(0,1)) + \n  scale_y_continuous(limits = c(0,1)) + \n  labs(x = \"Estimated goal probability\",\n       y = \"Observed goal frequency\") + \n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        strip.background = element_blank())\n\n\n\n\n\n\n\n\nBetween these two model options, which do you think is better?"
  },
  {
    "objectID": "demos/02-calibration-cv.html#recap",
    "href": "demos/02-calibration-cv.html#recap",
    "title": "Lecture 3: Calibration and Cross-Validation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced using calibration for evaluating logistic regression probability estimates\nWalked through steps for performing cross-validation while accounting for unique data structure"
  },
  {
    "objectID": "demos/04a-epa.html",
    "href": "demos/04a-epa.html",
    "title": "Lecture 5: Exploring Expected Points Added",
    "section": "",
    "text": "The goal of this demo is to introduce you to basic ways of summarizing and visualizing football statistics based on expected points added (EPA), as measured by nflfastR. Instead of manually computing EPA based on your own EP estimates, we’ll just use the nflfastR values since: (1) they’re extremely popular and (2) the code to compute EPA is really annoying to write (it’s a sloppy situation of ifelse/case_when situations). The code that follows in this demo borrows heavily from the nflfastR beginner’s guide.\nYou will need the following packages installed (besides the tidyverse):\n\nggrepel\nnflreadr\nnflplotR\n\nFor context, both nflreadr and nflplotR are packages inside the nflverse."
  },
  {
    "objectID": "demos/04a-epa.html#introduction",
    "href": "demos/04a-epa.html#introduction",
    "title": "Lecture 5: Exploring Expected Points Added",
    "section": "",
    "text": "The goal of this demo is to introduce you to basic ways of summarizing and visualizing football statistics based on expected points added (EPA), as measured by nflfastR. Instead of manually computing EPA based on your own EP estimates, we’ll just use the nflfastR values since: (1) they’re extremely popular and (2) the code to compute EPA is really annoying to write (it’s a sloppy situation of ifelse/case_when situations). The code that follows in this demo borrows heavily from the nflfastR beginner’s guide.\nYou will need the following packages installed (besides the tidyverse):\n\nggrepel\nnflreadr\nnflplotR\n\nFor context, both nflreadr and nflplotR are packages inside the nflverse."
  },
  {
    "objectID": "demos/04a-epa.html#reading-in-nfl-play-by-play-data",
    "href": "demos/04a-epa.html#reading-in-nfl-play-by-play-data",
    "title": "Lecture 5: Exploring Expected Points Added",
    "section": "Reading in NFL play-by-play data",
    "text": "Reading in NFL play-by-play data\nWe’ll start by reading in the play-by-play data from NFL games during the 2024 regular season. Since we are interested in creating statistics based on EPA, we will only consider rows in the dataset where epa is not missing:. The code chunk below reads in the data using nflreadr. You’ll notice that the play-by-play data contains a large number of columns with various statistics and other measurements provided by nflfastR. You can find a full glossary of the columns here.\n\nlibrary(tidyverse)\nlibrary(nflreadr)\n\n# Load the 2024 data:\nnfl_2024_pbp &lt;- load_pbp(2024) |&gt;\n  # Only use games from the regular season\n  filter(season_type == \"REG\", \n         # and where epa is not missing along with other issues for the \n         # teams involved either offense (posteam) or defense (defteam)\n         !is.na(epa), !is.na(posteam), posteam != \"\",\n         !is.na(defteam), defteam != \"\")\n\n# Preview the data\nnfl_2024_pbp\n\n# A tibble: 44,414 × 372\n   play_id game_id     old_game_id home_team away_team season_type  week posteam\n     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;  \n 1      40 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n 2      61 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n 3      83 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n 4     108 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n 5     133 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n 6     155 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n 7     177 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n 8     199 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n 9     224 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n10     265 2024_01_AR… 2024090801  BUF       ARI       REG             1 ARI    \n# ℹ 44,404 more rows\n# ℹ 364 more variables: posteam_type &lt;chr&gt;, defteam &lt;chr&gt;, side_of_field &lt;chr&gt;,\n#   yardline_100 &lt;dbl&gt;, game_date &lt;chr&gt;, quarter_seconds_remaining &lt;dbl&gt;,\n#   half_seconds_remaining &lt;dbl&gt;, game_seconds_remaining &lt;dbl&gt;,\n#   game_half &lt;chr&gt;, quarter_end &lt;dbl&gt;, drive &lt;dbl&gt;, sp &lt;dbl&gt;, qtr &lt;dbl&gt;,\n#   down &lt;dbl&gt;, goal_to_go &lt;int&gt;, time &lt;chr&gt;, yrdln &lt;chr&gt;, ydstogo &lt;dbl&gt;,\n#   ydsnet &lt;dbl&gt;, desc &lt;chr&gt;, play_type &lt;chr&gt;, yards_gained &lt;dbl&gt;, …"
  },
  {
    "objectID": "demos/04a-epa.html#summarizing-and-visualizing-total-epa",
    "href": "demos/04a-epa.html#summarizing-and-visualizing-total-epa",
    "title": "Lecture 5: Exploring Expected Points Added",
    "section": "Summarizing and Visualizing Total EPA",
    "text": "Summarizing and Visualizing Total EPA\nWith this dataset, we’re now ready to actually compute various EPA-related statistics to measure team performance. The following code chunk computes the total EPA (i.e., sum of EPA), EPA per play, and success rate for each team when they are on offense:\n\nteam_off_summary &lt;- nfl_2024_pbp |&gt;\n  group_by(posteam) |&gt;\n  summarize(total_epa = sum(epa),\n            ave_epa = mean(epa),\n            success_rate = mean(as.numeric(epa &gt; 0)),\n            .groups = \"drop\")\nteam_off_summary\n\n# A tibble: 32 × 4\n   posteam total_epa ave_epa success_rate\n   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n 1 ARI          85.6  0.0628        0.508\n 2 ATL          16.1  0.0114        0.502\n 3 BAL         195.   0.140         0.514\n 4 BUF         185.   0.136         0.5  \n 5 CAR         -52.8 -0.0392        0.460\n 6 CHI         -72.5 -0.0512        0.434\n 7 CIN         127.   0.0897        0.508\n 8 CLE        -221.  -0.151         0.406\n 9 DAL         -66.3 -0.0450        0.452\n10 DEN          35.7  0.0258        0.470\n# ℹ 22 more rows\n\n\nNext, we can display a ranking of the teams based on the total EPA via a bar chart ordered by the total EPA. For cosmetics, I flip the x/y axes here to display the bars horizontally, making the team abbreviations easier to see along the left-hand side. Note the use of reorder() to reorder the teams by their total_epa.\n\nteam_off_summary |&gt;\n  ggplot(aes(x = reorder(posteam, total_epa), \n             y = total_epa)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Team\", y = \"Total EPA on offense\",\n       caption = \"Data courtesy of nflreadr\") +\n  coord_flip() +\n  theme_bw()\n\n\n\n\n\n\n\n\nNOTE: From looking at this visual, we observe symmetry in terms of team with positive and negative total EPA. If we observed an imbalance, with favoring of one direction over another, then I would be concerned about the EPA values. Such type of asymmetry may be due to changes in the scoring environment for a particular season relative to previous seasons in the expected points model’s training dataset.\nWe can easily change the bar colors to match each team’s respective color(s) by loading in team data via load_teams() from nflreadr:\n\nteam_data &lt;- load_teams()\nteam_data\n\n── nflverse team graphics ──────────────────────────────────────────────────────\n\n\nℹ Data updated: 2025-01-27 16:36:39 EST\n\n\n# A tibble: 32 × 16\n   team_abbr team_name      team_id team_nick team_conf team_division team_color\n   &lt;chr&gt;     &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;     \n 1 ARI       Arizona Cardi… 3800    Cardinals NFC       NFC West      #97233F   \n 2 ATL       Atlanta Falco… 0200    Falcons   NFC       NFC South     #A71930   \n 3 BAL       Baltimore Rav… 0325    Ravens    AFC       AFC North     #241773   \n 4 BUF       Buffalo Bills  0610    Bills     AFC       AFC East      #00338D   \n 5 CAR       Carolina Pant… 0750    Panthers  NFC       NFC South     #0085CA   \n 6 CHI       Chicago Bears  0810    Bears     NFC       NFC North     #0B162A   \n 7 CIN       Cincinnati Be… 0920    Bengals   AFC       AFC North     #FB4F14   \n 8 CLE       Cleveland Bro… 1050    Browns    AFC       AFC North     #FF3C00   \n 9 DAL       Dallas Cowboys 1200    Cowboys   NFC       NFC East      #002244   \n10 DEN       Denver Broncos 1400    Broncos   AFC       AFC West      #002244   \n# ℹ 22 more rows\n# ℹ 9 more variables: team_color2 &lt;chr&gt;, team_color3 &lt;chr&gt;, team_color4 &lt;chr&gt;,\n#   team_logo_wikipedia &lt;chr&gt;, team_logo_espn &lt;chr&gt;, team_wordmark &lt;chr&gt;,\n#   team_conference_logo &lt;chr&gt;, team_league_logo &lt;chr&gt;, team_logo_squared &lt;chr&gt;\n\n\nTo add the colors to our figure, we can join the team_color to our summary table:\n\nteam_off_summary &lt;- team_off_summary |&gt;\n  inner_join(dplyr::select(team_data, team_abbr, team_color),\n             by = c(\"posteam\" = \"team_abbr\"))\nteam_off_summary\n\n# A tibble: 32 × 5\n   posteam total_epa ave_epa success_rate team_color\n   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;     \n 1 ARI          85.6  0.0628        0.508 #97233F   \n 2 ATL          16.1  0.0114        0.502 #A71930   \n 3 BAL         195.   0.140         0.514 #241773   \n 4 BUF         185.   0.136         0.5   #00338D   \n 5 CAR         -52.8 -0.0392        0.460 #0085CA   \n 6 CHI         -72.5 -0.0512        0.434 #0B162A   \n 7 CIN         127.   0.0897        0.508 #FB4F14   \n 8 CLE        -221.  -0.151         0.406 #FF3C00   \n 9 DAL         -66.3 -0.0450        0.452 #002244   \n10 DEN          35.7  0.0258        0.470 #002244   \n# ℹ 22 more rows\n\n\nAnd then recreate our bar chart using these colors:\n\nteam_off_summary |&gt;\n  ggplot(aes(x = reorder(posteam, total_epa), \n             y = total_epa)) +\n  geom_bar(stat = \"identity\",\n           # Note this is one way to set color without mapping inside aes\n           # that avoids a legend, it's convenient for using many colors with\n           # potential repeats like we have with teams\n           fill = team_off_summary$team_color) +\n  labs(x = \"Team\", y = \"Total EPA on offense\",\n       caption = \"Data courtesy of nflreadr\") +\n  coord_flip() +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can repeat the same steps from a defensive perspective as well, by first creating the defense summary:\n\nteam_def_summary &lt;- nfl_2024_pbp |&gt;\n  group_by(defteam) |&gt;\n  summarize(total_epa = sum(epa),\n            ave_epa = mean(epa),\n            # Flip success rate to be negative\n            success_rate = mean(as.numeric(epa &lt; 0)),\n            .groups = \"drop\")\nteam_def_summary\n\n# A tibble: 32 × 4\n   defteam total_epa  ave_epa success_rate\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 ARI         66.8   0.0497         0.474\n 2 ATL         61.3   0.0439         0.490\n 3 BAL         12.1   0.00849        0.523\n 4 BUF         -4.98 -0.00361        0.504\n 5 CAR        180.    0.121          0.458\n 6 CHI         14.8   0.0111         0.506\n 7 CIN         79.1   0.0560         0.483\n 8 CLE        -15.3  -0.0112         0.543\n 9 DAL         71.3   0.0511         0.495\n10 DEN       -104.   -0.0725         0.533\n# ℹ 22 more rows\n\n\nThen join the team colors again:\n\nteam_def_summary &lt;- team_def_summary |&gt;\n  inner_join(dplyr::select(team_data, team_abbr, team_color),\n             by = c(\"defteam\" = \"team_abbr\"))\nteam_def_summary\n\n# A tibble: 32 × 5\n   defteam total_epa  ave_epa success_rate team_color\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;     \n 1 ARI         66.8   0.0497         0.474 #97233F   \n 2 ATL         61.3   0.0439         0.490 #A71930   \n 3 BAL         12.1   0.00849        0.523 #241773   \n 4 BUF         -4.98 -0.00361        0.504 #00338D   \n 5 CAR        180.    0.121          0.458 #0085CA   \n 6 CHI         14.8   0.0111         0.506 #0B162A   \n 7 CIN         79.1   0.0560         0.483 #FB4F14   \n 8 CLE        -15.3  -0.0112         0.543 #FF3C00   \n 9 DAL         71.3   0.0511         0.495 #002244   \n10 DEN       -104.   -0.0725         0.533 #002244   \n# ℹ 22 more rows\n\n\nAnd create the appropriate visualization for defense where negative values are better:\n\nteam_def_summary |&gt;\n  ggplot(aes(x = reorder(defteam, total_epa), \n             y = total_epa)) +\n  geom_bar(stat = \"identity\",\n           fill = team_def_summary$team_color) +\n  labs(x = \"Team\", y = \"Total EPA on defense\",\n       caption = \"Data courtesy of nflreadr\") +\n  coord_flip() +\n  theme_bw()"
  },
  {
    "objectID": "demos/04a-epa.html#visualizing-offense-and-defense-performance-together",
    "href": "demos/04a-epa.html#visualizing-offense-and-defense-performance-together",
    "title": "Lecture 5: Exploring Expected Points Added",
    "section": "Visualizing offense and defense performance together",
    "text": "Visualizing offense and defense performance together\nWe can also visualize the offense and defensive performance for teams simultaneously with scatterplots. However, the first step is to merge the two tables together. There are a variety of ways to do this, but the simplest in this case is to first rename the columns in each table and join based on the team abbreviation columns:\n\n# First rename the team offense columns:\nteam_off_summary &lt;- team_off_summary |&gt;\n  rename(team = posteam, \n         off_total_epa = total_epa,\n         off_ave_epa = ave_epa,\n         off_success_rate = success_rate)\n\n# Repeat for defense:\nteam_def_summary &lt;- team_def_summary |&gt;\n  rename(team = defteam, \n         def_total_epa = total_epa,\n         def_ave_epa = ave_epa,\n         def_success_rate = success_rate)\n\n# And join together (dropping the team_color in the defense table):\nteam_summary &lt;- team_off_summary |&gt;\n  inner_join(dplyr::select(team_def_summary, -team_color),\n             by = \"team\")\nteam_summary\n\n# A tibble: 32 × 8\n   team  off_total_epa off_ave_epa off_success_rate team_color def_total_epa\n   &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;\n 1 ARI            85.6      0.0628            0.508 #97233F            66.8 \n 2 ATL            16.1      0.0114            0.502 #A71930            61.3 \n 3 BAL           195.       0.140             0.514 #241773            12.1 \n 4 BUF           185.       0.136             0.5   #00338D            -4.98\n 5 CAR           -52.8     -0.0392            0.460 #0085CA           180.  \n 6 CHI           -72.5     -0.0512            0.434 #0B162A            14.8 \n 7 CIN           127.       0.0897            0.508 #FB4F14            79.1 \n 8 CLE          -221.      -0.151             0.406 #FF3C00           -15.3 \n 9 DAL           -66.3     -0.0450            0.452 #002244            71.3 \n10 DEN            35.7      0.0258            0.470 #002244          -104.  \n# ℹ 22 more rows\n# ℹ 2 more variables: def_ave_epa &lt;dbl&gt;, def_success_rate &lt;dbl&gt;\n\n\nNext, using this dataset we can make a scatterplot of EPA per play with the color for each team:\n\nteam_summary |&gt;\n  ggplot(aes(x = off_ave_epa, y = def_ave_epa)) +\n  geom_point(color = team_summary$team_color,\n             alpha = 0.75) +\n  # Add reference lines at 0:\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"gray\") +\n  labs(x = \"Offense EPA per play\",\n       y = \"Defense EPA per play (negative is better)\",\n       caption = \"Data courtesy of nflreadr\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nOf course this visual makes it difficult to know what point corresponds to each team. We can add text labels to the points using ggrepel and geom_text_repel:\n\nlibrary(ggrepel)\n\nWarning: package 'ggrepel' was built under R version 4.2.3\n\nteam_summary |&gt;\n  ggplot(aes(x = off_ave_epa, y = def_ave_epa)) +\n  geom_point(color = team_summary$team_color,\n             alpha = 0.75) +\n  geom_text_repel(aes(label = team)) +\n  # Add reference lines at 0:\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"gray\") +\n  labs(x = \"Offense EPA per play\",\n       y = \"Defense EPA per play (negative is better)\",\n       caption = \"Data courtesy of nflreadr\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nThis is fairly easy to read, but thanks to nflplotR we can replace the points and team abbreviations with images of the team logos instead. As a word of caution, using the team logos may not be optimal all the time since their size can lead to overlap making it difficult to see what is directly going on. But using geom_nfl_logos() we can display the team logos instead of points, along with adjustments for the transparency and size of the logos. Furthermore, nflplotR includes a useful geom_mean_lines() function to display the averages for the x and y aesthetics via red dashed lines (although you can customize them). The following code chunk shows how you can make such a figure:\n\nlibrary(nflplotR)\n\nWarning: package 'nflplotR' was built under R version 4.2.3\n\nteam_summary |&gt;\n  ggplot(aes(x = off_ave_epa, y = def_ave_epa)) +\n  # Add the logo geom layer:\n  geom_nfl_logos(aes(team_abbr = team), width = 0.075, alpha = 0.75) +\n  # Add mean lines:\n  geom_mean_lines(aes(x0 = off_ave_epa, y0 = def_ave_epa)) +\n  # Add reference lines at 0:\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"gray\") +\n  labs(x = \"Offense EPA per play\",\n       y = \"Defense EPA per play (negative is better)\",\n       caption = \"Data courtesy of nflreadr\") +\n  theme_bw()"
  },
  {
    "objectID": "demos/04a-epa.html#summarizing-and-visualizing-qb-performance",
    "href": "demos/04a-epa.html#summarizing-and-visualizing-qb-performance",
    "title": "Lecture 5: Exploring Expected Points Added",
    "section": "Summarizing and visualizing QB performance",
    "text": "Summarizing and visualizing QB performance\nAs the last example in this demo, we’ll consider naive player evaluation based on measures of QB performance on passing plays. The following code first finds the passing plays, and then computes similar EPA-based statistics as before but at the passer-level instead of team-level. Additionally, we’ll compute completion percentage over expectation (CPOE) based on the nflfastr model for completion probability where cpoe is simply complete_pass - cp (complete_pass is a binary indicator for whether or not the pass is complete and cp is the predicted probability of a complete pass).\n\npasser_summary &lt;- nfl_2024_pbp |&gt;\n  filter(play_type == \"pass\") |&gt;\n  # group by the passer play name and id columns:\n  group_by(passer_player_name, passer_player_id) |&gt;\n  # Now summarize (also storing the last team they were on)\n  summarize(team = last(posteam),\n            n_plays = n(),\n            ave_epa = mean(epa),\n            success_rate = mean(epa &gt; 0),\n            cpoe = mean(cpoe, na.rm = TRUE),\n            .groups = \"drop\") |&gt;\n  # Join the team colors with left_join\n  left_join(dplyr::select(team_data, team_abbr, team_color),\n            by = c(\"team\" = \"team_abbr\"))\npasser_summary\n\n# A tibble: 110 × 8\n   passer_player_name passer_player_id team  n_plays  ave_epa success_rate\n   &lt;chr&gt;              &lt;chr&gt;            &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 A.Cole             00-0035190       LV          1  4.33           1    \n 2 A.Dalton           00-0027973       CAR       168 -0.151          0.411\n 3 A.Lazard           00-0034521       NYJ         1 -1.01           0    \n 4 A.Mitchell         00-0039890       IND         1  2.45           1    \n 5 A.O'Connell        00-0038579       LV        254  0.00981        0.441\n 6 A.Richardson       00-0039164       IND       277 -0.159          0.347\n 7 A.Rodgers          00-0023459       NYJ       627 -0.00202        0.434\n 8 A.St. Brown        00-0036963       DET         1  1.72           1    \n 9 B.Allen            00-0032434       SF         32 -0.546          0.344\n10 B.Anger            00-0029692       DAL         2 -2.84           0    \n# ℹ 100 more rows\n# ℹ 2 more variables: cpoe &lt;dbl&gt;, team_color &lt;chr&gt;\n\n\nWe can now visualize the CPOE and EPA per passing play (including sacks) for QBs during the 2024 season (with an arbitrary threshold of at least 200 plays for ease):\n\npasser_summary |&gt;\n  filter(n_plays &gt;= 200) |&gt;\n  ggplot(aes(x = cpoe, y = ave_epa)) +\n  # Note the filter within here could have been avoided if I just filtered\n  # beforehand to store a separate dataset entirely:\n  geom_point(color = pull(filter(passer_summary, \n                                 n_plays &gt;= 200), \n                          team_color),\n             aes(size = n_plays),\n             alpha = 0.75) +\n  geom_text_repel(aes(label = passer_player_name)) +\n  # Add mean lines\n  geom_mean_lines(aes(x0 = cpoe, y0 = ave_epa)) +\n  labs(x = \"Completion percentage over expectation (based on nflfastR model)\",\n       y = \"EPA per passing play (with sacks included)\",\n       caption = \"Data courtesy of nflreadr\",\n       size = \"Number of plays\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\nWarning: ggrepel: 1 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n\nWhile this plot probably passes the “eye test” (i.e., it generally agrees with who we think are good vs bad players), it’s an oversimplification to assign all EPA or CPOE credit to an individual player! We’ll focus on CPOE for the next so many lectures in approaching this topic of properly allocating residuals."
  },
  {
    "objectID": "demos/04a-epa.html#additional-resources",
    "href": "demos/04a-epa.html#additional-resources",
    "title": "Lecture 5: Exploring Expected Points Added",
    "section": "Additional Resources",
    "text": "Additional Resources\nIf you’re interested in American football data, there are several great resources readily available for you to access:\n\nnflverse is your one-stop shop for all things NFL data in R. There’s a great function within nflreadr called load_ftn_charting() that provides a variety of additional context (e.g., is it a screen pass, play-action pass, etc.) based on manual charting courtesy of FTNData.com.\nnfl_data_py is the Python equivalent that is just a wrapper for nflfastR data.\nOpen Source Football - a cool website that is effectively a repository of work people have done with public football data, including code. Note that there are likely mistakes made in the various posts regarding modeling techniques, but you’ll find ways to access interesting datasets and potentially get ideas for projects.\nA useful coding book with interesting examples: https://bradcongelio.com/nfl-analytics-with-r-book/ (note that I do not recommend the modeling sections of the book since many important details are omitted).\ncfbfastR for college football data (including recruiting data!).\nffverse for all things fantasy football."
  },
  {
    "objectID": "demos/12-intro-rapm.html",
    "href": "demos/12-intro-rapm.html",
    "title": "Lecture 13: Introduction to Regularized Adjusted Plus-Minus (RAPM)",
    "section": "",
    "text": "The purpose of this demo is to walk through the basics of building a regularized adjusted plus-minus (RAPM) model to estimate the impact of basketball players when they are on the court, while adjusting for the quality of their teammates and opponents. We will use a dataset that is already in the wide design matrix form with indicator columns for every player that was observed during the regular season. You can find the script (init_nba_rapm_data.R) for initializing this dataset on Canvas using the hoopR package.\nThe following code chunk reads in the wide data (assuming it is in the correct directory):\n\nlibrary(tidyverse)\n\n# Load the data\nnba_rapm_data &lt;- read_csv(here::here(\"data/nba_2324_season_rapm_data.csv.gz\"))\nnba_rapm_data\n\n# A tibble: 31,885 × 579\n   game_id    stint_id n_pos home_points away_points minutes  margin `203484`\n   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 0022300061        1    27          20          16   5.88    14.8         1\n 2 0022300061        2    14           9           2   3.29    50           1\n 3 0022300061        3     8           2           2   2.16     0           0\n 4 0022300061        4    11          11           4   3.2     63.6         0\n 5 0022300061        6     2           0           2   0.400 -100           1\n 6 0022300061        7     7           3           6   1.55   -42.9         1\n 7 0022300061        8     2           2           0   0.25   100           1\n 8 0022300061        9    12           7           8   2.43    -8.33        1\n 9 0022300061       10     9           6           6   1.76     0           1\n10 0022300061       11    34          15          19   7.39   -11.8         1\n# ℹ 31,875 more rows\n# ℹ 571 more variables: `203932` &lt;dbl&gt;, `203999` &lt;dbl&gt;, `1627750` &lt;dbl&gt;,\n#   `1629008` &lt;dbl&gt;, `202704` &lt;dbl&gt;, `1630192` &lt;dbl&gt;, `1631128` &lt;dbl&gt;,\n#   `1631212` &lt;dbl&gt;, `1629618` &lt;dbl&gt;, `1630296` &lt;dbl&gt;, `1631221` &lt;dbl&gt;,\n#   `101108` &lt;dbl&gt;, `201939` &lt;dbl&gt;, `202691` &lt;dbl&gt;, `203952` &lt;dbl&gt;,\n#   `1626172` &lt;dbl&gt;, `1630228` &lt;dbl&gt;, `203967` &lt;dbl&gt;, `1627780` &lt;dbl&gt;,\n#   `1630541` &lt;dbl&gt;, `202709` &lt;dbl&gt;, `1628380` &lt;dbl&gt;, `1629640` &lt;dbl&gt;, …\n\n\nIn this dataset, we have 31885 unique shifts/stints with 572 players represented by the indicator variables (+1 if on court for home team, -1 if on court for away team, and 0 if not on court). Additional context is captured by the following variables:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ngame_id\nUnique game ID\n\n\nstint_id\nUnique identifier within a game for a stint for particular combination of home and away lineup (in appearance of order, where 1 is the first stint in the game)\n\n\nn_pos\nNumber of possessions (combined for both home and away) during the observed stint\n\n\nhome_points\nNumber of points scored by the home team during the stint\n\n\naway_points\nNumber of points scored by the away team during the stint\n\n\nminutes\nLength of the stint in terms of minutes played\n\n\nmargin\nCommon response for RAPM models defined as: (home_points - away_points) / n_pos * 100"
  },
  {
    "objectID": "demos/12-intro-rapm.html#introduction",
    "href": "demos/12-intro-rapm.html#introduction",
    "title": "Lecture 13: Introduction to Regularized Adjusted Plus-Minus (RAPM)",
    "section": "",
    "text": "The purpose of this demo is to walk through the basics of building a regularized adjusted plus-minus (RAPM) model to estimate the impact of basketball players when they are on the court, while adjusting for the quality of their teammates and opponents. We will use a dataset that is already in the wide design matrix form with indicator columns for every player that was observed during the regular season. You can find the script (init_nba_rapm_data.R) for initializing this dataset on Canvas using the hoopR package.\nThe following code chunk reads in the wide data (assuming it is in the correct directory):\n\nlibrary(tidyverse)\n\n# Load the data\nnba_rapm_data &lt;- read_csv(here::here(\"data/nba_2324_season_rapm_data.csv.gz\"))\nnba_rapm_data\n\n# A tibble: 31,885 × 579\n   game_id    stint_id n_pos home_points away_points minutes  margin `203484`\n   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 0022300061        1    27          20          16   5.88    14.8         1\n 2 0022300061        2    14           9           2   3.29    50           1\n 3 0022300061        3     8           2           2   2.16     0           0\n 4 0022300061        4    11          11           4   3.2     63.6         0\n 5 0022300061        6     2           0           2   0.400 -100           1\n 6 0022300061        7     7           3           6   1.55   -42.9         1\n 7 0022300061        8     2           2           0   0.25   100           1\n 8 0022300061        9    12           7           8   2.43    -8.33        1\n 9 0022300061       10     9           6           6   1.76     0           1\n10 0022300061       11    34          15          19   7.39   -11.8         1\n# ℹ 31,875 more rows\n# ℹ 571 more variables: `203932` &lt;dbl&gt;, `203999` &lt;dbl&gt;, `1627750` &lt;dbl&gt;,\n#   `1629008` &lt;dbl&gt;, `202704` &lt;dbl&gt;, `1630192` &lt;dbl&gt;, `1631128` &lt;dbl&gt;,\n#   `1631212` &lt;dbl&gt;, `1629618` &lt;dbl&gt;, `1630296` &lt;dbl&gt;, `1631221` &lt;dbl&gt;,\n#   `101108` &lt;dbl&gt;, `201939` &lt;dbl&gt;, `202691` &lt;dbl&gt;, `203952` &lt;dbl&gt;,\n#   `1626172` &lt;dbl&gt;, `1630228` &lt;dbl&gt;, `203967` &lt;dbl&gt;, `1627780` &lt;dbl&gt;,\n#   `1630541` &lt;dbl&gt;, `202709` &lt;dbl&gt;, `1628380` &lt;dbl&gt;, `1629640` &lt;dbl&gt;, …\n\n\nIn this dataset, we have 31885 unique shifts/stints with 572 players represented by the indicator variables (+1 if on court for home team, -1 if on court for away team, and 0 if not on court). Additional context is captured by the following variables:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ngame_id\nUnique game ID\n\n\nstint_id\nUnique identifier within a game for a stint for particular combination of home and away lineup (in appearance of order, where 1 is the first stint in the game)\n\n\nn_pos\nNumber of possessions (combined for both home and away) during the observed stint\n\n\nhome_points\nNumber of points scored by the home team during the stint\n\n\naway_points\nNumber of points scored by the away team during the stint\n\n\nminutes\nLength of the stint in terms of minutes played\n\n\nmargin\nCommon response for RAPM models defined as: (home_points - away_points) / n_pos * 100"
  },
  {
    "objectID": "demos/12-intro-rapm.html#adjusted-plus-minus-apm",
    "href": "demos/12-intro-rapm.html#adjusted-plus-minus-apm",
    "title": "Lecture 13: Introduction to Regularized Adjusted Plus-Minus (RAPM)",
    "section": "Adjusted Plus-Minus (APM)",
    "text": "Adjusted Plus-Minus (APM)\nWe’ll first consider the classic Rosenbaum (2004) adjusted plus-minus (APM) model, which is weighted least-squares where:\n\nResponse variable is the score differential with respect to home team, i.e., home_points - away_points\nWeights are the number of posessions during the shift/stint, i.e., n_pos\n\nThe following code chunk fits this initial model (note this will take a bit to run::\n\n# First compute the score differential response:\nnba_rapm_data &lt;- nba_rapm_data |&gt;\n  mutate(score_diff = home_points - away_points)\n\n# Now for ease, create a dataset that only has the response and player columns:\nnba_apm_model_data &lt;- nba_rapm_data |&gt;\n  dplyr::select(-c(game_id, stint_id, n_pos, home_points, away_points, minutes,\n                   margin))\n\n# Fit the model (notice we do not include an intercept term)\nrosenbaum_model &lt;- lm(score_diff ~ 0 + ., data = nba_apm_model_data,\n                      weights = nba_rapm_data$n_pos)\n\nWe’re not going to view the summary of this model since it is a bit of a mess. Instead, we’ll take advantage of the broom package to view the coefficients:\n\nlibrary(broom)\nrosenbaum_coef &lt;- tidy(rosenbaum_model)\nrosenbaum_coef\n\n# A tibble: 572 × 5\n   term      estimate std.error statistic p.value\n   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 `203484`     1.58       1.74     0.911   0.362\n 2 `203932`     1.26       1.74     0.725   0.469\n 3 `203999`     1.92       1.75     1.10    0.273\n 4 `1627750`    1.58       1.74     0.909   0.363\n 5 `1629008`    1.27       1.74     0.732   0.464\n 6 `202704`     1.08       1.74     0.622   0.534\n 7 `1630192`    0.392      1.77     0.222   0.825\n 8 `1631128`    1.18       1.74     0.682   0.495\n 9 `1631212`    0.851      1.74     0.489   0.625\n10 `1629618`    1.00       1.86     0.537   0.591\n# ℹ 562 more rows\n\n\nObviously, in this current form we have no idea, we have no idea which player is which. Fortunately for you, there is a table on Canvas with the names of the players to join using these IDs in the term column:\n\nnba_player_table &lt;- read_csv(here::here(\"data/nba_2324_player_table.csv\"))\n\nRows: 572 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): player_name\ndbl (1): player_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nnba_player_table\n\n# A tibble: 572 × 2\n   player_id player_name             \n       &lt;dbl&gt; &lt;chr&gt;                   \n 1   1630173 Precious Achiuwa        \n 2   1628389 Bam Adebayo             \n 3   1630534 Ochai Agbaji            \n 4   1630583 Santi Aldama            \n 5   1629638 Nickeil Alexander-Walker\n 6   1628960 Grayson Allen           \n 7   1628386 Jarrett Allen           \n 8   1641851 Timmy Allen             \n 9   1630631 Jose Alvarado           \n10    203937 Kyle Anderson           \n# ℹ 562 more rows\n\n\nYou’ll notice that this matches the number of rows as the rosenbaum_coef table. But we first need to modify the term column by removing the back-tick symbols and then converting the IDs to numeric values before joining:\n\nrosenbaum_coef &lt;- rosenbaum_coef |&gt;\n  # First convert the term column to numeric:\n  mutate(term = as.numeric(str_remove_all(term, \"`\"))) |&gt;\n  # Now join the player names:\n  left_join(nba_player_table, by = c(\"term\" = \"player_id\"))\nrosenbaum_coef\n\n# A tibble: 572 × 6\n      term estimate std.error statistic p.value player_name             \n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                   \n 1  203484    1.58       1.74     0.911   0.362 Kentavious Caldwell-Pope\n 2  203932    1.26       1.74     0.725   0.469 Aaron Gordon            \n 3  203999    1.92       1.75     1.10    0.273 Nikola Jokić            \n 4 1627750    1.58       1.74     0.909   0.363 Jamal Murray            \n 5 1629008    1.27       1.74     0.732   0.464 Michael Porter Jr.      \n 6  202704    1.08       1.74     0.622   0.534 Reggie Jackson          \n 7 1630192    0.392      1.77     0.222   0.825 Zeke Nnaji              \n 8 1631128    1.18       1.74     0.682   0.495 Christian Braun         \n 9 1631212    0.851      1.74     0.489   0.625 Peyton Watson           \n10 1629618    1.00       1.86     0.537   0.591 Jalen Pickett           \n# ℹ 562 more rows\n\n\nWho are the top players based on this approach?\n\nrosenbaum_coef |&gt;\n  slice_max(estimate, n = 10)\n\n# A tibble: 10 × 6\n      term estimate std.error statistic p.value player_name     \n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;           \n 1 1641806     6.07      4.31     1.41   0.159  Markquis Nowell \n 2 1630259     5.18      2.27     2.28   0.0226 Jordan Ford     \n 3 1631157     4.04      1.88     2.15   0.0313 Ryan Rollins    \n 4 1630608     3.65      4.07     0.896  0.370  Malcolm Cazalon \n 5 1631321     3.13      1.83     1.71   0.0868 Sidy Cissoko    \n 6 1641766     3.09      1.96     1.57   0.116  Adama Sanogo    \n 7 1641774     3.08      1.82     1.69   0.0912 Tristan Vukcevic\n 8 1631220     3.07      1.99     1.55   0.122  Dereon Seabron  \n 9 1630207     3.07      2.02     1.52   0.129  Nate Hinton     \n10 1631217     3.01      1.92     1.57   0.117  Moussa Diabaté  \n\n\nAnd the worst players?\n\nrosenbaum_coef |&gt;\n  slice_min(estimate, n = 10)\n\n# A tibble: 10 × 6\n      term estimate std.error statistic p.value player_name         \n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1 1631199    -6.80      3.35    -2.03   0.0425 Ron Harper Jr.      \n 2 1630606    -4.20      7.65    -0.549  0.583  Javonte Smart       \n 3 1631214    -2.51      2.38    -1.05   0.292  Alondes Williams    \n 4 1631250    -2.48      2.27    -1.09   0.276  Pete Nance          \n 5 1627885    -2.37      3.10    -0.764  0.445  Shaquille Harrison  \n 6 1641847    -2.31      2.65    -0.871  0.384  Andrew Funk         \n 7 1631298    -1.78      1.98    -0.895  0.371  Jack White          \n 8 1631112    -1.68      2.04    -0.824  0.410  Kendall Brown       \n 9  202738    -1.65      2.33    -0.708  0.479  Isaiah Thomas       \n10 1631257    -1.63      2.12    -0.767  0.443  Jermaine Samuels Jr.\n\n\nThese look like pretty extreme values, with the most extreme values observed by players that have limited playing time (upon searching their stats online). Before we think about how to address these issues, let’s look at what happens if we make a slight tweak to our model by using the margin variable as the response instead:\n\n# Now for ease, create a dataset that only has the response and player columns:\nnba_margin_apm_model_data &lt;- nba_rapm_data |&gt;\n  dplyr::select(-c(game_id, stint_id, n_pos, home_points, away_points, minutes,\n                   score_diff))\n\n# Fit the model (notice we do not include an intercept term)\nrosenbaum_margin_model &lt;- lm(margin ~ 0 + ., data = nba_margin_apm_model_data)\n\n# Get the coefficients and join player names:\nrosenbaum_margin_coef &lt;- tidy(rosenbaum_margin_model) |&gt;\n  # First convert the term column to numeric:\n  mutate(term = as.numeric(str_remove_all(term, \"`\"))) |&gt;\n  # Now join the player names:\n  left_join(nba_player_table, by = c(\"term\" = \"player_id\"))\n\n# View top 10:\nrosenbaum_margin_coef |&gt;\n  slice_max(estimate, n = 10)\n\n# A tibble: 10 × 6\n      term estimate std.error statistic p.value player_name    \n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          \n 1 1628977     52.7      43.1     1.22    0.221 Hamidou Diallo \n 2 1630608     34.7      56.3     0.617   0.537 Malcolm Cazalon\n 3 1631131     29.0      28.5     1.02    0.308 Oscar Tshiebwe \n 4 1631220     28.7      26.6     1.08    0.280 Dereon Seabron \n 5 1631157     28.4      26.2     1.08    0.278 Ryan Rollins   \n 6 1629717     28.1      25.5     1.10    0.272 Armoni Brooks  \n 7 1630227     27.2      28.7     0.949   0.343 Daishen Nix    \n 8 1629010     24.2      26.7     0.907   0.365 Jerome Robinson\n 9 1630207     23.9      27.2     0.881   0.378 Nate Hinton    \n10 1631205     22.8      25.5     0.891   0.373 Buddy Boeheim  \n\n\nNotice the difference in magnitude now for the coefficient estimates compared to the score differential model. This is because the response is on the scale of points per 100 possessions.\nBefore we dive into fixing the issues covered in lecture, let’s take a look at the distribution of the coefficients for the players:\n\nrosenbaum_margin_coef |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram() +\n  labs(x = \"APM estimate\", y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nWhat do you notice about this distribution?"
  },
  {
    "objectID": "demos/12-intro-rapm.html#regularized-adjusted-plus-minus-rapm",
    "href": "demos/12-intro-rapm.html#regularized-adjusted-plus-minus-rapm",
    "title": "Lecture 13: Introduction to Regularized Adjusted Plus-Minus (RAPM)",
    "section": "Regularized Adjusted Plus-Minus (RAPM)",
    "text": "Regularized Adjusted Plus-Minus (RAPM)\nIn order to address the common issues facing APM models, we can fit a RAPM model using ridge regression. The go-to approach for fitting ridge (as well as lasso and elastic-net models) is with the glmnet package. The following code chunk demonstrates how we can easily fit a ridge regression model with the RAPM design matrix. In order to tune the penalty \\(\\lambda\\), we will use the built-in cross-validation code with the cv.glmnet() function:\n\n# First we need to grab the X and convert to a matrix:\nplayer_matrix &lt;- nba_margin_apm_model_data |&gt;\n  dplyr::select(-margin) |&gt;\n  as.matrix()\n\n# Next we load the package (assuming it's installed)\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n# Fit ridge (alpha = 0) w/ 10 fold CV, no intercept and no standardization\nfit_ridge_cv &lt;- cv.glmnet(player_matrix, nba_margin_apm_model_data$margin, \n                          alpha = 0, intercept = FALSE, standardize = FALSE)\n\n# View the penalty selection:\nplot(fit_ridge_cv)\n\n\n\n\n\n\n\n\nWe can easily plot the path of the ridge regression shrinkage, to see how the coefficients are pulled towards 0 as the penalty increases. The following code chunk shows this full path:\n\nplot(fit_ridge_cv$glmnet.fit, xvar = \"lambda\")\n\n\n\n\n\n\n\n\nUsing the broom package again, we can again make a tidy table of the coefficients for each player:\n\ntidy_ridge_coef &lt;- tidy(fit_ridge_cv$glmnet.fit)\ntidy_ridge_coef\n\n# A tibble: 57,200 × 5\n   term    step estimate lambda dev.ratio\n   &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n 1 203484     1 2.39e-37   351.  2.01e-39\n 2 203484     2 5.15e- 2   320.  4.25e- 4\n 3 203484     3 5.56e- 2   291.  4.62e- 4\n 4 203484     4 6.09e- 2   265.  5.05e- 4\n 5 203484     5 6.67e- 2   242.  5.52e- 4\n 6 203484     6 7.30e- 2   220.  6.03e- 4\n 7 203484     7 7.98e- 2   201.  6.59e- 4\n 8 203484     8 8.73e- 2   183.  7.20e- 4\n 9 203484     9 9.55e- 2   167.  7.85e- 4\n10 203484    10 1.04e- 1   152.  8.57e- 4\n# ℹ 57,190 more rows\n\n\nIf you look closely, this returns 100 rows for each player in the data - because it is returning the coefficient for each player at each value of the lambda penalty. We can filter to the values for the optimal choice of lambda based on the cross-validation results, and then join our player names as before:\n\n# Filter to the min lambda CV and join the player names:\nrapm_ridge_coef &lt;- tidy_ridge_coef |&gt;\n  filter(lambda == fit_ridge_cv$lambda.min) |&gt;\n  # Convert term to numeric:\n  mutate(term = as.numeric(term)) |&gt;\n  # Now join the player names:\n  left_join(nba_player_table, by = c(\"term\" = \"player_id\"))\n\n# View top 10:\nrapm_ridge_coef |&gt;\n  slice_max(estimate, n = 10) |&gt;\n  dplyr::select(term, player_name, estimate)\n\n# A tibble: 10 × 3\n      term player_name        estimate\n     &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n 1  203999 Nikola Jokić           4.68\n 2 1629029 Luka Dončić            4.34\n 3 1628973 Jalen Brunson          4.11\n 4  203954 Joel Embiid            3.63\n 5 1626164 Devin Booker           3.42\n 6 1626157 Karl-Anthony Towns     3.37\n 7 1628374 Lauri Markkanen        3.21\n 8 1630198 Isaiah Joe             2.95\n 9 1630581 Josh Giddey            2.89\n10 1628401 Derrick White          2.85\n\n\nConsidering Jokić won the MVP last season, this list definitely passes the eye test (it’s honestly amazing how well this works for basketball data). For context, let’s view the bottom 10:\n\nrapm_ridge_coef |&gt;\n  slice_min(estimate, n = 10) |&gt;\n  dplyr::select(term, player_name, estimate)\n\n# A tibble: 10 × 3\n      term player_name    estimate\n     &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n 1 1630171 Isaac Okoro       -2.94\n 2 1629651 Nic Claxton       -2.90\n 3 1630164 James Wiseman     -2.86\n 4 1630537 Chris Duarte      -2.77\n 5 1626224 Cedi Osman        -2.70\n 6  202397 Ish Smith         -2.67\n 7 1629018 Gary Trent Jr.    -2.46\n 8 1628381 John Collins      -2.38\n 9 1631367 Jacob Gilyard     -2.37\n10 1630201 Malachi Flynn     -2.35\n\n\nAnd finally, let’s view the RAPM coefficient distribution (for comparison against the APM coefficients):\n\nrapm_ridge_coef |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram() +\n  labs(x = \"RAPM estimate\", y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Special Topics: Sports Analytics 36-460/660",
    "section": "",
    "text": "This is the companion website for Special Topics: Sports Analytics 36-460/660. While all of the assignments will be posted on Canvas, this website provides an alternative way to access lecture materials and additional demo files (see the see side-bar).\nLectures are on Tuesdays and Thursday from 12:30 - 1:50 PM, located in SH 105.\nOffice hours schedule:\n\n\n\n\n\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\nProf Yurko\nTuesdays @ 3:30 PM, Wednesdays @ 10:45 AM\nBaker Hall 132D\n\n\nQuang Nguyen\nThursdays @ 11 AM\nZoom\n\n\nMeg Ellingwood\nMondays @ 10:30 AM\nZoom\n\n\n\nThere are no required textbooks for this course, but the following are useful free resources that I will sometimes refer to as recommended reading:\n\nBeyond Multiple Linear Regression\nBayes Rules! An Introduction to Applied Bayesian Modeling\nAnalyzing Baseball Data with R (3e)\n\nAnd the following are some interesting sports analytics websites (more are listed in course syllabus):\n\nNeil Paine’s Substack\nExploring Baseball Data with R by Jim Albert\nPlot the Ball\nThe F5",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "demos/11-beta-binomial.html",
    "href": "demos/11-beta-binomial.html",
    "title": "Lecture 12: Beta-Binomial model for Caitlin Clark’s rookie season",
    "section": "",
    "text": "The purpose of this demo is to walk through the Beta-Binomial Bayesian model for Caitlin Clark’s field goal percentage (FG%). We previously considered a discrete prior distribution for her probability of making a field goal \\(\\pi\\). In this demo, we’re going to replace the discrete prior with a continuous Beta distribution. This will provide us with a foundational example of using conjugate priors in Bayesian statistics. Although we are only considering Caitlin Clark’s FG% in this demo, this type of example can be applied to a wide variety of problems in sports that are based on considering some type of success out of a number of trials.\nWe will use two datasets in this demo: (1) season statistics WNBA players during the 2024 season and (2) a game log of Caitlin Clark’s statistics in her rookie WNBA season. Both of these files were created using the init_clark_wnba_game_log.R script located in the demos/week6 folder on Canvas. The following code chunk reads in data (assuming they are in the correct directory):\n\nlibrary(tidyverse)\n\nwnba_player_stats &lt;- read_csv(here::here(\"data/wnba_player_stats_2024.csv\"))\nclark_game_log &lt;- \n  read_csv(here::here(\"data/caitlin_clark_wnba_game_log_2024.csv\"))\n\n# View a preview of the datasets:\nwnba_player_stats\n\n# A tibble: 158 × 8\n   athlete_id athlete_display_name school  minutes fg_made fg_att position\n        &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n 1        585 Diana Taurasi        Mercury    1122     188    465 G       \n 2        869 DeWanna Bonner       Sun        1523     250    608 F       \n 3        887 Sami Whitcomb        Storm       613      72    209 G       \n 4        918 Tina Charles         Dream      1218     255    556 C       \n 5        924 Alysha Clark         Aces       1129      97    225 F       \n 6        981 Courtney Vandersloot Liberty     862     103    234 G       \n 7       1004 Sydney Colson        Aces        275      28     71 G       \n 8       1054 Tiffany Hayes        Aces        843     132    263 G       \n 9       1068 Nneka Ogwumike       Storm      1275     270    536 F       \n10    2284331 Emma Cannon          Aces         10       2      3 F       \n# ℹ 148 more rows\n# ℹ 1 more variable: fg_percentage &lt;dbl&gt;\n\nclark_game_log\n\n# A tibble: 43 × 7\n     game_id game_date  minutes field_goals_made field_goals_attempted\n       &lt;dbl&gt; &lt;date&gt;       &lt;dbl&gt;            &lt;dbl&gt;                 &lt;dbl&gt;\n 1 401721254 2024-09-25      40               10                    23\n 2 401721253 2024-09-22      36                4                    17\n 3 401620454 2024-09-19      20                2                     5\n 4 401620441 2024-09-15      36               10                    22\n 5 401620437 2024-09-13      34                7                    18\n 6 401620432 2024-09-11      38                6                    22\n 7 401620425 2024-09-08      45                7                    17\n 8 401620421 2024-09-06      36                8                    21\n 9 401620416 2024-09-04      40                8                    17\n10 401620409 2024-09-01      37               10                    19\n# ℹ 33 more rows\n# ℹ 2 more variables: opponent_team_display_name &lt;chr&gt;, fg_percentage &lt;dbl&gt;"
  },
  {
    "objectID": "demos/11-beta-binomial.html#introduction",
    "href": "demos/11-beta-binomial.html#introduction",
    "title": "Lecture 12: Beta-Binomial model for Caitlin Clark’s rookie season",
    "section": "",
    "text": "The purpose of this demo is to walk through the Beta-Binomial Bayesian model for Caitlin Clark’s field goal percentage (FG%). We previously considered a discrete prior distribution for her probability of making a field goal \\(\\pi\\). In this demo, we’re going to replace the discrete prior with a continuous Beta distribution. This will provide us with a foundational example of using conjugate priors in Bayesian statistics. Although we are only considering Caitlin Clark’s FG% in this demo, this type of example can be applied to a wide variety of problems in sports that are based on considering some type of success out of a number of trials.\nWe will use two datasets in this demo: (1) season statistics WNBA players during the 2024 season and (2) a game log of Caitlin Clark’s statistics in her rookie WNBA season. Both of these files were created using the init_clark_wnba_game_log.R script located in the demos/week6 folder on Canvas. The following code chunk reads in data (assuming they are in the correct directory):\n\nlibrary(tidyverse)\n\nwnba_player_stats &lt;- read_csv(here::here(\"data/wnba_player_stats_2024.csv\"))\nclark_game_log &lt;- \n  read_csv(here::here(\"data/caitlin_clark_wnba_game_log_2024.csv\"))\n\n# View a preview of the datasets:\nwnba_player_stats\n\n# A tibble: 158 × 8\n   athlete_id athlete_display_name school  minutes fg_made fg_att position\n        &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n 1        585 Diana Taurasi        Mercury    1122     188    465 G       \n 2        869 DeWanna Bonner       Sun        1523     250    608 F       \n 3        887 Sami Whitcomb        Storm       613      72    209 G       \n 4        918 Tina Charles         Dream      1218     255    556 C       \n 5        924 Alysha Clark         Aces       1129      97    225 F       \n 6        981 Courtney Vandersloot Liberty     862     103    234 G       \n 7       1004 Sydney Colson        Aces        275      28     71 G       \n 8       1054 Tiffany Hayes        Aces        843     132    263 G       \n 9       1068 Nneka Ogwumike       Storm      1275     270    536 F       \n10    2284331 Emma Cannon          Aces         10       2      3 F       \n# ℹ 148 more rows\n# ℹ 1 more variable: fg_percentage &lt;dbl&gt;\n\nclark_game_log\n\n# A tibble: 43 × 7\n     game_id game_date  minutes field_goals_made field_goals_attempted\n       &lt;dbl&gt; &lt;date&gt;       &lt;dbl&gt;            &lt;dbl&gt;                 &lt;dbl&gt;\n 1 401721254 2024-09-25      40               10                    23\n 2 401721253 2024-09-22      36                4                    17\n 3 401620454 2024-09-19      20                2                     5\n 4 401620441 2024-09-15      36               10                    22\n 5 401620437 2024-09-13      34                7                    18\n 6 401620432 2024-09-11      38                6                    22\n 7 401620425 2024-09-08      45                7                    17\n 8 401620421 2024-09-06      36                8                    21\n 9 401620416 2024-09-04      40                8                    17\n10 401620409 2024-09-01      37               10                    19\n# ℹ 33 more rows\n# ℹ 2 more variables: opponent_team_display_name &lt;chr&gt;, fg_percentage &lt;dbl&gt;"
  },
  {
    "objectID": "demos/11-beta-binomial.html#empirical-bayes---beta-prior-distribution",
    "href": "demos/11-beta-binomial.html#empirical-bayes---beta-prior-distribution",
    "title": "Lecture 12: Beta-Binomial model for Caitlin Clark’s rookie season",
    "section": "Empirical Bayes - Beta Prior Distribution",
    "text": "Empirical Bayes - Beta Prior Distribution\nFor our first step, we need a prior distribution for Clark’s probability of making a field goal, as denoted by parameter \\(\\pi\\). As discussed in lecture, the Beta distribution is a popular choice for the prior distribution for a probability since it is bounded between 0 and 1. The Beta distribution is defined by shape parameters \\(\\alpha\\) and \\(\\beta\\), which (as the name states) determine the shape of the distribution - altering the mean, mode(s), and variance. In the Bayesian syntax, parameters for prior distributions are called hyperparameters. Thus, we need to determine our choice for the hyperparameters \\(\\alpha\\) and \\(\\beta\\) in this particular context to serve as the prior distribution for Caitlin Clark’s probability of making a field goal \\(\\pi\\).\nAlthough we could consider a purely subjective approach for this (i.e., choose values for \\(\\alpha\\) and \\(\\beta\\) based on prior belief about what the mean, mode, and variance are for \\(\\pi\\)), in this example we will consider an empirical Bayes approach. Unlike traditional Bayesian statistics, which specifies a prior before observing any data, Empirical Bayes uses data to estimate the prior distribution’s hyperparameters.\nIn this example, we will use the wnba_player_stats table to estimate the hyperparameters for our Beta prior. However, the table currently includes a number of players with a relatively low number of field goal attempts (fg_att). For ease, we will only consider players with at least 100 FG attempts (excluding Caitlin Clark). Additionally, we will only consider Guard position players (indicated by position == \"G\") to only consider players that are similar to Clark.. The following code chunk filters the data and visualizes the distribution of FG%s (fg_percentage) for the considered players:\n\n# First filter to the players of interest\nprior_data &lt;- wnba_player_stats |&gt;\n  filter(fg_att &gt;= 100, position == \"G\",\n         athlete_display_name != \"Caitlin Clark\")\n\nprior_data |&gt;\n  ggplot(aes(x = fg_percentage)) +\n  geom_histogram(breaks = seq(0, 1, by = 0.05),\n                 closed = \"left\", color = \"black\",\n                 fill = \"gray\") +\n  labs(x = \"FG%\", y = \"Number of players\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nNext, we can use the fitdistr() function from the MASS package to estimate the values for \\(\\alpha\\) and \\(\\beta\\):\n\nprior_beta_model &lt;- MASS::fitdistr(prior_data$fg_percentage, \n                                   dbeta, \n                                   # Need starting values\n                                   start = list(shape1 = 5, shape2 = 8))\n\n# Grab the values:\nprior_alpha_shape &lt;- prior_beta_model$estimate[1]\nprior_beta_shape &lt;- prior_beta_model$estimate[2]\n\nThese values correspond to:\n\nprior_alpha_shape\n\n  shape1 \n45.88581 \n\nprior_beta_shape\n\n  shape2 \n68.68621 \n\n\nwhere shape1 is \\(\\alpha\\) and shape2 is \\(\\beta\\).\nWe can overlay this Beta density function based on these hyperparameters on top our histogram using stat_function():\n\nprior_data |&gt;\n  ggplot(aes(x = fg_percentage)) +\n  # Display on density scale\n  geom_histogram(aes(y = after_stat(density)),\n                 breaks = seq(0, 1, by = 0.05),\n                 closed = \"left\", color = \"black\",\n                 fill = \"gray\") +\n  # Now draw Beta distribution with these hyperparameters:\n  stat_function(fun = dbeta, color = \"red\", xlim = c(0, 1),\n                args = list(shape1 = prior_alpha_shape, \n                            shape2 = prior_beta_shape)) +\n  labs(x = \"FG%\", y = \"Density\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nArguably, this does not seem like the best fit for the data… however, we’re going to be lazy about this for now and proceed with this choice for the prior."
  },
  {
    "objectID": "demos/11-beta-binomial.html#binomial-likelihood-function",
    "href": "demos/11-beta-binomial.html#binomial-likelihood-function",
    "title": "Lecture 12: Beta-Binomial model for Caitlin Clark’s rookie season",
    "section": "Binomial Likelihood Function",
    "text": "Binomial Likelihood Function\nWe will use the Binomial model for Clark’s FG% (\\(\\pi\\)) based on the number of shots she made in her WNBA debut on May 14th 2024, where she made 5 of 15 FG attempts. Unlike the intro_bayes.qmd demo, all values in the interval between 0 and 1 are possible - as reflected in the Beta prior distribution. For ease, we’ll make a similar visual to the intro demo that displays the Binomial probability for a grid of possible \\(\\pi\\) values, with the observed \\(y = 5\\) out of \\(n = 15\\) shot attempts indicated in black:\n\n# First create a table with values from 0 to 15 to indicate the number of \n# made field goals:\nfield_goal_data &lt;- tibble(made_fg = 0:15, n_fg = 15)\n\n# Now, loop over a vector of values for the potential pi:\npotential_pi &lt;- seq(0.1, 0.9, by = 0.1)\n\n# Create a stacked dataset containing the Binomial probability of observing\n# the number of made_fg given pi and n_fg for each of the three values of pi:\nfield_goal_probs &lt;- map_dfr(potential_pi,\n                            function(pi) {\n                              \n                              field_goal_data |&gt;\n                                mutate(fg_pi = pi,\n                                       binom_pmf = dbinom(made_fg, n_fg, fg_pi))\n                              \n                            }) |&gt;\n  # Add an indicator denoting the observed outcome:\n  mutate(is_observed = ifelse(made_fg == 5, \"yes\", \"no\"))\n\n# And now create a plot displaying the probabilities for these choice of pis\nfield_goal_probs |&gt;\n  # Make a new label using fg_pi:\n  mutate(binom_label = paste0(\"Binomial(15, \", fg_pi, \")\")) |&gt;\n  ggplot(aes(x = made_fg, y = binom_pmf, color = is_observed)) +\n  geom_bar(aes(fill = is_observed), stat = \"identity\", width = 0.1) +\n  geom_point() +\n  scale_color_manual(values = c(\"gray\", \"black\")) +\n  scale_fill_manual(values = c(\"gray\", \"black\")) +\n  facet_wrap(~binom_label, ncol = 3) +\n  labs(x = \"y\", y = expression(paste(\"f(y|\", pi, \")\"))) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        strip.background = element_blank(),\n        strip.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nIf we focus on the observed values with \\(y = 5\\), we can view the likelihood as a function of the choice of \\(\\pi\\). Rather than view this likelihood only for the nine \\(\\pi\\) values in the grid of plots above, we need to compute this across the continuous range of \\(\\pi\\) values. The following code chunk displays this likelihood function across the full range of \\(\\pi\\) (with the nine values from above highlighted in black):\n\nfield_goal_probs |&gt;\n  # only use the rows for the observed outcome\n  filter(is_observed == \"yes\") |&gt;\n  ggplot(aes(x = fg_pi, y = binom_pmf)) +\n  geom_bar(stat = \"identity\", width = 0.001,\n           color = \"black\", fill = \"black\") +\n  geom_point(color = \"black\", size = 4) +\n  stat_function(fun = dbinom, color = \"red\", xlim = c(0, 1),\n                args = list(x = 5, \n                            size = 15)) +\n  labs(x = expression(pi), y = expression(paste(\"L(\", pi, \"|y = 5)\"))) +\n  theme_bw() +\n  theme(strip.background = element_blank(),\n        strip.text = element_text(size = 14))"
  },
  {
    "objectID": "demos/11-beta-binomial.html#beta-posterior",
    "href": "demos/11-beta-binomial.html#beta-posterior",
    "title": "Lecture 12: Beta-Binomial model for Caitlin Clark’s rookie season",
    "section": "Beta Posterior",
    "text": "Beta Posterior\nSince we now have the two pieces in place, prior and likelihood, we can arrive at the posterior distribution for Clark’s \\(\\pi\\). Before arriving at the posterior, we’ll visualize the prior and a scaled version of the likelihood (so that it integrates to 1) together on the same plot using a convenient function from the bayesrules package:\n\nlibrary(bayesrules)\nplot_beta_binomial(alpha = prior_alpha_shape, beta = prior_beta_shape, \n                   y = 5, n = 15, \n                   prior = TRUE, likelihood = TRUE, posterior = FALSE)\n\n\n\n\n\n\n\n\nAs discussed in lecture, the use of a Beta prior with the Binomial likelihood results in a Beta posterior distribution for \\(\\pi\\). This is because the Beta distribution is the conjugate prior for Binomial likelihood, meaning that the posterior is the same model family as the prior. The bayesrule package has a summarize_beta_binomial() function that returns the parameters for the prior and posterior under this form:\n\nsummarize_beta_binomial(prior_alpha_shape, prior_beta_shape,\n                        y = 5, n = 15)\n\n      model    alpha     beta      mean      mode         var         sd\n1     prior 45.88581 68.68621 0.4004975 0.3987297 0.002077486 0.04557945\n2 posterior 50.88581 78.68621 0.3927222 0.3910404 0.001826513 0.04273772\n\n\nWhile we can manually display this posterior Beta distribution with the above \\(\\alpha\\) and \\(\\beta\\) parameters using dbeta() and stat_function(), the code chunk below displays the posterior with the prior and scaled likelihood using the convenient helper function from bayesrules:\n\nplot_beta_binomial(alpha = prior_alpha_shape, beta = prior_beta_shape, \n                   y = 5, n = 15, # Now display the posterior\n                   prior = TRUE, likelihood = TRUE, posterior = TRUE)\n\n\n\n\n\n\n\n\nThis connects back to the idea of pooling from multilevel models: although we observe data for Caitlin Clark’s shot attempts, we apply regularization and move towards the prior."
  },
  {
    "objectID": "demos/11-beta-binomial.html#sequential-bayesian-analysis",
    "href": "demos/11-beta-binomial.html#sequential-bayesian-analysis",
    "title": "Lecture 12: Beta-Binomial model for Caitlin Clark’s rookie season",
    "section": "Sequential Bayesian Analysis",
    "text": "Sequential Bayesian Analysis\nThe Bayesian framework provides a way to incrementally update a posterior as new data arrives. We can start with a prior distribution, observe data to arrive at a posterior, then use this posterior as a new prior before repeating the process as we observe new data. For instance, we can use the game log of Caitlin Clark’s season to demonstrate this. Each row in clark_game_log corresponds to a single game. We can start with our Empirical Bayes prior from before, and update using the Beta-Binomial conjugate prior solution to arrive at the posterior for each game. The following code chunk performs this by updating the Clark game log table to include columns for the prior and posterior parameters:\n\n# First sort the game log in ascending order:\nclark_game_log &lt;- arrange(clark_game_log, game_date)\n\n# Initialize prior and posterior columns to use:\nclark_game_log &lt;- clark_game_log |&gt;\n  # Initialize the prior and posterior columns using the first game\n  mutate(prior_alpha = prior_alpha_shape,\n         prior_beta = prior_beta_shape,\n         posterior_alpha = prior_alpha + field_goals_made,\n         posterior_beta = prior_beta + field_goals_attempted - field_goals_made)\n\n# Now use a for loop to modify the values for the parameters for all rows \n# starting at 2:\n\nfor (i in 2:nrow(clark_game_log)) {\n  \n  # Update the priors to be the posterior from the previous row:\n  clark_game_log$prior_alpha[i] &lt;- clark_game_log$posterior_alpha[i - 1]\n  clark_game_log$prior_beta[i] &lt;- clark_game_log$posterior_beta[i - 1]\n  \n  # And now update the posterior:\n  clark_game_log$posterior_alpha[i] &lt;- clark_game_log$prior_alpha[i] +\n    clark_game_log$field_goals_made[i]\n  clark_game_log$posterior_beta[i] &lt;- clark_game_log$prior_beta[i] +\n    clark_game_log$field_goals_attempted[i] - clark_game_log$field_goals_made[i]\n}\n\nYou can view the updating of the parameters from viewing the table:\n\nclark_game_log\n\n# A tibble: 43 × 11\n     game_id game_date  minutes field_goals_made field_goals_attempted\n       &lt;dbl&gt; &lt;date&gt;       &lt;dbl&gt;            &lt;dbl&gt;                 &lt;dbl&gt;\n 1 401620219 2024-05-14      32                5                    15\n 2 401620224 2024-05-16      30                2                     8\n 3 401620227 2024-05-18      34                9                    17\n 4 401620232 2024-05-20      27                5                    11\n 5 401620237 2024-05-22      33                6                    16\n 6 401620241 2024-05-24      37                4                    14\n 7 401620244 2024-05-25      29                2                     8\n 8 401620250 2024-05-28      34                7                    16\n 9 401620255 2024-05-30      40                6                    17\n10 401620261 2024-06-01      37                4                    11\n# ℹ 33 more rows\n# ℹ 6 more variables: opponent_team_display_name &lt;chr&gt;, fg_percentage &lt;dbl&gt;,\n#   prior_alpha &lt;dbl&gt;, prior_beta &lt;dbl&gt;, posterior_alpha &lt;dbl&gt;,\n#   posterior_beta &lt;dbl&gt;\n\n\nThe following code chunk draws the posterior across the first 15 games using the convenient cowplot package to display a list of plots (NOTE: I could not find a easier way to make this other than manually drawing separate layers for each posterior which would’ve been annoying). I am only displaying the first 15 games for ease, but we have a posterior after each of the 43 games that Clark played in. For reference, I’ve included a dashed red line indicating the average FG% of the players forming the prior.\n\nx_lower &lt;- 0\nx_upper &lt;- 1\n# For ease, only displaying the first 15 games' posteriors\nN_GAMES &lt;- 15\n\ngame_plot_list &lt;- \n  lapply(1:N_GAMES, \n         function(i) {\n           tibble(x = c(x_lower, x_upper)) |&gt;\n             ggplot(aes(x = x)) +\n             geom_vline(xintercept = mean(prior_data$fg_percentage),\n                        linetype = \"dashed\", color = \"red\") +\n             scale_x_continuous(limits = c(x_lower, x_upper)) +\n             stat_function(fun = dbeta, color = \"black\", xlim = c(0, 1),\n                           args = list(shape1 = clark_game_log$posterior_alpha[i], \n                                       shape2 = clark_game_log$posterior_beta[i])) +\n             labs(x = expression(pi), y = expression(paste(\"f(\", pi, \"|y)\")),\n                  title = paste0(\"Game \", i, \": made \", \n                                 clark_game_log$field_goals_made[i], \" of \",\n                                 clark_game_log$field_goals_attempted[i])) +\n             theme_bw() +\n             theme(axis.title = element_text(size = 6),\n                   axis.text = element_text(size = 4),\n                   plot.title = element_text(size = 6))\n         })\n\ncowplot::plot_grid(plotlist = game_plot_list, ncol = 3)\n\n\n\n\n\n\n\n\nNow take a look at posterior parameters in final row of the game log:\n\nclark_game_log |&gt;\n  slice_tail(n = 1) |&gt;\n  dplyr::select(posterior_alpha, posterior_beta)\n\n# A tibble: 1 × 2\n  posterior_alpha posterior_beta\n            &lt;dbl&gt;          &lt;dbl&gt;\n1            304.           440.\n\n\nAnd compare with the output of the posterior distribution if we just use the accumulated totals:\n\nsummarize_beta_binomial(prior_alpha_shape, prior_beta_shape,\n                        y = sum(clark_game_log$field_goals_made), \n                        n = sum(clark_game_log$field_goals_attempted))\n\n      model     alpha      beta      mean      mode          var         sd\n1     prior  45.88581  68.68621 0.4004975 0.3987297 0.0020774861 0.04557945\n2 posterior 303.88581 439.68621 0.4086838 0.4084375 0.0003245641 0.01801566\n\n\nWhat do you observe?"
  },
  {
    "objectID": "demos/13-posterior-approx.html",
    "href": "demos/13-posterior-approx.html",
    "title": "Lecture 14: Methods for Approximating the Posterior",
    "section": "",
    "text": "The purpose of this demo is to walk through different approaches for approximating the posterior distribution. We’ll consider the Beta-Binomial Bayesian model for Caitlin Clark’s field goal percentage (FG%) from previous lectures. As we already know, the Beta-Binomial is an example of a conjugate prior model such that the posterior distribution also follows a Beta with a simple calculation. However, we’ll imagine that we did not know this fact and will need to use procedures for approximating the posterior distribution. This will prepare us for scenarios where the posterior is actually too difficult to compute, but you’ll see how well these types of approximation can perform.\nWe will not actually load any data for this demo, instead we’ll just use the values from the Week 6 Beta-Binomial demo (beta_binomial.qmd). For our prior distribution, we’ll use the same Empirical Bayes prior based on the WNBA FG% statistics:\n\\[\n\\pi \\sim \\text{Beta}(\\alpha = 45.9,\\  \\beta = 68.7)\n\\]\nWe’ll consider the observed data from the first 5 games of Clark’s rookie season, where she made \\(y = 33\\) of \\(n = 85\\) FG attempts. As a reminder, the likelihood function is Binomial:\n\\[\nY | \\pi \\sim \\text{Binomial}(n = 85, \\pi)\n\\]\nYou can keep in mind during this demo that the true posterior distribution for a Beta-Binomial conjugate model is simply:\n\\[\n\\pi | (Y = y) \\sim \\text{Beta}(\\alpha + y,\\ \\beta + n - y)\n\\]\nThis means that the posterior distribution for \\(\\pi\\) after observing the \\(y = 33\\) for \\(n = 85\\) performance is:\n\\[\n\\pi | (Y = y) \\sim \\text{Beta}(45.9 + 33,\\ 68.7 + 85 - 33)\n\\]"
  },
  {
    "objectID": "demos/13-posterior-approx.html#introduction",
    "href": "demos/13-posterior-approx.html#introduction",
    "title": "Lecture 14: Methods for Approximating the Posterior",
    "section": "",
    "text": "The purpose of this demo is to walk through different approaches for approximating the posterior distribution. We’ll consider the Beta-Binomial Bayesian model for Caitlin Clark’s field goal percentage (FG%) from previous lectures. As we already know, the Beta-Binomial is an example of a conjugate prior model such that the posterior distribution also follows a Beta with a simple calculation. However, we’ll imagine that we did not know this fact and will need to use procedures for approximating the posterior distribution. This will prepare us for scenarios where the posterior is actually too difficult to compute, but you’ll see how well these types of approximation can perform.\nWe will not actually load any data for this demo, instead we’ll just use the values from the Week 6 Beta-Binomial demo (beta_binomial.qmd). For our prior distribution, we’ll use the same Empirical Bayes prior based on the WNBA FG% statistics:\n\\[\n\\pi \\sim \\text{Beta}(\\alpha = 45.9,\\  \\beta = 68.7)\n\\]\nWe’ll consider the observed data from the first 5 games of Clark’s rookie season, where she made \\(y = 33\\) of \\(n = 85\\) FG attempts. As a reminder, the likelihood function is Binomial:\n\\[\nY | \\pi \\sim \\text{Binomial}(n = 85, \\pi)\n\\]\nYou can keep in mind during this demo that the true posterior distribution for a Beta-Binomial conjugate model is simply:\n\\[\n\\pi | (Y = y) \\sim \\text{Beta}(\\alpha + y,\\ \\beta + n - y)\n\\]\nThis means that the posterior distribution for \\(\\pi\\) after observing the \\(y = 33\\) for \\(n = 85\\) performance is:\n\\[\n\\pi | (Y = y) \\sim \\text{Beta}(45.9 + 33,\\ 68.7 + 85 - 33)\n\\]"
  },
  {
    "objectID": "demos/13-posterior-approx.html#grid-approximation",
    "href": "demos/13-posterior-approx.html#grid-approximation",
    "title": "Lecture 14: Methods for Approximating the Posterior",
    "section": "Grid Approximation",
    "text": "Grid Approximation\nWe’ll first consider grid approximation, which proceeds in the following manner:\n\nStep 1: define a grid of possible parameter values\nThe code chunk below sets up an initial grid of possible values for \\(\\pi\\). There are technically an infinite number of values for \\(\\pi \\in (0, 1)\\), so it is ideal to produce a grid containing as many values as possible - but there is a computational trade-off at play. A larger grid will take longer to work with, but lead to a better approximation of the posterior. For demonstration purposes, we’ll consider a grid of 101 values:\n\nlibrary(tidyverse)\n\n# Step 1: Define a grid of 101 pi values\ngrid_data &lt;- tibble(pi = seq(from = 0, to = 1, length = 101))\ngrid_data\n\n# A tibble: 101 × 1\n      pi\n   &lt;dbl&gt;\n 1  0   \n 2  0.01\n 3  0.02\n 4  0.03\n 5  0.04\n 6  0.05\n 7  0.06\n 8  0.07\n 9  0.08\n10  0.09\n# ℹ 91 more rows\n\n\n\n\nStep 2: evaluate prior and likelihood at each parameter value in grid\nNext, the code chunk below adds columns to the grid_data table that are the values for the prior and likelihood for each \\(\\pi\\) in the grid above:\n\n# Step 2: Evaluate the prior and likelihood at each pi\ngrid_data &lt;- grid_data |&gt;\n  mutate(prior = dbeta(pi, 45.9, 68.7), likelihood = dbinom(33, 85, pi))\ngrid_data\n\n# A tibble: 101 × 3\n      pi    prior likelihood\n   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1  0    0          0       \n 2  0.01 5.38e-57   2.39e-43\n 3  0.02 8.88e-44   1.21e-33\n 4  0.03 3.58e-36   4.59e-28\n 5  0.04 7.22e-31   3.55e-24\n 6  0.05 7.98e-27   3.25e-21\n 7  0.06 1.40e-23   7.69e-19\n 8  0.07 6.88e-21   7.14e-17\n 9  0.08 1.33e-18   3.34e-15\n10  0.09 1.26e-16   9.22e-14\n# ℹ 91 more rows\n\n\n\n\nStep 3: approximate the posterior\nWe’re now ready to approximate the posterior using the product of the prior and likelihood. This involves first computing the unnormalized version (i.e., the numerator in the posterior formula), and then approximating the posterior by dividing the unnormalized version by the sum of values across the grid. This results in a discretized version of the posterior, with values that sum to 1 due to the normalization. The code chunk below performs these steps and then displays a visual of the approximate posterior distribution:\n\n# Step 3: Approximate the posterior\ngrid_data &lt;- grid_data |&gt; \n  mutate(unnormalized = likelihood * prior, \n         posterior = unnormalized / sum(unnormalized))\n\n# And now display the approx posterior\ngrid_data |&gt;\n  ggplot(aes(x = pi, y = posterior)) + \n  geom_point() + \n  geom_segment(aes(x = pi, xend = pi, \n                   y = 0, yend = posterior)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nStep 4: sample from the discretized posterior\nAnd finally, we can sample from our discretized posterior PDF to generate a posterior sample:\n\n# Set seed for reproducibility\nset.seed(2024)\n\n# Step 4: sample from the discretized posterior\nposterior_sample &lt;- grid_data |&gt;\n  # Use the sample_n function to resample with replacement the parameter grid \n  # data weighted by the posterior probability weights\n  sample_n(size = 10000, replace = TRUE, weight = posterior)\n\nThe following displays a histogram of the sampled parameter values on the density scale:\n\nposterior_sample |&gt;\n  ggplot(aes(x = pi)) +\n  geom_histogram(aes(y = after_stat(density))) +\n  scale_x_continuous(limits = c(0, 1)) +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nAnd for reference, we draw the true posterior distribution density on top in red:\n\nposterior_sample |&gt;\n  ggplot(aes(x = pi)) +\n  geom_histogram(aes(y = after_stat(density))) +\n  stat_function(fun = dbeta, args = list(78.9, 120.7),\n                color = \"red\") + \n  scale_x_continuous(limits = c(0, 1)) +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nWe can see that this does a pretty good job at capturing the true posterior distribution, with some variation around it since we’re dealing with a sample. Similar to your work in HW4, we can compute various summaries of the posterior via our sample:\n\n# Compute various summaries of posterior sample:\nposterior_sample |&gt; \n  summarize(posterior_mean = mean(pi), \n            posterior_median = median(pi),\n            # Convenient function for mode:\n            posterior_mode = bayesrules::sample_mode(pi),\n            # 95% credible interval:\n            lower_95 = quantile(pi, 0.025),\n            upper_95 = quantile(pi, 0.975))\n\n# A tibble: 1 × 5\n  posterior_mean posterior_median posterior_mode lower_95 upper_95\n           &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1          0.395              0.4          0.400     0.33     0.46\n\n\nWe can see these values are relatively close to the true values of the known posterior distribution:\n\ntrue_posterior_alpha &lt;- 78.9\ntrue_posterior_beta &lt;- 120.7\n\n# True posterior mean:\nprint(paste0(\"Posterior mean: \", true_posterior_alpha / (true_posterior_alpha + true_posterior_beta)))\n\n[1] \"Posterior mean: 0.395290581162325\"\n\n# True posterior median:\nprint(paste0(\"Posterior median: \", qbeta(0.5, true_posterior_alpha, true_posterior_beta)))\n\n[1] \"Posterior median: 0.394940169853597\"\n\n# True posterior mode:\nprint(paste0(\"Posterior mode: \", \n      (true_posterior_alpha - 1) / (true_posterior_alpha + true_posterior_beta - 2)))\n\n[1] \"Posterior mode: 0.394230769230769\"\n\n# 95% credible interval:\nprint(paste0(\"95% credible interval: \", \n             paste0(qbeta(c(0.025, 0.975), true_posterior_alpha, true_posterior_beta),\n                    collapse = \", \")))\n\n[1] \"95% credible interval: 0.328704819452707, 0.463864243216083\""
  },
  {
    "objectID": "demos/13-posterior-approx.html#markov-chain-monte-carlo",
    "href": "demos/13-posterior-approx.html#markov-chain-monte-carlo",
    "title": "Lecture 14: Methods for Approximating the Posterior",
    "section": "Markov Chain Monte Carlo",
    "text": "Markov Chain Monte Carlo\nWe’ll now consider the widely used Markov chain Monte Carlo (MCMC) approach for approximating the posterior. Similar to grid approximation, we can use MCMC to approximate the posterior without directly sampling from it. However, unlike grid approximation, MCMC samples are subsequent values that depend on the previously observed values - hence the chain.\nTo provide you with a walk-through of how MCMC works, we’ll implement the Metropolis-Hastings algorithm.\nTo start, we need a function that will produce a single iteration of the MCMC sequence of \\(\\pi\\) values. This involves proposing a new value followed by the decision to accept it or not. we’ll call to produce a sequence of \\(\\pi\\) values. The code chunk below initializes a function for a single step that uses the Uniform proposal model. Notice that since \\(\\pi\\) is bounded, we’ll need to use a floor and ceiling to ensure the value is possible.\n\none_unif_iteration &lt;- function(w, current){\n  \n  # STEP 1: Propose the next chain location\n  proposal &lt;- runif(1, min = current - w, max = current + w)\n  # Use the right floor and cap for the value:\n  proposal &lt;- pmax(pmin(proposal, 1), 0)\n  \n  # STEP 2: Decide whether or not to go there (prior x likelihood)\n  proposal_plaus &lt;- dbeta(proposal, 45.9, 68.7) * dbinom(33, 85, proposal)\n  current_plaus  &lt;- dbeta(current, 45.9, 68.7) * dbinom(33, 85, current)\n  alpha &lt;- min(1, proposal_plaus / current_plaus)\n  next_stop &lt;- sample(c(proposal, current), \n                      size = 1, prob = c(alpha, 1 - alpha))\n  \n  return(data.frame(proposal, alpha, next_stop))\n}\n\nTo demonstrate, we’ll run one iteration with the function using a window of 0.1 and starting with a value of 0.5:\n\nset.seed(1)\none_unif_iteration(0.1, 0.5)\n\n   proposal alpha next_stop\n1 0.4531017     1 0.4531017\n\n\nYou can see that the proposal is 0.4531017, the acceptance probability is 1 and then we move to the proposed value based on the sample output at the end.\nAnd now we can write a function to “tour” the posterior distribution via the Metropolis-Hastings algorithm:\n\nmh_tour &lt;- function(N, w, start_pi) {\n  # 1. Start the chain at the initial given value\n  current &lt;- start_pi\n\n  # 2. Initialize the simulation\n  pi &lt;- rep(0, N)\n\n  # 3. Simulate N Markov chain stops\n  for (i in 1:N) {    \n    # Simulate one iteration\n    sim &lt;- one_unif_iteration(w = w, current = current)\n    \n    # Record next location\n    pi[i] &lt;- sim$next_stop\n    \n    # Reset the current location\n    current &lt;- sim$next_stop\n  }\n  \n  # 4. Return the chain locations\n  return(data.frame(iteration = c(1:N), pi))\n}\n\nWe call this function below to generate a chain of 5000 values, using w = .1 and start_pi = 0.5:\n\nset.seed(1979)\nmh_sim_1 &lt;- mh_tour(N = 5000, w = 0.1, start_pi = 0.5)\n\nWe’ll first display the trace plot for this simulation to display how the chain traverses the sample space of the plausible posterior \\(\\pi\\) values:\n\nmh_sim_1 |&gt;\n  ggplot(aes(x = iteration, y = pi)) + \n  geom_line() +\n  theme_bw()\n\n\n\n\n\n\n\n\nNotice that this plot shows how the Markov chain moves across each step, with local dependence observed, but an overall random looking walk. If we ignore the longitudinal structure of these values, we can visualize the distribution of the MCMC samples to see how well it approximates the posterior:\n\nmh_sim_1 |&gt;\n  ggplot(aes(x = pi)) +\n  geom_histogram(aes(y = after_stat(density))) +\n  stat_function(fun = dbeta, args = list(78.9, 120.7),\n                color = \"red\") + \n  scale_x_continuous(limits = c(0, 1)) +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nAs you can see, this approximates the posterior distribution extremely well! Even better than the grid approximation from early - which technically had more samples! Just like the grid approximation posterior, we can compute various summaries (like the mean, mode, percentiles for credible intervals, etc).\nJust for the sake of demonstration, the following code chunk repeats the this MCMC sampling from above but uses independence sampling with a Beta distribution for the proposal distribution. We can again see how well this approximates the posterior distribution:\n\none_beta_iteration &lt;- function(a, b, current){\n  \n  # STEP 1: Propose the next chain location\n  proposal &lt;- rbeta(1, a, b)\n  \n  \n  # STEP 2: Decide whether or not to go there (prior x likelihood)\n  proposal_plaus &lt;- dbeta(proposal, 45.9, 68.7) * dbinom(33, 85, proposal)\n  proposal_q     &lt;- dbeta(proposal, a, b)\n  current_plaus  &lt;- dbeta(current, 45.9, 68.7) * dbinom(33, 85, current)\n  current_q      &lt;- dbeta(current, a, b)\n  alpha &lt;- min(1, proposal_plaus / current_plaus * current_q / proposal_q)\n  next_stop &lt;- sample(c(proposal, current), \n                      size = 1, prob = c(alpha, 1 - alpha))\n  \n  return(data.frame(proposal, alpha, next_stop))\n}\n\nmh_beta_tour &lt;- function(N, a, b, start_pi) {\n  # 1. Start the chain at the initial given value\n  current &lt;- start_pi\n\n  # 2. Initialize the simulation\n  pi &lt;- rep(0, N)\n\n  # 3. Simulate N Markov chain stops\n  for (i in 1:N) {    \n    # Simulate one iteration\n    sim &lt;- one_beta_iteration(a, b, current)\n    \n    # Record next location\n    pi[i] &lt;- sim$next_stop\n    \n    # Reset the current location\n    current &lt;- sim$next_stop\n  }\n  \n  # 4. Return the chain locations\n  return(data.frame(iteration = c(1:N), pi))\n}\n\n\nset.seed(2013)\nmh_sim_2 &lt;- mh_beta_tour(N = 5000, a = 1, b = 1, start_pi = 0.5)\n\n# Create the plots:\nmh_sim_2 |&gt;\n  ggplot(aes(x = iteration, y = pi)) + \n  geom_line() +\n  theme_bw()\n\n\n\n\n\n\n\nmh_sim_2 |&gt;\n  ggplot(aes(x = pi)) +\n  geom_histogram(aes(y = after_stat(density))) +\n  stat_function(fun = dbeta, args = list(78.9, 120.7),\n                color = \"red\") + \n  scale_x_continuous(limits = c(0, 1)) +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`)."
  },
  {
    "objectID": "demos/05-intro-multilevel-models.html",
    "href": "demos/05-intro-multilevel-models.html",
    "title": "Lecture 6: Intro to multilevel modeling",
    "section": "",
    "text": "The goal of this demo is to walk through the initial steps of multilevel modeling in the context of modeling pass completion probability. We’ll continue where we left off in the cpoe.qmd demo, using a dataset corresponding to pass attempts in NFL regular season games during the 2023 and 2024 seasons. You can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/05-intro-multilevel-models.html#introduction",
    "href": "demos/05-intro-multilevel-models.html#introduction",
    "title": "Lecture 6: Intro to multilevel modeling",
    "section": "",
    "text": "The goal of this demo is to walk through the initial steps of multilevel modeling in the context of modeling pass completion probability. We’ll continue where we left off in the cpoe.qmd demo, using a dataset corresponding to pass attempts in NFL regular season games during the 2023 and 2024 seasons. You can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/05-intro-multilevel-models.html#modeling-completion-probability-with-logistic-regression",
    "href": "demos/05-intro-multilevel-models.html#modeling-completion-probability-with-logistic-regression",
    "title": "Lecture 6: Intro to multilevel modeling",
    "section": "Modeling completion probability with logistic regression",
    "text": "Modeling completion probability with logistic regression\nIn the previous demo, we fit a logistic regression model to estimate the probability of a complete pass (i.e., when complete_pass == 1) based on a few variables:\n\npass_location: a categorical variable denoting which side of the field the ball was thrown to, either left, middle, or right (based on manually charted data). We’re going to be lazy and treat left as the reference level, but one should think more carefully about which level is more appropriate.\nair_yards: a quantitative variable indicating how many yards the ball traveled in the air perpendicular to the line of scrimmage. This does not measure the actual distance traveled by the ball (e.g., if the QB throws the ball across the field but only to the line of scrimmage then it has traveled 0 air yards), but still provides measure for the length of the pass.\nqb_hit: a binary indicator variable denoting whether or not the QB was hit on the play, serving as a proxy for plays where the QB observes pressure (i.e., a tougher situation to make a throw).\n\nThe following code chunk fits this logistic regression model on all of the data:\n\nlogit_completion &lt;- glm(complete_pass ~ pass_location + air_yards + qb_hit,\n                        data = nfl_passing_data, family = \"binomial\")\n\nsummary(logit_completion)\n\n\nCall:\nglm(formula = complete_pass ~ pass_location + air_yards + qb_hit, \n    family = \"binomial\", data = nfl_passing_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1567  -1.1713   0.7187   0.8481   2.3971  \n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          1.221994   0.021886  55.834  &lt; 2e-16 ***\npass_locationmiddle  0.164057   0.032141   5.104 3.32e-07 ***\npass_locationright  -0.090248   0.026235  -3.440 0.000582 ***\nair_yards           -0.058879   0.001203 -48.957  &lt; 2e-16 ***\nqb_hit              -1.080257   0.038836 -27.816  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46543  on 35986  degrees of freedom\nResidual deviance: 42900  on 35982  degrees of freedom\nAIC: 42910\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "demos/05-intro-multilevel-models.html#multiple-levels-in-the-data",
    "href": "demos/05-intro-multilevel-models.html#multiple-levels-in-the-data",
    "title": "Lecture 6: Intro to multilevel modeling",
    "section": "Multiple levels in the data",
    "text": "Multiple levels in the data\nIn the previous logistic regression model, we naively ignored the structure of the data: there are repeated pass attempts by quarterbacks (QBs, passer_name_id), repeatedly to a set of receivers (receiver_name_id), against different defenses (defteam). For the sake of this intro demo, we will just focus on QBs and will return to handling receivers and defenses later.\nIgnoring receivers and defenses, there are two levels in the dataset:\n\nLevel One: individual pass attempts, which are the the simplest and most frequent unit of observation in the dataset. For each pass attempt we have information describing the pass such as the pass_location, air_yards, and if the QB was hit on the play qb_hit.\nLevel Two: the QB attempting the pass, which is a larger observational unit. In other words, we observe the same QB across multiple pass attempts - which should make us think the outcome of such attempts are correlated with each other.\n\nWhen we think about performing preliminary exploratory data analysis (EDA), we should consider it at both levels of the data. This includes starting with a basic summary of the response at the pass level:\n\nnfl_passing_data |&gt;\n  ggplot(aes(x = as.factor(complete_pass))) +\n  geom_bar() +\n  scale_x_discrete(labels = c(\"Incomplete\", \"Complete\")) +\n  labs(x = \"Pass outcome\", y = \"Number of passes\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAs well seeing how the outcome varies as a function of the different variables, such as the pass location:\n\nnfl_passing_data |&gt;\n  ggplot(aes(x = pass_location,\n             fill = as.factor(complete_pass))) +\n  geom_bar() +\n  ggthemes::scale_fill_colorblind(labels = c(\"Incomplete\", \"Complete\")) +\n  labs(x = \"Pass location\", y = \"Number of passes\",\n       fill = \"Pass outcome\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAnd by making an empirical logit plot (similar to the logit_expected_goals.qmd demo) to view the relationship between the response with the air yards variable:\n\nnfl_passing_data |&gt;\n  mutate(air_yards_bin = cut_number(air_yards, 10)) |&gt;\n  group_by(air_yards_bin) |&gt;\n  summarize(cp = mean(complete_pass),\n            air_yards_midpoint = median(air_yards),\n            .groups = \"drop\") |&gt;\n  mutate(cp = pmax(cp, 0.0001),\n         emp_logit = log(cp / (1 - cp))) |&gt;\n  ggplot(aes(x = air_yards_midpoint, y = emp_logit)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x = \"Air yards (midpoint of bins)\",\n       y = \"Empirical logits\") +\n  theme_bw()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nIn order to consider EDA for Level Two, we can start by making a summary dataset with one row for each QB in the data along with appropriate summaries of the different considered explanatory variables:\n\n# Start with the basic summary:\nqb_summary &lt;- nfl_passing_data |&gt;\n  group_by(passer_name_id) |&gt;\n  summarize(n_passes = n(),\n            cp = mean(complete_pass),\n            fraction_hit = mean(qb_hit),\n            fraction_left = mean(pass_location == \"left\"),\n            fraction_middle = mean(pass_location == \"middle\"),\n            fraction_right = mean(pass_location == \"right\"),\n            ave_air_yards = mean(air_yards),\n            .groups = \"drop\")\n\nAnd then we can repeat the EDA process at this level, such as viewing the distribution of completion percentages for each QB:\n\nqb_summary |&gt;\n  ggplot(aes(x = cp)) +\n  geom_histogram(breaks = seq(0, 1, by = 0.05), closed = \"left\") +\n  labs(x = \"Completion %\",\n       y = \"Number of QBs\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAs well as relationships between completion percentages with the different variables, such as average air yards:\n\nqb_summary |&gt;\n  ggplot(aes(x = ave_air_yards, y = cp)) +\n  geom_point(aes(size = n_passes), alpha = 0.25) +\n  labs(x = \"Average air yards thrown each pass\",\n       y = \"Completion %\",\n       size = \"# passes\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nTo make this easier to see, here is the same plot but for passers with at least 100 attempts:\n\nqb_summary |&gt;\n  filter(n_passes &gt;= 100) |&gt;\n  ggplot(aes(x = ave_air_yards, y = cp)) +\n  geom_point(aes(size = n_passes), alpha = 0.25) +\n  labs(x = \"Average air yards thrown each pass\",\n       y = \"Completion %\",\n       size = \"# passes\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can also view the Level One EDA for each observation unit in Level Two. For instance, the code chunk below displays the empirical logit plots for the nine QBs with the most passing attempts:\n\ntop_attempt_qbs &lt;- qb_summary |&gt;\n  arrange(desc(n_passes)) |&gt;\n  slice(1:9) |&gt;\n  pull(passer_name_id)\n\nnfl_passing_data |&gt;\n  filter(passer_name_id %in% top_attempt_qbs) |&gt;\n  mutate(air_yards_bin = cut_number(air_yards, 10)) |&gt;\n  group_by(passer_name_id, air_yards_bin) |&gt;\n  summarize(cp = mean(complete_pass),\n            air_yards_midpoint = median(air_yards),\n            .groups = \"drop\") |&gt;\n  mutate(cp = pmax(cp, 0.0001),\n         emp_logit = log(cp / (1 - cp))) |&gt;\n  ggplot(aes(x = air_yards_midpoint, y = emp_logit)) +\n  geom_point() +\n  # Add a smooth trend line\n  geom_smooth(se = FALSE) +\n  # Facet by QB:\n  facet_wrap(~passer_name_id, ncol = 3) +\n  labs(x = \"Air yards (midpoint of bins)\",\n       y = \"Empirical logits\") +\n  theme_bw() +\n  theme(strip.background = element_blank())\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFrom this we can see slight differences in the relationship with air yards across the small sample of QBs. Patrick Mahomes displays a relatively monotone relationships, while players such as Geno Smith and Josh Allen display a clear nonlinear relationship between the empirical logit and air yards."
  },
  {
    "objectID": "demos/05-intro-multilevel-models.html#modeling-strategies",
    "href": "demos/05-intro-multilevel-models.html#modeling-strategies",
    "title": "Lecture 6: Intro to multilevel modeling",
    "section": "Modeling strategies",
    "text": "Modeling strategies\nWhen handling data of this structure, we have a few different options for how to approach modeling the data. For ease, we’ll only consider the air_yards variable as a coefficient in the following models below. But the same ideas can be applied to models with more features.\n\n1) Naive Level One Model\nOur starting point, is the model we already considered that completely ignores the QB-level of the data. The following code chunk fits this logistic regression model as a function of the air_yards plus an intercept:\n\ninit_logit &lt;- glm(complete_pass ~ air_yards,\n                  data = nfl_passing_data, family = \"binomial\")\n\nsummary(init_logit)\n\n\nCall:\nglm(formula = complete_pass ~ air_yards, family = \"binomial\", \n    data = nfl_passing_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1115  -1.2496   0.7541   0.8767   2.1930  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.11219    0.01529   72.75   &lt;2e-16 ***\nair_yards   -0.05900    0.00119  -49.57   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46543  on 35986  degrees of freedom\nResidual deviance: 43746  on 35985  degrees of freedom\nAIC: 43750\n\nNumber of Fisher Scoring iterations: 4\n\n\nHowever, this completely ignores the correlated structure of the data and we ideally like to somehow account for the QB in the model.\n\n\n2) Two-Stage Modeling Approach\nAlternatively, since we believe QBs are independent of each other, we can fit separate logistic regression models for each QB in the dataset. For example, the code chunk below fits the same logistic regression model as above but only for pass attempts by Patrick Mahomes:\n\nmahomes_passes &lt;- nfl_passing_data |&gt;\n  filter(str_detect(passer_name_id, \"Mahomes\"))\n\nmahomes_logit &lt;- glm(complete_pass ~ air_yards,\n                     data = mahomes_passes, family = \"binomial\")\n\nsummary(mahomes_logit)\n\n\nCall:\nglm(formula = complete_pass ~ air_yards, family = \"binomial\", \n    data = mahomes_passes)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0991  -1.1114   0.6825   0.8297   2.3811  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.263493   0.084389   14.97   &lt;2e-16 ***\nair_yards   -0.074776   0.007257  -10.30   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1479.8  on 1173  degrees of freedom\nResidual deviance: 1349.3  on 1172  degrees of freedom\nAIC: 1353.3\n\nNumber of Fisher Scoring iterations: 4\n\n\nIf we compare the Mahomes’ model to the naive model, we notice some slight differences in the intercept and coefficient estimates as well as larger standard errors (due to the smaller sized dataset).\nWe can repeat this for every single QB in the dataset, storing the intercept and coefficients in a table. For simplicity, we’ll only do this with the air_yards variable since the categorical variables require observing the different levels at least once. You can ignore the warning messages that are popping up for players with only one observation.\n\nqb_coef_table &lt;- \n  map_dfr(unique(nfl_passing_data$passer_name_id),\n          function(qb_i) {\n            \n            qb_i_data &lt;- nfl_passing_data |&gt;\n              filter(passer_name_id == qb_i)\n            \n            qb_i_model &lt;- glm(complete_pass ~ air_yards,\n                              data = qb_i_data, family = \"binomial\")\n            \n            # Return the tidy coefficient table:\n            broom::tidy(qb_i_model) |&gt;\n              mutate(qb = qb_i)\n          })\n# Ignore the warning messages that are displayed\n\nWe can visualize what the distribution for the intercepts and coefficients looks like:\n\nqb_coef_table |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram() +\n  facet_wrap(~term, ncol = 1, scales = \"free_x\") +\n  labs(x = \"Estimate value\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 40 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nThere are so notable extreme values making this figure difficult to read. We can zoom in on the relevant portions with appropriate filters:\n\nqb_coef_table |&gt;\n  # First filter for the Intercept condition, based on reasonable cutoff\n  filter((term == \"(Intercept)\" & abs(estimate) &lt;= 3) |\n           # And then for air_yards:\n           (term == \"air_yards\" & abs(estimate) &lt;= .5)) |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram() +\n  facet_wrap(~term, ncol = 1, scales = \"free_x\") +\n  labs(x = \"Estimate value\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nBased on this plot, we may decide to try modeling the intercepts and slopes at the QB level via their own regression models. In other words, we can treat the intercepts and slopes as the response variable, and fit a regression model (maybe as a function of QB level variables) to model the coefficients.\n\n# First filter to create separate datasets for each term:\nintercept_data &lt;- qb_coef_table |&gt;\n  filter(term == \"(Intercept)\")\nslope_data &lt;- qb_coef_table |&gt;\n  filter(term == \"air_yards\")\n\n# And now fit intercept-only models:\nintercept_lm &lt;- lm(estimate ~ 1, data = intercept_data)\nslope_lm &lt;- lm(estimate ~ 1, data = slope_data)\n\nThe summary of these models provide us the averages and estimates for the variances of their respective distributions:\n\nsummary(intercept_lm)\n\n\nCall:\nlm(formula = estimate ~ 1, data = intercept_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-190.02   -5.94   -5.61   -4.75  570.27 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    6.734      4.495   1.498    0.136\n\nResidual standard error: 53.37 on 140 degrees of freedom\n\n\n\nsummary(slope_lm)\n\n\nCall:\nlm(formula = estimate ~ 1, data = slope_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-45.606   0.480   0.497   0.506  16.270 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  -0.5565     0.5413  -1.028    0.306\n\nResidual standard error: 5.44 on 100 degrees of freedom\n  (40 observations deleted due to missingness)\n\n\nThere are clear limitations with this type of approach:\n\nWe are completely ignoring the number of observations (in this case pass attempts) for each QB, treating QBs with only a small number of attempts the same as QBs with many attempts.\nWe drop players with insufficient number of observations for slopes.\nWe are not sharing information across the QBs when modeling the relationship between air yards and completion probability. Ideally, we want to leverage the information across the full dataset in order to provide better estimates for the relationships.\n\nThis leads us to the ideal approach for modeling such data…\n\n\n3) Unified Multilevel Model\nIn order to fit multilevel models in R, we need to use the lme4 package, which follows a unique syntax that we’ll breakdown in the lectures ahead. First install the package:\n\ninstall.packages(\"lme4\")\n\nThen we can fit a generalized linear multilevel model (GLMM) using the glmer() function in the package, which is analogous to the glm() function in R. Note that in Homework 2 you will use the lmer() function which is used for modeling continuous data under the assumption of Gaussian errors. In this problem, we are modeling completion probability so we are relying on a linear model for the log odds function. The following code chunk demonstrates how to fit a GLMM for completion probability with random effects for QB intercepts and air yards slopes, along with a fixed effect for air yards:\n\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nglmm_completion &lt;- glmer(complete_pass ~ air_yards + (air_yards | passer_name_id),\n                         family = binomial, data = nfl_passing_data)\n\nboundary (singular) fit: see help('isSingular')\n\nsummary(glmm_completion)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ air_yards + (air_yards | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43704.2  43746.6 -21847.1  43694.2    35982 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0276 -1.0727  0.5727  0.6774  4.8845 \n\nRandom effects:\n Groups         Name        Variance  Std.Dev. Corr\n passer_name_id (Intercept) 0.0000000 0.00000      \n                air_yards   0.0001159 0.01077   NaN\nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.114817   0.016567   67.29   &lt;2e-16 ***\nair_yards   -0.062080   0.001886  -32.91   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.412\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\n(You can ignore the warning messages for now…)\nWe will break down the steps for building multilevel models in the lectures ahead, starting with simple varying intercepts models in the next lecture."
  },
  {
    "objectID": "demos/07-nested-crossed-effects.html",
    "href": "demos/07-nested-crossed-effects.html",
    "title": "Lecture 8: Nested and crossed random effects",
    "section": "",
    "text": "The purpose of this demo is to walk through fitting and interpreting the output of multilevel models with more than two levels, i.e., more than one group treated as random effects. Building off the previous demos and lecture content, we’ll do this in the context of modeling pass completion probability. The additional levels we’ll consider are the receivers and opposing defenses. As a reminder, you can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas in the demos/week3 folder.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/07-nested-crossed-effects.html#introduction",
    "href": "demos/07-nested-crossed-effects.html#introduction",
    "title": "Lecture 8: Nested and crossed random effects",
    "section": "",
    "text": "The purpose of this demo is to walk through fitting and interpreting the output of multilevel models with more than two levels, i.e., more than one group treated as random effects. Building off the previous demos and lecture content, we’ll do this in the context of modeling pass completion probability. The additional levels we’ll consider are the receivers and opposing defenses. As a reminder, you can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas in the demos/week3 folder.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/07-nested-crossed-effects.html#nested-levels-demonstrated-by-receivers",
    "href": "demos/07-nested-crossed-effects.html#nested-levels-demonstrated-by-receivers",
    "title": "Lecture 8: Nested and crossed random effects",
    "section": "Nested levels demonstrated by receivers",
    "text": "Nested levels demonstrated by receivers\nIn the previous demo and lecture material, we only considered modeling the passer/QB group as a random effect. But we know that the structure of passing plays includes receivers and opposing defenses which we should also account for.\nTo start, we’ll first consider including receivers in the model. If players did not change teams at all during the period of time we collected data, then receivers would only attempt to catch passes from a single passer/QB. This would mean that the receivers would be a nested level within the passer/QB level, i.e., we observe the outcomes of pass attempts by QBs to a group of receivers such that their receivers do not receive any passes from other QBs. This type of data structure would correspond to a nested three-level model.\nTo make this more concrete, we’ll consider a subset of our data corresponding to pass attempts that were only during the 2024 season and were attempted by the top 32 QBs in terms of the number of pass attempts that that only played for a single team. Additionally, we’ll only consider receivers that caught for these QBs that only caught passes for one QB. This results in a smaller dataset that preserves the nested structure we just described. The code chunk below creates this dataset:\n\n# First get the 2024 season only:\nnfl_passing_2024 &lt;- nfl_passing_data |&gt;\n  filter(str_detect(game_id, \"2024_\"))\n\n# Next find the QBs and receivers that only played for one team, \nqb_list &lt;- nfl_passing_2024 |&gt;\n  group_by(passer_name_id) |&gt;\n  summarize(n_teams = length(unique(posteam)),\n            n_passes = n(),\n            .groups = \"drop\") |&gt;\n  filter(n_teams == 1) |&gt;\n  slice_max(n_passes, n = 32) |&gt;\n  pull(passer_name_id)\n\n# Grab the sample of passes by these QBs:\nnested_passing_data &lt;- nfl_passing_2024 |&gt;\n  filter(passer_name_id %in% qb_list)\n\n# Now find the receivers that only caught passes for just one QB in these plays:\nreceiver_list &lt;- nested_passing_data |&gt;\n  # Drop the QBs from this:\n  filter(!(receiver_name_id %in% qb_list)) |&gt;\n  group_by(receiver_name_id) |&gt;\n  summarize(n_qbs = length(unique(passer_name_id)),\n            .groups = \"drop\") |&gt;\n  filter(n_qbs == 1) |&gt;\n  pull(receiver_name_id)\n\n# And now filter the data to only these receivers:\nnested_passing_data &lt;- nested_passing_data |&gt;\n  filter(receiver_name_id %in% receiver_list)\n# Note this results in 31 QBs since it drops Cooper Rush for the Cowboys since\n# the Cowboys started multiple QBs this season...\n\nUsing this dataset, we’ll start with models that only contain varying intercepts. We can fit the nested model in one of two ways:\n\n1.) Explicit nested effects\nThe lme4 syntax for modeling the three level effects, with receivers nested within the passers, uses two terms: (1) the highest level intercepts (1 | passer_name_id), and (2) the nested level intercepts (1 | passer_name_id:receiver_name_id). The code below fits this model and displays the relevant output:\n\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nrec_nested_glmm &lt;- glmer(complete_pass ~ (1 | passer_name_id) + (1 | passer_name_id:receiver_name_id),\n                         family = binomial, data = nested_passing_data)\n\nboundary (singular) fit: see help('isSingular')\n\nsummary(rec_nested_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: \ncomplete_pass ~ (1 | passer_name_id) + (1 | passer_name_id:receiver_name_id)\n   Data: nested_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 15488.6  15510.9  -7741.3  15482.6    12738 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.3285 -1.2747  0.5849  0.6815  0.9387 \n\nRandom effects:\n Groups                          Name        Variance Std.Dev.\n passer_name_id:receiver_name_id (Intercept) 0.1702   0.4126  \n passer_name_id                  (Intercept) 0.0000   0.0000  \nNumber of obs: 12741, groups:  \npasser_name_id:receiver_name_id, 421; passer_name_id, 31\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.88268    0.03281    26.9   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\n\n\n2.) Implicit nested effects\nAn alternative way to fit the same model, if and only if one level is completely nested within another, is by simply specifying the two varying intercepts separately:\n\nrec_nested_glmm2 &lt;- glmer(complete_pass ~ (1 | passer_name_id) + (1 | receiver_name_id),\n                         family = binomial, data = nested_passing_data)\n\nboundary (singular) fit: see help('isSingular')\n\nsummary(rec_nested_glmm2)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ (1 | passer_name_id) + (1 | receiver_name_id)\n   Data: nested_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 15488.6  15510.9  -7741.3  15482.6    12738 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.3285 -1.2747  0.5849  0.6815  0.9387 \n\nRandom effects:\n Groups           Name        Variance Std.Dev.\n receiver_name_id (Intercept) 0.1702   0.4126  \n passer_name_id   (Intercept) 0.0000   0.0000  \nNumber of obs: 12741, groups:  receiver_name_id, 421; passer_name_id, 31\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.88268    0.03281    26.9   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nIf you look closely at the summary output, this is the same model as before (same AIC, BIC, fixed effect estimates) including the random effects.\nFor both of these models, the passer_name_id variance is estimated to be 0, with the indication that any variance in completion probability is at the receiver level. Part of the concern of fitting this model is the fact we’ve approached a boundary constraint. Consider that the variance for the passer_name_id random effect is 0. This is at the boundary of possible values for the variance term since variance can only be \\(\\geq 0\\). Because this model is fit with maximum likelihood estimation via some optimization technique, this means that the best model fit is likely an impossible value for the passer_name_id variance (i.e., something negative). But we cannot have a negative variance value so the boundary at 0 is used instead. The presence of a boundary constraint should be concerning to you - it likely means that we need to re-parameterize our model (i.e., pick a different specification for it). If we did not compare about the parameters that hit the boundary, then we do not need to worry about it. In this context, I should be concerned that the variance for passers is 0.\nDespite these issues, we can also compute the ICC for the different random effects in this model as before:\n\nVarCorr(rec_nested_glmm2) |&gt;\n  as_tibble() |&gt;\n  # Note the use of sum(vcov) to work later with multiple levels\n  mutate(icc = vcov / (sum(vcov) + (pi^2 / 3))) |&gt;\n  dplyr::select(grp, icc)\n\n# A tibble: 2 × 2\n  grp                 icc\n  &lt;chr&gt;             &lt;dbl&gt;\n1 receiver_name_id 0.0492\n2 passer_name_id   0     \n\n\nWe can also update this model to consider random slopes at both levels for air_yards (note this will take a bit of time to run):\n\nrec_air_nested_glmm &lt;- glmer(complete_pass ~ air_yards + (air_yards | passer_name_id) + \n                               (air_yards | receiver_name_id),\n                             family = binomial, data = nested_passing_data)\n\nboundary (singular) fit: see help('isSingular')\n\nsummary(rec_air_nested_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: \ncomplete_pass ~ air_yards + (air_yards | passer_name_id) + (air_yards |  \n    receiver_name_id)\n   Data: nested_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 14436.6  14496.2  -7210.3  14420.6    12733 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4281 -0.9201  0.5031  0.6104  4.1502 \n\nRandom effects:\n Groups           Name        Variance  Std.Dev. Corr \n receiver_name_id (Intercept) 6.502e-02 0.254998      \n                  air_yards   3.263e-04 0.018064 -0.78\n passer_name_id   (Intercept) 3.073e-03 0.055438      \n                  air_yards   3.906e-06 0.001976 -1.00\nNumber of obs: 12741, groups:  receiver_name_id, 421; passer_name_id, 31\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.414036   0.034630   40.83   &lt;2e-16 ***\nair_yards   -0.068676   0.002636  -26.05   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.694\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nFrom this summary, we see a few changes to the output. There are the estimates for the different parameters we’ve now accounted for in this more complex model such as the variances for the intercepts and air_yards slopes. You can see that the variance for the passer-level information is no longer 0 - meaning that there is some QB level variation explaining completion probability. However, we once again run into a boundary constraint problem! Look at the correlation for the passer_name_id random effects reported under the Corr column: it’s -1. As correlation coefficients are bounded between -1 and 1, this is again another boundary estimate likely indicating the model parameterization is problematic."
  },
  {
    "objectID": "demos/07-nested-crossed-effects.html#crossed-effects",
    "href": "demos/07-nested-crossed-effects.html#crossed-effects",
    "title": "Lecture 8: Nested and crossed random effects",
    "section": "Crossed effects",
    "text": "Crossed effects\nIn the examples above, we assumed that the receivers only caught passes from one QB, and that QBs did not overlap in terms of the receivers they threw to. However, this is not true - players change teams via trades and signings such that we can observe crossing of the different levels. This is especially true over the course of multiple seasons. Furthermore, if we want to account for the opposing defense on a passing play - we know for a fact that there is no longer nesting structure since any opposing defense is not associated with a single QB/receiver group combination. Teams play several different teams throughout the course of the season. This leads to a structure that is no longer nested, but called crossed effects.\nUsing the original nfl_passing_data corresponding to all passing plays during the 2023 and 2024 seasons, we fit a multilevel model that accounts for air yards with varying intercepts for the QB/passer, receiver, and opposing defense using the same syntax for a single varying intercept term:\n\nfull_pass_glmm &lt;- glmer(complete_pass ~ air_yards + (1 | passer_name_id) +\n                          (1 | receiver_name_id) + (1 | defteam),\n                        family = binomial, data = nfl_passing_data)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\n\nsummary(full_pass_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: \ncomplete_pass ~ air_yards + (1 | passer_name_id) + (1 | receiver_name_id) +  \n    (1 | defteam)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 40405.5  40447.9 -20197.7  40395.5    35982 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2661 -0.9074  0.5001  0.6348  3.8108 \n\nRandom effects:\n Groups           Name        Variance Std.Dev.\n receiver_name_id (Intercept) 0.167115 0.40880 \n passer_name_id   (Intercept) 0.018565 0.13625 \n defteam          (Intercept) 0.003775 0.06144 \nNumber of obs: 35987, groups:  \nreceiver_name_id, 635; passer_name_id, 141; defteam, 32\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.225964   0.034411   35.63   &lt;2e-16 ***\nair_yards   -0.064595   0.001353  -47.74   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.298\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\n\n\nUsing this type of model, we can compare the different estimates of the variances to provide us with an understanding of which groups (passer vs receiver vs defense) explain more variation in the outcome. The code chunk below quickly computes the ICC value for each group term:\n\nVarCorr(full_pass_glmm) |&gt;\n  as_tibble() |&gt;\n  # Note the use of sum(vcov) to work later with multiple levels\n  mutate(icc = vcov / (sum(vcov) + (pi^2 / 3))) |&gt;\n  dplyr::select(grp, icc)\n\n# A tibble: 3 × 2\n  grp                  icc\n  &lt;chr&gt;              &lt;dbl&gt;\n1 receiver_name_id 0.0480 \n2 passer_name_id   0.00534\n3 defteam          0.00109\n\n\nAccording to this model, receivers display more variance followed (by a large gap) by passers and then defense. This is not necessarily the most optimal model, but it provides a reasonable starting point for understanding the receiver-level importance in modeling completion probability. Next steps from this would be to potentially explore random slopes between the different groups and air yards, but more importantly we could account for other information (such as QB hit or the different contextual variables in the play-by-play data). I will leave that for you to explore on your own…"
  },
  {
    "objectID": "demos/04b-cpoe.html",
    "href": "demos/04b-cpoe.html",
    "title": "Lecture 5: Completion Percentage Over Expectation",
    "section": "",
    "text": "The goal of this demo is begin our build-up to understanding the importance of multilevel modeling in sports. We’ll do this in the context of modeling completion probability for pass attempts in the NFL based on games during the 2023 and 2024 regular seasons. The dataset and code used to initialize it (init_nfl_passing_data.R) are available on Canvas.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/04b-cpoe.html#introduction",
    "href": "demos/04b-cpoe.html#introduction",
    "title": "Lecture 5: Completion Percentage Over Expectation",
    "section": "",
    "text": "The goal of this demo is begin our build-up to understanding the importance of multilevel modeling in sports. We’ll do this in the context of modeling completion probability for pass attempts in the NFL based on games during the 2023 and 2024 regular seasons. The dataset and code used to initialize it (init_nfl_passing_data.R) are available on Canvas.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/04b-cpoe.html#modeling-completion-probability-with-logistic-regression",
    "href": "demos/04b-cpoe.html#modeling-completion-probability-with-logistic-regression",
    "title": "Lecture 5: Completion Percentage Over Expectation",
    "section": "Modeling completion probability with logistic regression",
    "text": "Modeling completion probability with logistic regression\nSimilar to how we modeled expected goals in hockey, we will use a logistic regression model to estimate the probability of a complete pass (i.e., when complete_pass equals 1) based on a few variables:\n\npass_location: a categorical variable denoting which side of the field the ball was thrown to, either left, middle, or right (based on manually charted data). We’re going to be lazy and treat left as the reference level, but one should think more carefully about which level is more appropriate.\nair_yards: a quantitative variable indicating how many yards the ball traveled in the air perpendicular to the line of scrimmage. This does not measure the actual distance traveled by the ball (e.g., if the QB throws the ball across the field but only to the line of scrimmage then it has air yards of 0), but still provides measure for the length of the pass.\nqb_hit: a binary indicator variable denoting whether or not the QB was hit on the play, serving as a proxy for plays where the QB observes pressure (i.e., a tougher situation to make a throw).\n\nThe following code chunk fits the logistic regression model on all of the data:\n\nlogit_completion &lt;- glm(complete_pass ~ pass_location + air_yards + qb_hit,\n                        data = nfl_passing_data, family = \"binomial\")\n\nsummary(logit_completion)\n\n\nCall:\nglm(formula = complete_pass ~ pass_location + air_yards + qb_hit, \n    family = \"binomial\", data = nfl_passing_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1567  -1.1713   0.7187   0.8481   2.3971  \n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          1.221994   0.021886  55.834  &lt; 2e-16 ***\npass_locationmiddle  0.164057   0.032141   5.104 3.32e-07 ***\npass_locationright  -0.090248   0.026235  -3.440 0.000582 ***\nair_yards           -0.058879   0.001203 -48.957  &lt; 2e-16 ***\nqb_hit              -1.080257   0.038836 -27.816  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46543  on 35986  degrees of freedom\nResidual deviance: 42900  on 35982  degrees of freedom\nAIC: 42910\n\nNumber of Fisher Scoring iterations: 4\n\n\nEXERCISE: How should we evaluate this model? Perform the appropriate type of evaluation on your own time. Are there any variables that be adjusted in some way? Are there are any other variables in the dataset that we should account for?"
  },
  {
    "objectID": "demos/04b-cpoe.html#computing-cpoe-by-allocating-residuals",
    "href": "demos/04b-cpoe.html#computing-cpoe-by-allocating-residuals",
    "title": "Lecture 5: Completion Percentage Over Expectation",
    "section": "Computing CPOE by allocating residuals",
    "text": "Computing CPOE by allocating residuals\nAs discussed in lecture, completion percentage over expectation (CPOE) is a very popular statistic in football analytics that is commonly used for measuring QB performance. The idea behind the stat is very simple: for every pass attempt we can compute the residual between the pass outcome (1 for completion, 0 for incomplete) and the estimated completion probability based on our model. We can then accumulate and average over these residuals to compute CPOE, representing how many more completions are observed than expected on average. For \\(n\\) pass attempts, the CPOE is:\n\\[\nCPOE = \\frac{1}{n} \\sum_i^n (Outcome_i - \\widehat{Pr}(Outcome_i | X_i))\n\\] where \\(Outcome_i\\) is 1 for complete and 0 for incomplete or an interception.\nThe following code chunk performs this calculation for every passer in the dataset, along with computing the observed number of completions and completion percentage, as well as the sum and average of the completion probability estimates to get the expected number of completions and expected completion percentage respectively.\n\n# First add the predicted probabilities to the dataset:\nnfl_passing_data &lt;- nfl_passing_data |&gt;\n  mutate(comp_prob = logit_completion$fitted.values,\n         # Compute the residual:\n         comp_resid = complete_pass - comp_prob)\n\n# Now create the QB summary table:\nqb_summary &lt;- nfl_passing_data |&gt;\n  group_by(passer_name_id) |&gt;\n  summarize(n_pass = n(),\n            comps = sum(complete_pass),\n            comp_perc = mean(complete_pass),\n            ex_comps = sum(comp_prob),\n            ex_comp_perc = mean(comp_prob),\n            cpoe = mean(comp_resid),\n            .groups = \"drop\")\nqb_summary\n\n# A tibble: 141 × 7\n   passer_name_id          n_pass comps comp_perc ex_comps ex_comp_perc    cpoe\n   &lt;chr&gt;                    &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n 1 A.Cole_00-0035190            1     1     1        0.710        0.710  0.290 \n 2 A.Dalton_00-0027973        218   140     0.642  144.           0.661 -0.0187\n 3 A.Lazard_00-0034521          1     0     0        0.533        0.533 -0.533 \n 4 A.McCarron_00-0031288        5     4     0.8      3.93         0.786  0.0136\n 5 A.Mitchell_00-0039890        1     1     1        0.829        0.829  0.171 \n 6 A.O'Connell_00-0038579     584   367     0.628  383.           0.656 -0.0277\n 7 A.Richardson_00-0039164    346   176     0.509  209.           0.603 -0.0944\n 8 A.Rodgers_00-0023459       585   368     0.629  388.           0.663 -0.0334\n 9 A.St. Brown_00-0036963       1     1     1        0.717        0.717  0.283 \n10 B.Allen_00-0032434          30    17     0.567   19.7          0.657 -0.0905\n# ℹ 131 more rows\n\n\nWe can create a custom table with the top 10 QBs in terms of CPOE (with a minimum of 200 passing attempts) using the gt package:\n\nlibrary(gt)\n\nWarning: package 'gt' was built under R version 4.2.3\n\nqb_summary |&gt;\n  filter(n_pass &gt;= 200) |&gt;\n  # Sort by CPOE in descending order:\n  arrange(desc(cpoe)) |&gt;\n  # Only grab the top 10 QBs:\n  slice(1:10) |&gt;\n  # Round the various stats and multiple the %s by 100 for display reasons\n  mutate(comp_perc = round(comp_perc * 100, digits = 4),\n         ex_comps = round(ex_comps, digits = 4),\n         ex_comp_perc = round(ex_comp_perc * 100, digits = 4),\n         cpoe = round(cpoe * 100, digits = 4)) |&gt;\n  # Rename the columns for display purposes:\n  rename(`QB_ID` = passer_name_id,\n         `# Passes` = n_pass,\n         `# Comps` = comps,\n         `Comp %` = comp_perc,\n         `Exp # Comps` = ex_comps,\n         `Exp Comp %` = ex_comp_perc,\n         `CPOE` = cpoe) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Top 10 QBs based on CPOE (minimum of 200 pass attempts)\",\n             subtitle = \"Based on 2023-2024 regular season games accessed using nflreadr\") |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = \"right\",\n        color = \"black\",\n        weight = px(3)\n      )\n    ),\n    # Where to place the thick border\n    locations = list(\n      cells_body(\n        columns = c(`# Passes`)\n      )\n    )\n  ) |&gt;\n  # Which variables to color by\n  data_color(columns = c(`Comp %`,\n                         `Exp Comp %`,\n                         `CPOE`),\n             colors = scales::col_numeric(\n               palette = c(\"darkblue\", \"darkorange\"),\n               domain = NULL\n             ))\n\nWarning: Since gt v0.9.0, the `colors` argument has been deprecated.\n• Please use the `fn` argument instead.\nThis warning is displayed once every 8 hours.\n\n\n\n\n\n\n\n\nTop 10 QBs based on CPOE (minimum of 200 pass attempts)\n\n\nBased on 2023-2024 regular season games accessed using nflreadr\n\n\nQB_ID\n# Passes\n# Comps\nComp %\nExp # Comps\nExp Comp %\nCPOE\n\n\n\n\nJ.Browning_00-0035100\n243\n171\n70.3704\n161.6712\n66.5313\n3.8390\n\n\nK.Cousins_00-0029604\n758\n519\n68.4697\n490.1913\n64.6690\n3.8006\n\n\nJ.Burrow_00-0036442\n1014\n704\n69.4280\n666.7347\n65.7529\n3.6751\n\n\nJ.Goff_00-0033106\n1137\n797\n70.0967\n755.9979\n66.4906\n3.6062\n\n\nT.Tagovailoa_00-0036212\n955\n679\n71.0995\n644.5809\n67.4954\n3.6041\n\n\nB.Purdy_00-0037834\n891\n608\n68.2379\n576.0082\n64.6474\n3.5905\n\n\nD.Prescott_00-0033077\n874\n595\n68.0778\n568.9769\n65.1003\n2.9775\n\n\nD.Carr_00-0031280\n827\n564\n68.1983\n541.8996\n65.5259\n2.6724\n\n\nJ.Daniels_00-0039910\n478\n331\n69.2469\n318.3892\n66.6086\n2.6382\n\n\nL.Jackson_00-0034796\n925\n623\n67.3514\n598.8349\n64.7389\n2.6124\n\n\n\n\n\n\n\nBut this table only displays the QB rankings. We can do the same for receivers, from the view point of catches over expectation:\n\nrec_summary &lt;- nfl_passing_data |&gt;\n  group_by(receiver_name_id) |&gt;\n  summarize(n_pass = n(),\n            n_rec = sum(complete_pass),\n            catch_perc = mean(complete_pass),\n            ex_rec = sum(comp_prob),\n            ex_catch_perc = mean(comp_prob),\n            cpoe = mean(comp_resid),\n            .groups = \"drop\")\n\nrec_summary |&gt;\n  filter(n_pass &gt;= 50) |&gt;\n  # Sort by CPOE in descending order:\n  arrange(desc(cpoe)) |&gt;\n  # Only grab the top 10 QBs:\n  slice(1:10) |&gt;\n  # Round the various stats and multiple the %s by 100 for display reasons\n  mutate(catch_perc = round(catch_perc * 100, digits = 4),\n         ex_rec = round(ex_rec, digits = 4),\n         ex_catch_perc = round(ex_catch_perc * 100, digits = 4),\n         cpoe = round(cpoe * 100, digits = 4)) |&gt;\n  # Rename the columns for display purposes:\n  rename(`Receiver_ID` = receiver_name_id,\n         `# Targets` = n_pass,\n         `# Catches` = n_rec,\n         `Catch %` = catch_perc,\n         `Exp # Catches` = ex_rec,\n         `Exp Catch %` = ex_catch_perc,\n         `CPOE` = cpoe) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Top 10 receivers based on CPOE (minimum of 50 targets)\",\n             subtitle = \"Based on 2023-2024 regular season games accessed using nflreadr\") |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = \"right\",\n        color = \"black\",\n        weight = px(3)\n      )\n    ),\n    # Where to place the thick border\n    locations = list(\n      cells_body(\n        columns = c(`# Targets`)\n      )\n    )\n  ) |&gt;\n  # Which variables to color by\n  data_color(columns = c(`Catch %`,\n                         `Exp Catch %`,\n                         `CPOE`),\n             colors = scales::col_numeric(\n               palette = c(\"darkblue\", \"darkorange\"),\n               domain = NULL\n             ))\n\n\n\n\n\n\n\nTop 10 receivers based on CPOE (minimum of 50 targets)\n\n\nBased on 2023-2024 regular season games accessed using nflreadr\n\n\nReceiver_ID\n# Targets\n# Catches\nCatch %\nExp # Catches\nExp Catch %\nCPOE\n\n\n\n\nC.Kmet_00-0036290\n145\n120\n82.7586\n98.0541\n67.6235\n15.1351\n\n\nK.Raymond_00-0032464\n66\n52\n78.7879\n42.2940\n64.0818\n14.7061\n\n\nR.White_00-0037256\n127\n115\n90.5512\n97.1515\n76.4973\n14.0539\n\n\nG.Kittle_00-0033288\n184\n143\n77.7174\n118.9066\n64.6232\n13.0942\n\n\nD.Smith_00-0036912\n201\n149\n74.1294\n124.9528\n62.1656\n11.9638\n\n\nL.McConkey_00-0039915\n112\n82\n73.2143\n68.8615\n61.4835\n11.7308\n\n\nK.Shakir_00-0037261\n145\n115\n79.3103\n98.0211\n67.6007\n11.7096\n\n\nS.Perine_00-0033526\n91\n78\n85.7143\n67.4318\n74.1009\n11.6134\n\n\nM.Andrews_00-0034753\n130\n100\n76.9231\n84.9763\n65.3664\n11.5567\n\n\nA.Thielen_00-0030035\n199\n151\n75.8794\n128.1946\n64.4194\n11.4600\n\n\n\n\n\n\n\nAnd again for opposing defenses:\n\ndef_summary &lt;- nfl_passing_data |&gt;\n  group_by(defteam) |&gt;\n  summarize(n_pass = n(),\n            comps = sum(complete_pass),\n            comp_perc = mean(complete_pass),\n            ex_comps = sum(comp_prob),\n            ex_comp_perc = mean(comp_prob),\n            cpoe = mean(comp_resid),\n            .groups = \"drop\")\n\ndef_summary |&gt;\n  # Sort by CPOE in ascending order:\n  arrange(cpoe) |&gt;\n  # Round the various stats and multiple the %s by 100 for display reasons\n  mutate(comp_perc = round(comp_perc * 100, digits = 4),\n         ex_comps = round(ex_comps, digits = 4),\n         ex_comp_perc = round(ex_comp_perc * 100, digits = 4),\n         cpoe = round(cpoe * 100, digits = 4)) |&gt;\n  # Rename the columns for display purposes:\n  rename(`Team` = defteam,\n         `# Passes` = n_pass,\n         `# Comps` = comps,\n         `Comp %` = comp_perc,\n         `Exp # Comps` = ex_comps,\n         `Exp Comp %` = ex_comp_perc,\n         `CPOE` = cpoe) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Team defenses ranked based on CPOE\",\n             subtitle = \"Based on 2023-2024 regular season games accessed using nflreadr\") |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = \"right\",\n        color = \"black\",\n        weight = px(3)\n      )\n    ),\n    # Where to place the thick border\n    locations = list(\n      cells_body(\n        columns = c(`# Passes`)\n      )\n    )\n  ) |&gt;\n  # Which variables to color by\n  data_color(columns = c(`Comp %`,\n                         `Exp Comp %`,\n                         `CPOE`),\n             colors = scales::col_numeric(\n               palette = c(\"darkblue\", \"darkorange\"),\n               domain = NULL\n             ))\n\n\n\n\n\n\n\nTeam defenses ranked based on CPOE\n\n\nBased on 2023-2024 regular season games accessed using nflreadr\n\n\nTeam\n# Passes\n# Comps\nComp %\nExp # Comps\nExp Comp %\nCPOE\n\n\n\n\nNO\n1145\n699\n61.0480\n741.1526\n64.7295\n-3.6814\n\n\nCLE\n1040\n623\n59.9038\n659.3903\n63.4029\n-3.4991\n\n\nNYJ\n1039\n640\n61.5977\n675.6156\n65.0256\n-3.4279\n\n\nBAL\n1257\n780\n62.0525\n814.9431\n64.8324\n-2.7799\n\n\nPIT\n1148\n730\n63.5889\n748.4911\n65.1996\n-1.6107\n\n\nLA\n1141\n721\n63.1902\n736.0505\n64.5092\n-1.3191\n\n\nPHI\n1189\n762\n64.0875\n775.4755\n65.2208\n-1.1334\n\n\nLAC\n1163\n756\n65.0043\n763.7140\n65.6676\n-0.6633\n\n\nDET\n1194\n744\n62.3116\n750.9671\n62.8951\n-0.5835\n\n\nKC\n1119\n715\n63.8963\n720.1965\n64.3607\n-0.4644\n\n\nWAS\n1090\n703\n64.4954\n707.7514\n64.9313\n-0.4359\n\n\nLV\n1117\n746\n66.7860\n747.6657\n66.9352\n-0.1491\n\n\nHOU\n1118\n708\n63.3274\n709.6572\n63.4756\n-0.1482\n\n\nNE\n1105\n716\n64.7964\n715.9658\n64.7933\n0.0031\n\n\nSEA\n1152\n761\n66.0590\n760.2891\n65.9973\n0.0617\n\n\nDAL\n1014\n657\n64.7929\n655.2981\n64.6251\n0.1678\n\n\nCHI\n1119\n735\n65.6836\n732.3731\n65.4489\n0.2348\n\n\nMIA\n1134\n745\n65.6966\n740.9915\n65.3432\n0.3535\n\n\nNYG\n1082\n720\n66.5434\n715.0393\n66.0850\n0.4585\n\n\nCAR\n1008\n669\n66.3690\n663.5180\n65.8252\n0.5439\n\n\nSF\n1132\n748\n66.0777\n741.1312\n65.4710\n0.6068\n\n\nJAX\n1196\n793\n66.3043\n784.0176\n65.5533\n0.7510\n\n\nDEN\n1173\n775\n66.0699\n764.9314\n65.2115\n0.8584\n\n\nATL\n1124\n744\n66.1922\n731.5522\n65.0847\n1.1075\n\n\nGB\n1083\n723\n66.7590\n710.5881\n65.6129\n1.1461\n\n\nBUF\n1124\n759\n67.5267\n742.8475\n66.0896\n1.4371\n\n\nTEN\n1041\n701\n67.3391\n684.8598\n65.7886\n1.5504\n\n\nTB\n1235\n822\n66.5587\n802.8306\n65.0065\n1.5522\n\n\nCIN\n1124\n736\n65.4804\n718.5373\n63.9268\n1.5536\n\n\nIND\n1105\n748\n67.6923\n724.5386\n65.5691\n2.1232\n\n\nMIN\n1237\n841\n67.9871\n808.1054\n65.3278\n2.6592\n\n\nARI\n1039\n717\n69.0087\n688.5146\n66.2670\n2.7416\n\n\n\n\n\n\n\nThe point of going through these three different rankings is to indicate how each group of variables: QB, receiver, and defense, each display variation that we ideally want to account for in a model. This will be the topic of discussion for the next so many lectures."
  },
  {
    "objectID": "demos/04b-cpoe.html#estimating-coefficients-for-qbs",
    "href": "demos/04b-cpoe.html#estimating-coefficients-for-qbs",
    "title": "Lecture 5: Completion Percentage Over Expectation",
    "section": "Estimating coefficients for QBs",
    "text": "Estimating coefficients for QBs\nAs a starting point, we’ll fit another logistic regression model for completion probability but now we’ll account for the QB attempting the pass via a categorical variable to estimate coefficients for each passer (note this will take a slightly longer amount of time to run):\n\npasser_logit &lt;- glm(complete_pass ~ pass_location + air_yards + qb_hit +\n                      passer_name_id,\n                    data = nfl_passing_data, family = \"binomial\")\nsummary(passer_logit)\n\n\nCall:\nglm(formula = complete_pass ~ pass_location + air_yards + qb_hit + \n    passer_name_id, family = \"binomial\", data = nfl_passing_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.2047  -1.1610   0.7084   0.8486   2.4092  \n\nCoefficients:\n                                               Estimate Std. Error z value\n(Intercept)                                   13.890565 535.411133   0.026\npass_locationmiddle                            0.158477   0.032375   4.895\npass_locationright                            -0.087527   0.026422  -3.313\nair_yards                                     -0.059243   0.001213 -48.837\nqb_hit                                        -1.085293   0.039252 -27.649\npasser_name_idA.Dalton_00-0027973            -12.756376 535.411153  -0.024\npasser_name_idA.Lazard_00-0034521            -26.361977 757.185710  -0.035\npasser_name_idA.McCarron_00-0031288          -12.585484 535.412306  -0.024\npasser_name_idA.Mitchell_00-0039890           -0.679955 757.185711  -0.001\npasser_name_idA.O'Connell_00-0038579         -12.798841 535.411140  -0.024\npasser_name_idA.Richardson_00-0039164        -13.102355 535.411145  -0.024\npasser_name_idA.Rodgers_00-0023459           -12.826538 535.411140  -0.024\npasser_name_idA.St. Brown_00-0036963          -0.028285 757.185711   0.000\npasser_name_idB.Allen_00-0032434             -13.081262 535.411270  -0.024\npasser_name_idB.Anger_00-0029692             -13.600205 535.413021  -0.025\npasser_name_idB.Gabbert_00-0027948           -13.235460 535.411257  -0.025\npasser_name_idB.Hoyer_00-0026625             -13.221568 535.411227  -0.025\npasser_name_idB.Mann_00-0036313                0.414699 757.185710   0.001\npasser_name_idB.Mayfield_00-0034855          -12.576821 535.411136  -0.023\npasser_name_idB.Nix_00-0039732               -12.658471 535.411141  -0.024\npasser_name_idB.Purdy_00-0037834             -12.487777 535.411138  -0.023\npasser_name_idB.Rypien_00-0034955            -13.404705 535.411240  -0.025\npasser_name_idB.Young_00-0039150             -12.850871 535.411137  -0.024\npasser_name_idB.Zappe_00-0038108             -12.971181 535.411150  -0.024\npasser_name_idC.Beathard_00-0033936          -12.215626 535.411236  -0.023\npasser_name_idC.Godwin_00-0033921            -26.302734 757.185710  -0.035\npasser_name_idC.Keenum_00-0028986            -12.803016 535.411216  -0.024\npasser_name_idC.Kirk_00-0034775              -13.062503 535.413315  -0.024\npasser_name_idC.Rush_00-0033662              -12.893358 535.411145  -0.024\npasser_name_idC.Stroud_00-0039163            -12.669463 535.411137  -0.024\npasser_name_idC.Sutton_00-0034348              0.355204 648.697971   0.001\npasser_name_idC.Tune_00-0038582              -13.095103 535.411316  -0.024\npasser_name_idC.Wentz_00-0032950             -12.556132 535.411241  -0.023\npasser_name_idC.Williams_00-0039918          -12.769664 535.411140  -0.024\npasser_name_idC.Wilson_00-0034418              0.947884 757.185710   0.001\npasser_name_idCo.Heyward_00-0037304          -27.606075 757.185710  -0.036\npasser_name_idD.Brown_00-0036626             -12.794574 535.413549  -0.024\npasser_name_idD.Carr_00-0031280              -12.529190 535.411138  -0.023\npasser_name_idD.Henry_00-0032764             -12.628181 535.412580  -0.024\npasser_name_idD.Hopkins_00-0030564           -26.430581 757.185712  -0.035\npasser_name_idD.Jones_00-0035710             -12.673487 535.411142  -0.024\npasser_name_idD.Lock_00-0035704              -12.933044 535.411149  -0.024\npasser_name_idD.London_00-0037238              0.386415 757.185711   0.001\npasser_name_idD.Maye_00-0039851              -12.632783 535.411146  -0.024\npasser_name_idD.Mills_00-0036898             -13.397939 535.411185  -0.025\npasser_name_idD.Montgomery_00-0035685         -0.059243 757.185710   0.000\npasser_name_idD.Mooney_00-0036309            -25.158198 757.185711  -0.033\npasser_name_idD.Moore_00-0034827             -25.414093 757.185711  -0.034\npasser_name_idD.Prescott_00-0033077          -12.516723 535.411138  -0.023\npasser_name_idD.Ridder_00-0038122            -12.707752 535.411142  -0.024\npasser_name_idD.Samuel_00-0035719            -25.632140 757.185711  -0.034\npasser_name_idD.Singletary_00-0035250          1.203779 757.185711   0.002\npasser_name_idD.Thompson-Robinson_00-0038583 -13.280235 535.411150  -0.025\npasser_name_idD.Watson_00-0033537            -12.699020 535.411144  -0.024\npasser_name_idD.Wicks_00-0038393               0.296214 757.185710   0.000\npasser_name_idE.Stick_00-0035282             -12.780861 535.411158  -0.024\npasser_name_idG.Minshew_00-0035289           -12.793448 535.411138  -0.024\npasser_name_idG.Smith_00-0030565             -12.554024 535.411137  -0.023\npasser_name_idG.Wilson_00-0037740            -26.776676 757.185710  -0.035\npasser_name_idH.Hooker_00-0038550            -12.764219 535.411614  -0.024\npasser_name_idJ.Allen_00-0034857             -12.605147 535.411137  -0.024\npasser_name_idJ.Brissett_00-0033119          -12.795409 535.411157  -0.024\npasser_name_idJ.Browning_00-0035100          -12.466457 535.411153  -0.023\npasser_name_idJ.Burrow_00-0036442            -12.479120 535.411137  -0.023\npasser_name_idJ.Chase_00-0036900              -0.739198 757.185711  -0.001\npasser_name_idJ.Coker_00-0039491               0.710913 757.185710   0.001\npasser_name_idJ.Daniels_00-0039910           -12.529462 535.411142  -0.023\npasser_name_idJ.Dobbs_00-0033949             -12.680533 535.411142  -0.024\npasser_name_idJ.Driskel_00-0032436           -13.142576 535.411295  -0.025\npasser_name_idJ.Fields_00-0036945            -12.746152 535.411141  -0.024\npasser_name_idJ.Flacco_00-0026158            -12.692742 535.411142  -0.024\npasser_name_idJ.Fox_00-0035156                 0.405666 757.185711   0.001\npasser_name_idJ.Garoppolo_00-0031345         -12.645310 535.411154  -0.024\npasser_name_idJ.Goff_00-0033106              -12.480962 535.411137  -0.023\npasser_name_idJ.Haener_00-0038998            -13.370829 535.411240  -0.025\npasser_name_idJ.Hall_00-0038598              -12.607966 535.411361  -0.024\npasser_name_idJ.Hekker_00-0028872            -14.161782 535.412596  -0.026\npasser_name_idJ.Herbert_00-0036355           -12.572364 535.411137  -0.023\npasser_name_idJ.Hurts_00-0036389             -12.578289 535.411137  -0.023\npasser_name_idJ.Jefferson_00-0036322         -12.816070 535.413880  -0.024\npasser_name_idJ.Johnson_00-0026300           -11.709013 535.412653  -0.022\npasser_name_idJ.Love_00-0036264              -12.667203 535.411137  -0.024\npasser_name_idJ.McKinnon_00-0031376           -0.660704 757.185711  -0.001\npasser_name_idJ.Meyers_00-0034960            -12.864965 535.412549  -0.024\npasser_name_idJ.Milton_00-0039398            -11.960663 535.411326  -0.022\npasser_name_idJ.Mixon_00-0033897             -26.776676 757.185710  -0.035\npasser_name_idJ.Reeves-Maybin_00-0033557       1.066370 757.185710   0.001\npasser_name_idJ.Scott_00-0034162              -0.473942 757.185710  -0.001\npasser_name_idJ.Smith_00-0033858             -26.954405 757.185710  -0.036\npasser_name_idJ.Smith-Njigba_00-0038543        2.921819 757.185712   0.004\npasser_name_idJ.Stidham_00-0035264           -12.791442 535.411201  -0.024\npasser_name_idJ.Winston_00-0031503           -12.807717 535.411145  -0.024\npasser_name_idK.Allen_00-0030279             -13.456050 535.412545  -0.025\npasser_name_idK.Allen_00-0034577               0.287180 757.185711   0.000\npasser_name_idK.Bourne_00-0033307            -27.369104 757.185710  -0.036\npasser_name_idK.Cousins_00-0029604           -12.477423 535.411139  -0.023\npasser_name_idK.Gainwell_00-0036919            0.682629 757.185711   0.001\npasser_name_idK.Murray_00-0035228            -12.632661 535.411138  -0.024\npasser_name_idK.Pickett_00-0038102           -12.813749 535.411144  -0.024\npasser_name_idK.Toney_00-0036913             -26.421220 757.185710  -0.035\npasser_name_idK.Trask_00-0036928             -13.846801 535.413023  -0.026\npasser_name_idL.Cooke_00-0034437              -0.087527 757.185711   0.000\npasser_name_idL.Jackson_00-0034796           -12.534336 535.411137  -0.023\npasser_name_idL.Woodside_00-0034438          -12.372938 535.412433  -0.023\npasser_name_idM.Jones_00-0036972             -12.730917 535.411140  -0.024\npasser_name_idM.Killebrew_00-0032399         -26.627233 757.185711  -0.035\npasser_name_idM.Mariota_00-0032268           -12.177335 535.411213  -0.023\npasser_name_idM.Nabers_00-0039337            -27.309861 757.185710  -0.036\npasser_name_idM.Penix_00-0039917             -12.864351 535.411173  -0.024\npasser_name_idM.Rudolph_00-0034771           -12.612450 535.411148  -0.024\npasser_name_idM.Stafford_00-0026498          -12.691916 535.411137  -0.024\npasser_name_idM.Trubisky_00-0033869          -12.608433 535.411168  -0.024\npasser_name_idM.White_00-0034401             -13.557147 535.411388  -0.025\npasser_name_idM.Willis_00-0038128            -12.169524 535.411227  -0.023\npasser_name_idN.Mullens_00-0033319           -12.252149 535.411165  -0.023\npasser_name_idP.Mahomes_00-0033873           -12.588532 535.411136  -0.024\npasser_name_idP.Walker_00-0033275            -13.256732 535.411170  -0.025\npasser_name_idR.Dixon_00-0032943              -0.779189 757.185711  -0.001\npasser_name_idR.Pearsall_00-0039916          -26.776676 757.185710  -0.035\npasser_name_idR.Tannehill_00-0029701         -12.556541 535.411153  -0.023\npasser_name_idR.Wilson_00-0029263            -12.574812 535.411138  -0.023\npasser_name_idS.Clifford_00-0038391            1.531279 757.185712   0.002\npasser_name_idS.Darnold_00-0034869           -12.577759 535.411140  -0.023\npasser_name_idS.Diggs_00-0031588              -0.473942 757.185710  -0.001\npasser_name_idS.Howell_00-0037077            -12.789672 535.411139  -0.024\npasser_name_idS.Rattler_00-0039376           -13.025311 535.411151  -0.024\npasser_name_idS.Thompson_00-0037327          -12.645821 535.411265  -0.024\npasser_name_idT.Atwell_00-0036849            -25.354850 757.185711  -0.033\npasser_name_idT.Bagent_00-0038416            -12.767563 535.411164  -0.024\npasser_name_idT.Boyd_00-0033009              -27.029112 630.160400  -0.043\npasser_name_idT.Boyle_00-0034177             -13.008536 535.411167  -0.024\npasser_name_idT.DeVito_00-0038476            -12.758477 535.411152  -0.024\npasser_name_idT.Heinicke_00-0031800          -13.073210 535.411163  -0.024\npasser_name_idT.Hill_00-0033357              -12.973565 535.411426  -0.024\npasser_name_idT.Huntley_00-0035993           -12.729958 535.411158  -0.024\npasser_name_idT.Lance_00-0037012             -12.987293 535.411237  -0.024\npasser_name_idT.Lawrence_00-0036971          -12.686691 535.411138  -0.024\npasser_name_idT.McKee_00-0038400             -12.608173 535.411231  -0.024\npasser_name_idT.Morstead_00-0027114            0.267929 757.185711   0.000\npasser_name_idT.Siemian_00-0032156           -13.204427 535.411159  -0.025\npasser_name_idT.Tagovailoa_00-0036212        -12.480383 535.411137  -0.023\npasser_name_idT.Taylor_00-0028118            -12.484961 535.411157  -0.023\npasser_name_idT.Townsend_00-0035889            0.327172 757.185711   0.000\npasser_name_idW.Levis_00-0039152             -12.672050 535.411141  -0.024\npasser_name_idZ.Wilson_00-0037013            -12.879896 535.411144  -0.024\n                                             Pr(&gt;|z|)    \n(Intercept)                                  0.979302    \npass_locationmiddle                          9.83e-07 ***\npass_locationright                           0.000924 ***\nair_yards                                     &lt; 2e-16 ***\nqb_hit                                        &lt; 2e-16 ***\npasser_name_idA.Dalton_00-0027973            0.980992    \npasser_name_idA.Lazard_00-0034521            0.972227    \npasser_name_idA.McCarron_00-0031288          0.981247    \npasser_name_idA.Mitchell_00-0039890          0.999283    \npasser_name_idA.O'Connell_00-0038579         0.980929    \npasser_name_idA.Richardson_00-0039164        0.980476    \npasser_name_idA.Rodgers_00-0023459           0.980887    \npasser_name_idA.St. Brown_00-0036963         0.999970    \npasser_name_idB.Allen_00-0032434             0.980508    \npasser_name_idB.Anger_00-0029692             0.979735    \npasser_name_idB.Gabbert_00-0027948           0.980278    \npasser_name_idB.Hoyer_00-0026625             0.980299    \npasser_name_idB.Mann_00-0036313              0.999563    \npasser_name_idB.Mayfield_00-0034855          0.981259    \npasser_name_idB.Nix_00-0039732               0.981138    \npasser_name_idB.Purdy_00-0037834             0.981392    \npasser_name_idB.Rypien_00-0034955            0.980026    \npasser_name_idB.Young_00-0039150             0.980851    \npasser_name_idB.Zappe_00-0038108             0.980672    \npasser_name_idC.Beathard_00-0033936          0.981798    \npasser_name_idC.Godwin_00-0033921            0.972289    \npasser_name_idC.Keenum_00-0028986            0.980922    \npasser_name_idC.Kirk_00-0034775              0.980536    \npasser_name_idC.Rush_00-0033662              0.980788    \npasser_name_idC.Stroud_00-0039163            0.981121    \npasser_name_idC.Sutton_00-0034348            0.999563    \npasser_name_idC.Tune_00-0038582              0.980487    \npasser_name_idC.Wentz_00-0032950             0.981290    \npasser_name_idC.Williams_00-0039918          0.980972    \npasser_name_idC.Wilson_00-0034418            0.999001    \npasser_name_idCo.Heyward_00-0037304          0.970917    \npasser_name_idD.Brown_00-0036626             0.980935    \npasser_name_idD.Carr_00-0031280              0.981330    \npasser_name_idD.Henry_00-0032764             0.981183    \npasser_name_idD.Hopkins_00-0030564           0.972154    \npasser_name_idD.Jones_00-0035710             0.981115    \npasser_name_idD.Lock_00-0035704              0.980729    \npasser_name_idD.London_00-0037238            0.999593    \npasser_name_idD.Maye_00-0039851              0.981176    \npasser_name_idD.Mills_00-0036898             0.980036    \npasser_name_idD.Montgomery_00-0035685        0.999938    \npasser_name_idD.Mooney_00-0036309            0.973494    \npasser_name_idD.Moore_00-0034827             0.973225    \npasser_name_idD.Prescott_00-0033077          0.981349    \npasser_name_idD.Ridder_00-0038122            0.981064    \npasser_name_idD.Samuel_00-0035719            0.972995    \npasser_name_idD.Singletary_00-0035250        0.998732    \npasser_name_idD.Thompson-Robinson_00-0038583 0.980211    \npasser_name_idD.Watson_00-0033537            0.981077    \npasser_name_idD.Wicks_00-0038393             0.999688    \npasser_name_idE.Stick_00-0035282             0.980955    \npasser_name_idG.Minshew_00-0035289           0.980937    \npasser_name_idG.Smith_00-0030565             0.981293    \npasser_name_idG.Wilson_00-0037740            0.971790    \npasser_name_idH.Hooker_00-0038550            0.980980    \npasser_name_idJ.Allen_00-0034857             0.981217    \npasser_name_idJ.Brissett_00-0033119          0.980934    \npasser_name_idJ.Browning_00-0035100          0.981424    \npasser_name_idJ.Burrow_00-0036442            0.981405    \npasser_name_idJ.Chase_00-0036900             0.999221    \npasser_name_idJ.Coker_00-0039491             0.999251    \npasser_name_idJ.Daniels_00-0039910           0.981330    \npasser_name_idJ.Dobbs_00-0033949             0.981105    \npasser_name_idJ.Driskel_00-0032436           0.980417    \npasser_name_idJ.Fields_00-0036945            0.981007    \npasser_name_idJ.Flacco_00-0026158            0.981087    \npasser_name_idJ.Fox_00-0035156               0.999573    \npasser_name_idJ.Garoppolo_00-0031345         0.981157    \npasser_name_idJ.Goff_00-0033106              0.981402    \npasser_name_idJ.Haener_00-0038998            0.980076    \npasser_name_idJ.Hall_00-0038598              0.981213    \npasser_name_idJ.Hekker_00-0028872            0.978898    \npasser_name_idJ.Herbert_00-0036355           0.981266    \npasser_name_idJ.Hurts_00-0036389             0.981257    \npasser_name_idJ.Jefferson_00-0036322         0.980903    \npasser_name_idJ.Johnson_00-0026300           0.982552    \npasser_name_idJ.Love_00-0036264              0.981125    \npasser_name_idJ.McKinnon_00-0031376          0.999304    \npasser_name_idJ.Meyers_00-0034960            0.980830    \npasser_name_idJ.Milton_00-0039398            0.982177    \npasser_name_idJ.Mixon_00-0033897             0.971790    \npasser_name_idJ.Reeves-Maybin_00-0033557     0.998876    \npasser_name_idJ.Scott_00-0034162             0.999501    \npasser_name_idJ.Smith_00-0033858             0.971603    \npasser_name_idJ.Smith-Njigba_00-0038543      0.996921    \npasser_name_idJ.Stidham_00-0035264           0.980940    \npasser_name_idJ.Winston_00-0031503           0.980915    \npasser_name_idK.Allen_00-0030279             0.979950    \npasser_name_idK.Allen_00-0034577             0.999697    \npasser_name_idK.Bourne_00-0033307            0.971166    \npasser_name_idK.Cousins_00-0029604           0.981407    \npasser_name_idK.Gainwell_00-0036919          0.999281    \npasser_name_idK.Murray_00-0035228            0.981176    \npasser_name_idK.Pickett_00-0038102           0.980906    \npasser_name_idK.Toney_00-0036913             0.972164    \npasser_name_idK.Trask_00-0036928             0.979367    \npasser_name_idL.Cooke_00-0034437             0.999908    \npasser_name_idL.Jackson_00-0034796           0.981323    \npasser_name_idL.Woodside_00-0034438          0.981563    \npasser_name_idM.Jones_00-0036972             0.981030    \npasser_name_idM.Killebrew_00-0032399         0.971947    \npasser_name_idM.Mariota_00-0032268           0.981855    \npasser_name_idM.Nabers_00-0039337            0.971228    \npasser_name_idM.Penix_00-0039917             0.980831    \npasser_name_idM.Rudolph_00-0034771           0.981206    \npasser_name_idM.Stafford_00-0026498          0.981088    \npasser_name_idM.Trubisky_00-0033869          0.981212    \npasser_name_idM.White_00-0034401             0.979799    \npasser_name_idM.Willis_00-0038128            0.981866    \npasser_name_idN.Mullens_00-0033319           0.981743    \npasser_name_idP.Mahomes_00-0033873           0.981242    \npasser_name_idP.Walker_00-0033275            0.980246    \npasser_name_idR.Dixon_00-0032943             0.999179    \npasser_name_idR.Pearsall_00-0039916          0.971790    \npasser_name_idR.Tannehill_00-0029701         0.981290    \npasser_name_idR.Wilson_00-0029263            0.981262    \npasser_name_idS.Clifford_00-0038391          0.998386    \npasser_name_idS.Darnold_00-0034869           0.981258    \npasser_name_idS.Diggs_00-0031588             0.999501    \npasser_name_idS.Howell_00-0037077            0.980942    \npasser_name_idS.Rattler_00-0039376           0.980591    \npasser_name_idS.Thompson_00-0037327          0.981157    \npasser_name_idT.Atwell_00-0036849            0.973287    \npasser_name_idT.Bagent_00-0038416            0.980975    \npasser_name_idT.Boyd_00-0033009              0.965787    \npasser_name_idT.Boyle_00-0034177             0.980616    \npasser_name_idT.DeVito_00-0038476            0.980989    \npasser_name_idT.Heinicke_00-0031800          0.980520    \npasser_name_idT.Hill_00-0033357              0.980668    \npasser_name_idT.Huntley_00-0035993           0.981031    \npasser_name_idT.Lance_00-0037012             0.980648    \npasser_name_idT.Lawrence_00-0036971          0.981096    \npasser_name_idT.McKee_00-0038400             0.981213    \npasser_name_idT.Morstead_00-0027114          0.999718    \npasser_name_idT.Siemian_00-0032156           0.980324    \npasser_name_idT.Tagovailoa_00-0036212        0.981403    \npasser_name_idT.Taylor_00-0028118            0.981396    \npasser_name_idT.Townsend_00-0035889          0.999655    \npasser_name_idW.Levis_00-0039152             0.981118    \npasser_name_idZ.Wilson_00-0037013            0.980808    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46543  on 35986  degrees of freedom\nResidual deviance: 42623  on 35842  degrees of freedom\nAIC: 42913\n\nNumber of Fisher Scoring iterations: 12\n\n\nObviously there are many more coefficients displayed in the summary output, with a number of players that I’ve never heard of before that seem to have rather large coefficient estimates… likely due to limited sample size (more on that in the lectures ahead).\nWe can examine what the distribution of the coefficients looks like using the tidy() function from the broom package which helps grab relevant model output and puts it in a tidy table:\n\nlibrary(broom)\n\n# Get the model coefficients:\nlogit_coef_table &lt;- tidy(passer_logit)\n\n# Only display the estimates for the passer_name_id coefficients:\nlogit_coef_table |&gt;\n  filter(str_detect(term, \"passer_name_id\")) |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(color = \"black\", fill = \"blue\", alpha = 0.7) +\n  labs(x = \"Passer coefficient estimate\",\n       y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAnd if we focus on the middle portion of the distribution:\n\nlogit_coef_table |&gt;\n  filter(str_detect(term, \"passer_name_id\"),\n         estimate &lt; -10, estimate &gt; -15) |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(color = \"black\", fill = \"blue\", alpha = 0.7) +\n  labs(x = \"Passer coefficient estimate\",\n       y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThis suggests we can model the QB coefficients according to a distribution! And that leads us into the next lecture’s material…"
  },
  {
    "objectID": "demos/15-bayes-rapm-stan.html",
    "href": "demos/15-bayes-rapm-stan.html",
    "title": "Lecture 16: Bayesian RAPM in Stan",
    "section": "",
    "text": "The purpose of this demo is demonstrate how to fit and examine the posterior distributions for a Bayesian regularized adjusted plus-minus (RAPM) model, in order to estimate the impact of basketball players when they are on the court, while adjusting for the quality of their teammates and opponents. We will use the same dataset from the intro_rapm.qmd demo. As a reminder, you can find the script (init_nba_rapm_data.R) for initializing this dataset on Canvas using the hoopR package.\nThe following code chunk reads in the wide data (assuming it is in the correct directory):\n\nlibrary(tidyverse)\n\n# Load the data\nnba_rapm_data &lt;- read_csv(here::here(\"data/nba_2324_season_rapm_data.csv.gz\"))\nnba_rapm_data\n\n# A tibble: 31,885 × 579\n   game_id    stint_id n_pos home_points away_points minutes  margin `203484`\n   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 0022300061        1    27          20          16   5.88    14.8         1\n 2 0022300061        2    14           9           2   3.29    50           1\n 3 0022300061        3     8           2           2   2.16     0           0\n 4 0022300061        4    11          11           4   3.2     63.6         0\n 5 0022300061        6     2           0           2   0.400 -100           1\n 6 0022300061        7     7           3           6   1.55   -42.9         1\n 7 0022300061        8     2           2           0   0.25   100           1\n 8 0022300061        9    12           7           8   2.43    -8.33        1\n 9 0022300061       10     9           6           6   1.76     0           1\n10 0022300061       11    34          15          19   7.39   -11.8         1\n# ℹ 31,875 more rows\n# ℹ 571 more variables: `203932` &lt;dbl&gt;, `203999` &lt;dbl&gt;, `1627750` &lt;dbl&gt;,\n#   `1629008` &lt;dbl&gt;, `202704` &lt;dbl&gt;, `1630192` &lt;dbl&gt;, `1631128` &lt;dbl&gt;,\n#   `1631212` &lt;dbl&gt;, `1629618` &lt;dbl&gt;, `1630296` &lt;dbl&gt;, `1631221` &lt;dbl&gt;,\n#   `101108` &lt;dbl&gt;, `201939` &lt;dbl&gt;, `202691` &lt;dbl&gt;, `203952` &lt;dbl&gt;,\n#   `1626172` &lt;dbl&gt;, `1630228` &lt;dbl&gt;, `203967` &lt;dbl&gt;, `1627780` &lt;dbl&gt;,\n#   `1630541` &lt;dbl&gt;, `202709` &lt;dbl&gt;, `1628380` &lt;dbl&gt;, `1629640` &lt;dbl&gt;, …\n\n\nIn this dataset, we have 31,885 unique shifts/stints with 572 players represented by the indicator variables (+1 if on court for home team, -1 if on court for away team, and 0 if not on court). Additional context is captured by the following variables:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ngame_id\nUnique game ID\n\n\nstint_id\nUnique identifier within a game for a stint for particular combination of home and away lineup (in appearance of order, where 1 is the first stint in the game)\n\n\nn_pos\nNumber of possessions (combined for both home and away) during the observed stint\n\n\nhome_points\nNumber of points scored by the home team during the stint\n\n\naway_points\nNumber of points scored by the away team during the stint\n\n\nminutes\nLength of the stint in terms of minutes played\n\n\nmargin\nCommon response for RAPM models defined as: (home_points - away_points) / n_pos * 100"
  },
  {
    "objectID": "demos/15-bayes-rapm-stan.html#introduction",
    "href": "demos/15-bayes-rapm-stan.html#introduction",
    "title": "Lecture 16: Bayesian RAPM in Stan",
    "section": "",
    "text": "The purpose of this demo is demonstrate how to fit and examine the posterior distributions for a Bayesian regularized adjusted plus-minus (RAPM) model, in order to estimate the impact of basketball players when they are on the court, while adjusting for the quality of their teammates and opponents. We will use the same dataset from the intro_rapm.qmd demo. As a reminder, you can find the script (init_nba_rapm_data.R) for initializing this dataset on Canvas using the hoopR package.\nThe following code chunk reads in the wide data (assuming it is in the correct directory):\n\nlibrary(tidyverse)\n\n# Load the data\nnba_rapm_data &lt;- read_csv(here::here(\"data/nba_2324_season_rapm_data.csv.gz\"))\nnba_rapm_data\n\n# A tibble: 31,885 × 579\n   game_id    stint_id n_pos home_points away_points minutes  margin `203484`\n   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 0022300061        1    27          20          16   5.88    14.8         1\n 2 0022300061        2    14           9           2   3.29    50           1\n 3 0022300061        3     8           2           2   2.16     0           0\n 4 0022300061        4    11          11           4   3.2     63.6         0\n 5 0022300061        6     2           0           2   0.400 -100           1\n 6 0022300061        7     7           3           6   1.55   -42.9         1\n 7 0022300061        8     2           2           0   0.25   100           1\n 8 0022300061        9    12           7           8   2.43    -8.33        1\n 9 0022300061       10     9           6           6   1.76     0           1\n10 0022300061       11    34          15          19   7.39   -11.8         1\n# ℹ 31,875 more rows\n# ℹ 571 more variables: `203932` &lt;dbl&gt;, `203999` &lt;dbl&gt;, `1627750` &lt;dbl&gt;,\n#   `1629008` &lt;dbl&gt;, `202704` &lt;dbl&gt;, `1630192` &lt;dbl&gt;, `1631128` &lt;dbl&gt;,\n#   `1631212` &lt;dbl&gt;, `1629618` &lt;dbl&gt;, `1630296` &lt;dbl&gt;, `1631221` &lt;dbl&gt;,\n#   `101108` &lt;dbl&gt;, `201939` &lt;dbl&gt;, `202691` &lt;dbl&gt;, `203952` &lt;dbl&gt;,\n#   `1626172` &lt;dbl&gt;, `1630228` &lt;dbl&gt;, `203967` &lt;dbl&gt;, `1627780` &lt;dbl&gt;,\n#   `1630541` &lt;dbl&gt;, `202709` &lt;dbl&gt;, `1628380` &lt;dbl&gt;, `1629640` &lt;dbl&gt;, …\n\n\nIn this dataset, we have 31,885 unique shifts/stints with 572 players represented by the indicator variables (+1 if on court for home team, -1 if on court for away team, and 0 if not on court). Additional context is captured by the following variables:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ngame_id\nUnique game ID\n\n\nstint_id\nUnique identifier within a game for a stint for particular combination of home and away lineup (in appearance of order, where 1 is the first stint in the game)\n\n\nn_pos\nNumber of possessions (combined for both home and away) during the observed stint\n\n\nhome_points\nNumber of points scored by the home team during the stint\n\n\naway_points\nNumber of points scored by the away team during the stint\n\n\nminutes\nLength of the stint in terms of minutes played\n\n\nmargin\nCommon response for RAPM models defined as: (home_points - away_points) / n_pos * 100"
  },
  {
    "objectID": "demos/15-bayes-rapm-stan.html#model-set-up",
    "href": "demos/15-bayes-rapm-stan.html#model-set-up",
    "title": "Lecture 16: Bayesian RAPM in Stan",
    "section": "Model set-up",
    "text": "Model set-up\nWe’re now going to proceed to set-up the Bayesian RAPM model. First, we’ll initialize our dataset in the manner appropriate for handling in Stan. This is similar to the intro_rapm.qmd demo since it is just based on creating a matrix for the players with a numeric vector for the response variable.\n\n# Now for ease, create a dataset that only has the response and player columns:\nnba_margin_apm_model_data &lt;- nba_rapm_data |&gt;\n  dplyr::select(-c(game_id, stint_id, n_pos, home_points, away_points, minutes))\n\n# Next set-up the design matrix of player indicators\nplayer_matrix &lt;- nba_margin_apm_model_data |&gt;\n  dplyr::select(-margin) |&gt;\n  as.matrix()\n\n# And vector for the response\nmargin_response &lt;- nba_margin_apm_model_data$margin\n\nNow with the data constructed, we can use Stan to simulate from the posterior distribution for the considered model parameters.\nThe following chunk below displays the Stan code that is also available in bayes_ridge_rapm.stan:\n\nstan_ridge_model &lt;- \"\ndata{\n  // Set-up the context in terms of dataset size\n  int&lt;lower = 0&gt; N_shifts; \n  int&lt;lower = 1&gt; N_players;\n  vector[N_shifts] y;\n  matrix[N_shifts, N_players] X_players; \n}\n\n// Now define the parameters we'll consider, with the player betas and two\n// variance components:\nparameters{\n  // Shift-level variance\n  real&lt;lower=0&gt; sigma_shifts;\n  // Player-level variance\n  real&lt;lower=0&gt; sigma_players; \n  // Vector of coefficients for players\n  vector[N_players] beta; \n}\n\n// And now write out the model\nmodel{\n  \n  // Observation-level\n  y ~ normal(X_players * beta, sigma_shifts);\n  \n  // Player level effects\n  beta ~ normal(0, sigma_players);\n  \n  // Priors for the variances:\n  sigma_shifts ~ cauchy(0, 5);\n  sigma_players ~ cauchy(0, 5);\n\n}\n\"\n\nCompared to the intro_stan.qmd code, there are more components here for the input. We need to tell Stan how many observations we’ve observed (N_shifts) and the number of player coefficients (N_players), as well as the actual data input: the response vector (y) and the design matrix with the player indicators (X_players).\nThe following code chunk sets up the data list and then uses rstan to start sampling. NOTE: this code takes about 30 minutes to run on my laptop, so do NOT try and knit this file with the code chunk evaluated!\n\n# Construct the data list\nbayes_ridge_rapm_data &lt;- list(N_shifts = nrow(player_matrix),\n                              N_players = ncol(player_matrix),\n                              y = margin_response,\n                              X_players = player_matrix)\n\n# Use rstan to start sampling - where we'll use 4 chain with 5000 iterations,\n# where 2500 are burn-in, and speed things up with the 4 chains in parallel:\nlibrary(rstan)\nbayes_ridge_rapm_fit &lt;- stan(model_code = stan_ridge_model, \n                             data = bayes_ridge_rapm_data, \n                             chains = 4, iter = 2500 * 2, \n                             cores = 4,\n                             seed = 2024)\n# Or you could use the following if the bayes_ridge_rapm.stan file is in the\n# current directory:\n# bayes_ridge_rapm_fit &lt;- stan(file = \"bayes_ridge_rapm.stan\", \n#                              data = bayes_ridge_rapm_data, \n#                              chains = 4, iter = 2500 * 2, \n#                              cores = 4,\n#                              seed = 2024)\n\nSince this code takes a decent amount of time to run, the following code chunk reads in the saved .rds object from the Stan model fit (that was created in the fit_bayes_ridge_rapm.R script on Canvas):\n\nbayes_ridge_rapm_fit &lt;- \n  read_rds(here::here(\"data/bayes_ridge_rapm_fit.rds\"))\n\nSimilar to the intro_stan.qmd demo, we should check MCMC diagnostics for our posterior samples. We can again view the trace plots for parameters - BUT we have to deal with the fact that we have hundreds of parameters! The following displays the trace plots for just two of the players, with their parameters designated by just the index in the Stan beta vector:\n\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\nmcmc_trace(bayes_ridge_rapm_fit, pars = c(\"beta[15]\", \"beta[25]\"), \n           facet_args = list(ncol = 1, strip.position = \"left\"))\n\n\n\n\n\n\n\n\nFor a quick glance, we can also compute the various diagnostics that we discussed in the intro_stan.qmd demo. For instance, we can compute the rhat values for each of the parameters to assess the stability. I decided to be lazy and just used the hist() function to create a base R histogram displaying that none of the rhat values concerning (i.e., noticeably greater than 1).\n\nrapm_rhats &lt;- rhat(bayes_ridge_rapm_fit)\nhist(rapm_rhats)\n\n\n\n\n\n\n\n\nSimilarly, we can also compute the neff_ratio for all of the parameters:\n\nrapm_neff_ratio &lt;- neff_ratio(bayes_ridge_rapm_fit)\nhist(rapm_neff_ratio)\n\n\n\n\n\n\n\n\nThe strange behavior of this distribution is discussed in lecture…"
  },
  {
    "objectID": "demos/15-bayes-rapm-stan.html#posterior-analysis",
    "href": "demos/15-bayes-rapm-stan.html#posterior-analysis",
    "title": "Lecture 16: Bayesian RAPM in Stan",
    "section": "Posterior analysis",
    "text": "Posterior analysis\nWe’re now ready to examine the posterior distributions for the parameters. First, we’ll create a simple, tidy table that has one column for each parameter (excluding Stan’s reported log posterior density). The following code chunk sets up this table with 10,000 rows (one for each sample) and 574 columns (one for each parameter):\n\nposterior_sample &lt;- as.data.frame(bayes_ridge_rapm_fit, pars = \"lp__\", include = FALSE) |&gt;\n  as_tibble()\n\nposterior_sample\n\n# A tibble: 10,000 × 574\n   sigma_shifts sigma_players `beta[1]` `beta[2]` `beta[3]` `beta[4]` `beta[5]`\n          &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1         69.7          2.10    0.773     0.731       2.88     2.09      0.708\n 2         69.7          2.08    0.258    -1.65        5.31     1.95      0.663\n 3         70.0          2.09    4.35     -1.13        1.94    -1.92      1.39 \n 4         69.7          2.15   -0.626     0.0126      6.30     3.16     -1.17 \n 5         70.0          2.17    4.60     -0.886       2.24    -1.73      1.15 \n 6         69.8          2.32    2.72     -0.538       6.43     0.561     2.68 \n 7         69.8          2.27    2.40     -0.874       6.31     0.950    -2.05 \n 8         70.0          2.18   -0.0970    0.113       6.13     0.601     2.57 \n 9         70.1          2.19    2.65     -1.52        6.70     2.17      1.22 \n10         70.2          2.28    2.79     -1.22        6.14     1.34      0.488\n# ℹ 9,990 more rows\n# ℹ 567 more variables: `beta[6]` &lt;dbl&gt;, `beta[7]` &lt;dbl&gt;, `beta[8]` &lt;dbl&gt;,\n#   `beta[9]` &lt;dbl&gt;, `beta[10]` &lt;dbl&gt;, `beta[11]` &lt;dbl&gt;, `beta[12]` &lt;dbl&gt;,\n#   `beta[13]` &lt;dbl&gt;, `beta[14]` &lt;dbl&gt;, `beta[15]` &lt;dbl&gt;, `beta[16]` &lt;dbl&gt;,\n#   `beta[17]` &lt;dbl&gt;, `beta[18]` &lt;dbl&gt;, `beta[19]` &lt;dbl&gt;, `beta[20]` &lt;dbl&gt;,\n#   `beta[21]` &lt;dbl&gt;, `beta[22]` &lt;dbl&gt;, `beta[23]` &lt;dbl&gt;, `beta[24]` &lt;dbl&gt;,\n#   `beta[25]` &lt;dbl&gt;, `beta[26]` &lt;dbl&gt;, `beta[27]` &lt;dbl&gt;, `beta[28]` &lt;dbl&gt;, …\n\n\nWe can start by visualizing the posterior distributions of the variance terms, such as the shift/stint level variance:\n\nposterior_sample |&gt;\n  ggplot(aes(x = sigma_shifts)) +\n  geom_histogram() +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAs well as the between player variance:\n\nposterior_sample |&gt;\n  ggplot(aes(x = sigma_players)) +\n  geom_histogram() +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAnd similarly, we can use these quantities to display the posterior distribution for the ICC! Which we only had access to before in terms of one number, but now we have a full posterior distribution:\n\nposterior_sample |&gt;\n  mutate(icc = sigma_players / (sigma_players + sigma_shifts)) |&gt;\n  ggplot(aes(x = icc)) +\n  geom_histogram() +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNow, in order to compare the players - we need to replace the arbitrary index values with the original player IDs. The following code does this by first grabbing the columns for the players and then replacing the column names with the original design matrix column names:\n\n# First just grab the players\nplayer_posterior_samples &lt;- posterior_sample |&gt;\n  dplyr::select(-sigma_shifts, -sigma_players)\n\n# And now change the column names:\ncolnames(player_posterior_samples) &lt;- colnames(player_matrix)\n\nFor ease, we’ll then convert this to a long table with one row per player-sample. And borrowing our code from the intro_rapm.qmd demo, we’ll join the player names based on the IDs from the nba_2324_player_table.csv table:\n\n# First load the player table\nnba_player_table &lt;- read_csv(here::here(\"data/nba_2324_player_table.csv\"))\n\nRows: 572 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): player_name\ndbl (1): player_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Now create a long player posterior sample and join the player names:\nlong_player_posterior_samples &lt;- player_posterior_samples |&gt;\n  pivot_longer(cols = everything(),\n               names_to = \"player_id\",\n               values_to = \"beta\") |&gt;\n  mutate(player_id = as.numeric(player_id)) |&gt;\n  left_join(nba_player_table, by = c(\"player_id\"))\nlong_player_posterior_samples\n\n# A tibble: 5,720,000 × 3\n   player_id    beta player_name             \n       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                   \n 1    203484  0.773  Kentavious Caldwell-Pope\n 2    203932  0.731  Aaron Gordon            \n 3    203999  2.88   Nikola Jokić            \n 4   1627750  2.09   Jamal Murray            \n 5   1629008  0.708  Michael Porter Jr.      \n 6    202704  2.83   Reggie Jackson          \n 7   1630192 -3.79   Zeke Nnaji              \n 8   1631128 -1.13   Christian Braun         \n 9   1631212 -0.0339 Peyton Watson           \n10   1629618  0.310  Jalen Pickett           \n# ℹ 5,719,990 more rows\n\n\nWith this long table, we can once again compute various summaries such as the posterior mean and 80% credible intervals for each player:\n\nplayer_summary &lt;- long_player_posterior_samples |&gt;\n  group_by(player_id, player_name) |&gt;\n  summarize(posterior_mean = mean(beta), \n            posterior_median = median(beta),\n            # 80% credible interval:\n            lower_80 = quantile(beta, 0.1),\n            upper_80 = quantile(beta, 0.9),\n            .groups = \"drop\") |&gt;\n  arrange(desc(posterior_mean))\nplayer_summary\n\n# A tibble: 572 × 6\n   player_id player_name       posterior_mean posterior_median lower_80 upper_80\n       &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt;            &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1    203999 Nikola Jokić                4.88             4.81    2.58      7.28\n 2   1629029 Luka Dončić                 4.49             4.45    2.30      6.76\n 3   1628973 Jalen Brunson               4.28             4.25    2.02      6.55\n 4    203954 Joel Embiid                 3.72             3.68    1.32      6.18\n 5   1626164 Devin Booker                3.59             3.55    1.39      5.82\n 6   1626157 Karl-Anthony Tow…           3.50             3.49    1.25      5.80\n 7   1628374 Lauri Markkanen             3.38             3.35    1.02      5.75\n 8   1630198 Isaiah Joe                  3.05             3.03    0.823     5.29\n 9   1630581 Josh Giddey                 3.01             3.00    0.754     5.29\n10   1628401 Derrick White               2.93             2.92    0.635     5.29\n# ℹ 562 more rows\n\n\nWe can see that the top 10 players match what we observed using ridge regression (with slightly more penalized values than what we say with frequentist ridge…) - but now we have full posterior distributions for each player. In the above table, you can see the 80% credible intervals that we can use for comparisons of player effects. Instead of just reporting intervals, we can also display full distributions using something like ggridges. For instance, the code chunk below displays the posterior distributions for the top 10 and bottom 10 players based on the Bayesian RAPM model (sorted by posterior means):\n\n# Grab the players\ntop_10_players &lt;- player_summary |&gt;\n  slice_head(n = 10) |&gt;\n  pull(player_name)\nbottom_10_players &lt;- player_summary |&gt;\n  slice_tail(n = 10) |&gt;\n  pull(player_name)\n\n# And now display ridges for them:\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.2.3\n\nlong_player_posterior_samples |&gt;\n  filter(player_name %in% c(top_10_players, bottom_10_players)) |&gt;\n  mutate(player_name = factor(player_name, levels = c(top_10_players,\n                                                      bottom_10_players))) |&gt;\n  ggplot(aes(x = beta, y = player_name)) +\n  geom_density_ridges(rel_min_height = 0.05) +\n  theme_bw() +\n  labs(x = \"Bayesian RAPM posterior beta\",\n       y = \"Player\")\n\nPicking joint bandwidth of 0.256"
  },
  {
    "objectID": "demos/10-intro-bayes.html",
    "href": "demos/10-intro-bayes.html",
    "title": "Lecture 11: Introduction to Bayes with a Binomial model",
    "section": "",
    "text": "The purpose of this demo is to begin our understanding the framework used to build Bayesian models. We are starting with a simple model of Caitlin Clark’s field goal percentage (FG%), and will expand on this in the next demo."
  },
  {
    "objectID": "demos/10-intro-bayes.html#introduction",
    "href": "demos/10-intro-bayes.html#introduction",
    "title": "Lecture 11: Introduction to Bayes with a Binomial model",
    "section": "",
    "text": "The purpose of this demo is to begin our understanding the framework used to build Bayesian models. We are starting with a simple model of Caitlin Clark’s field goal percentage (FG%), and will expand on this in the next demo."
  },
  {
    "objectID": "demos/10-intro-bayes.html#discrete-prior-model-example",
    "href": "demos/10-intro-bayes.html#discrete-prior-model-example",
    "title": "Lecture 11: Introduction to Bayes with a Binomial model",
    "section": "Discrete Prior Model Example",
    "text": "Discrete Prior Model Example\nBefore diving into the full Beta-Binomial model in the next demo, we’ll consider an initial starting point based on a discrete prior model for Caitlin Clark’s probability of making a field goal as denoted by \\(\\pi\\). We’ll start with the following discrete prior model \\(f(\\pi)\\):\n\n\n\n\\(\\pi\\)\n0.2\n0.4\n0.6\nTotal\n\n\n\n\n\\(f(\\pi)\\)\n0.10\n0.65\n0.25\n1\n\n\n\nOn Feb 15th 2024, Caitlin Clark broke the NCAA women’s basketball scoring record by making 16 of 31 field goal attempts. Based on our prior, there are three different possibilities for the Binomial model of her field goal success: (1) Binomial(\\(n\\) = 31, \\(\\pi\\) = 0.2), (2) Binomial(\\(n\\) = 31, \\(\\pi\\) = 0.4), or (3) Binomial(\\(n\\) = 31, \\(\\pi\\) = 0.6). The following code chunk displays the conditional probability mass functions (PMFs) \\(f(y|\\pi)\\) for each of these prior possibilities:\n\nlibrary(tidyverse)\n# First create a table with values from 0 to 31 to indicate the number of \n# made field goals:\nfield_goal_data &lt;- tibble(made_fg = 0:31,\n                          n_fg = 31)\n\n# Now, loop over a vector of values for the prior pi:\nprior_pi &lt;- c(0.2, 0.4, 0.6)\n\n# Create a stacked dataset containing the Binomial probability of observing\n# the number of made_fg given pi and n_fg for each of the three values of pi:\nfield_goal_probs &lt;- map_dfr(prior_pi,\n                            function(pi) {\n                              \n                              field_goal_data |&gt;\n                                mutate(fg_pi = pi,\n                                       binom_pmf = dbinom(made_fg, n_fg, fg_pi))\n                              \n                            }) |&gt;\n  # Add an indicator denoting the observed outcome:\n  mutate(is_observed = ifelse(made_fg == 16, \"yes\", \"no\"))\n\n# And now create a plot displaying the probabilities for these three prior \n# probabilities:\nfield_goal_probs |&gt;\n  # Make a new label using fg_pi:\n  mutate(binom_label = paste0(\"Binomial(31, \", fg_pi, \")\")) |&gt;\n  ggplot(aes(x = made_fg, y = binom_pmf, color = is_observed)) +\n  geom_bar(aes(fill = is_observed), stat = \"identity\", width = 0.1) +\n  geom_point() +\n  scale_color_manual(values = c(\"gray\", \"black\")) +\n  scale_fill_manual(values = c(\"gray\", \"black\")) +\n  facet_wrap(~binom_label, ncol = 3) +\n  labs(x = \"y\", y = expression(paste(\"f(y|\", pi, \")\"))) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        strip.background = element_blank(),\n        strip.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nWhile the Binomial model provides us with the probabilities of outcomes we could have observed, we can see (in black) the actual observed outcome where Caitlin Clark made \\(Y = 16\\) FGs. From this figure, we can actually observe the likelihood function of her making \\(Y = 16\\) FGs for each of the possible \\(\\pi\\) values by grabbing the parts corresponding to \\(Y = 16\\):\n\nfield_goal_probs |&gt;\n  # only use the rows for the observed outcome\n  filter(is_observed == \"yes\") |&gt;\n  ggplot(aes(x = fg_pi, y = binom_pmf)) +\n  geom_bar(stat = \"identity\", width = 0.001,\n           color = \"black\", fill = \"black\") +\n  geom_point(color = \"black\", size = 4) +\n  scale_x_continuous(breaks = prior_pi) +\n  labs(x = expression(pi), y = expression(paste(\"L(\", pi, \"|y = 16)\"))) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        strip.background = element_blank(),\n        strip.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nLikewise, we can report the likelihood values describing the compatibility of the observed data \\(Y = 16\\) with the different choices of \\(\\pi\\) from the values used to make this graph:\n\nfield_goal_probs |&gt;\n  # only use the rows for the observed outcome\n  filter(is_observed == \"yes\")\n\n# A tibble: 3 × 5\n  made_fg  n_fg fg_pi binom_pmf is_observed\n    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      \n1      16    31   0.2 0.0000693 yes        \n2      16    31   0.4 0.0607    yes        \n3      16    31   0.6 0.0910    yes        \n\n\nIn order to compute the posterior probabilities for the different choices of \\(\\pi\\), we will first compute the normalizing constant which is the total probability \\(Y = 16\\) by summing across the different choices \\(\\pi\\) with their respective prior probabilities \\(f(\\pi)\\). The following code chunk sets up this table by first initializing a prior distribution table:\n\nprior_probs &lt;- tibble(fg_pi = prior_pi,\n                      prior = c(0.1, 0.65, 0.25))\n\n# Make the visualization of it:\nprior_probs |&gt;\n  # only use the rows for the observed outcome\n  ggplot(aes(x = fg_pi, y = prior)) +\n  geom_bar(stat = \"identity\", width = 0.001,\n           color = \"black\", fill = \"black\") +\n  geom_point(color = \"black\", size = 4) +\n  scale_x_continuous(breaks = prior_pi) +\n  labs(x = expression(pi), y = expression(paste(\"f(\", pi, \")\"))) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        strip.background = element_blank(),\n        strip.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nWe can then join it over to the rows corresponding to the observed data to compute the normalizing constant:\n\nobs_fg_data &lt;- field_goal_probs |&gt;\n  filter(is_observed == \"yes\") |&gt;\n  left_join(prior_probs, by = \"fg_pi\")\n\nnormalizing_constant &lt;- sum(obs_fg_data$binom_pmf * obs_fg_data$prior)\n\nWith this, we can now compute the posterior probabilities for the three different choices for \\(\\pi\\):\n\nobs_fg_data &lt;- obs_fg_data |&gt;\n  mutate(posterior = (binom_pmf * prior) / normalizing_constant)\n\nobs_fg_data |&gt;\n  ggplot(aes(x = fg_pi, y = posterior)) +\n  geom_bar(stat = \"identity\", width = 0.001,\n           color = \"black\", fill = \"black\") +\n  geom_point(color = \"black\", size = 4) +\n  scale_x_continuous(breaks = prior_pi) +\n  labs(x = expression(pi), y = expression(paste(\"f(\", pi, \"|y = 16)\"))) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        strip.background = element_blank(),\n        strip.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nIn comparison to the prior and likelihood, we can see that the posterior distribution for \\(\\pi\\) is very similar to the prior distribution. The choice of \\(\\pi = 0.4\\) is still the most likely, but the probability is slightly lower than what it was under the prior because of the observed data (Caitlin Clark making 16 of 31 FG attempts).\nAs discussed in lecture, in practice we do not need to compute the normalizing constant. The posterior is proportional to the product of the likelihood and prior, while the constant does not depend on a choice for \\(\\pi\\) (since it integrates across all possible values). To illustrate this, the following figure displays the unnormalized version of the posterior, yielding the same display as the explicitly computed posterior:\n\nobs_fg_data |&gt;\n  mutate(unnorm_posterior = posterior * normalizing_constant) |&gt;\n  ggplot(aes(x = fg_pi, y = unnorm_posterior)) +\n  geom_bar(stat = \"identity\", width = 0.001,\n           color = \"black\", fill = \"black\") +\n  geom_point(color = \"black\", size = 4) +\n  scale_x_continuous(breaks = prior_pi) +\n  labs(x = expression(pi), \n       y = expression(paste(\"Unnormalized f(\", pi, \"|y = 16)\"))) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        strip.background = element_blank(),\n        strip.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nThis property of proportionality will become useful later on when we are interested in building more complex models."
  },
  {
    "objectID": "demos/08-random-effects-pooling.html",
    "href": "demos/08-random-effects-pooling.html",
    "title": "Lecture 9: Random effects and pooling",
    "section": "",
    "text": "The purpose of this demo is to demonstrate how to access random effect estimates from multilevel models with insight about the behavior of pooling. Building off the previous demos and lecture content, we’ll look at this in the context of modeling the dataset of NFL pass attempts. As a reminder, you can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas in the demos/week3 folder.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/08-random-effects-pooling.html#introduction",
    "href": "demos/08-random-effects-pooling.html#introduction",
    "title": "Lecture 9: Random effects and pooling",
    "section": "",
    "text": "The purpose of this demo is to demonstrate how to access random effect estimates from multilevel models with insight about the behavior of pooling. Building off the previous demos and lecture content, we’ll look at this in the context of modeling the dataset of NFL pass attempts. As a reminder, you can find the dataset and code to create the data (init_nfl_passing_data.R) on Canvas in the demos/week3 folder.\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\nlibrary(tidyverse)\nnfl_passing_data &lt;- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id &lt;chr&gt;, complete_pass &lt;dbl&gt;,\n#   pass_location &lt;chr&gt;, air_yards &lt;dbl&gt;, qb_hit &lt;dbl&gt;, epa &lt;dbl&gt;,\n#   yardline_100 &lt;dbl&gt;, down &lt;dbl&gt;, ydstogo &lt;dbl&gt;, is_home &lt;dbl&gt;"
  },
  {
    "objectID": "demos/08-random-effects-pooling.html#accessing-random-effect-estimates",
    "href": "demos/08-random-effects-pooling.html#accessing-random-effect-estimates",
    "title": "Lecture 9: Random effects and pooling",
    "section": "Accessing random effect estimates",
    "text": "Accessing random effect estimates\nWe’ll first demonstrate how to grab random effect estimates in the context of a varying intercepts model for modeling EPA, using the same model from the varying_ints_slopes.qmd demo. The following code chunk fits this model (with the default setting of REML = TRUE this time):\n\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nepa_lmm &lt;- lmer(epa ~ (1 | passer_name_id), \n                data = nfl_passing_data, REML = TRUE)\n\nsummary(epa_lmm)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: epa ~ (1 | passer_name_id)\n   Data: nfl_passing_data\n\nREML criterion at convergence: 133283\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-8.3024 -0.5206 -0.1420  0.5539  5.6367 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.01467  0.1211  \n Residual                   2.37035  1.5396  \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  0.09218    0.01703   5.412\n\n\nThere are a couple of ways of accessing the random effects estimates from the model. The first way is to use the lme4 package function ranef():\n\nranef(epa_lmm)\n\n$passer_name_id\n                                (Intercept)\nA.Cole_00-0035190               0.026086976\nA.Dalton_00-0027973            -0.058671095\nA.Lazard_00-0034521            -0.006783395\nA.McCarron_00-0031288          -0.021830094\nA.Mitchell_00-0039890           0.014474047\nA.O'Connell_00-0038579         -0.008539064\nA.Richardson_00-0039164        -0.077646393\nA.Rodgers_00-0023459            0.014757403\nA.St. Brown_00-0036963          0.010036507\nB.Allen_00-0032434             -0.068893212\nB.Anger_00-0029692             -0.035888738\nB.Gabbert_00-0027948           -0.087429227\nB.Hoyer_00-0026625             -0.055121079\nB.Mann_00-0036313               0.025320730\nB.Mayfield_00-0034855           0.135634137\nB.Nix_00-0039732                0.009670612\nB.Purdy_00-0037834              0.221228938\nB.Rypien_00-0034955            -0.077704620\nB.Young_00-0039150             -0.088111688\nB.Zappe_00-0038108             -0.188632108\nC.Beathard_00-0033936           0.007028658\nC.Godwin_00-0033921            -0.004940695\nC.Keenum_00-0028986            -0.074714817\nC.Kirk_00-0034775              -0.011864092\nC.Rush_00-0033662              -0.067065764\nC.Stroud_00-0039163             0.097714305\nC.Sutton_00-0034348             0.044660054\nC.Tune_00-0038582              -0.129369546\nC.Wentz_00-0032950              0.040244310\nC.Williams_00-0039918           0.017964672\nC.Wilson_00-0034418             0.011947935\nCo.Heyward_00-0037304          -0.002120499\nD.Brown_00-0036626             -0.005624211\nD.Carr_00-0031280               0.064074147\nD.Henry_00-0032764              0.025795078\nD.Hopkins_00-0030564           -0.003137752\nD.Jones_00-0035710             -0.066273193\nD.Lock_00-0035704              -0.066063437\nD.London_00-0037238             0.010773892\nD.Maye_00-0039851               0.019563465\nD.Mills_00-0036898             -0.076382628\nD.Montgomery_00-0035685         0.008775943\nD.Mooney_00-0036309            -0.003173442\nD.Moore_00-0034827             -0.003317685\nD.Prescott_00-0033077           0.112030293\nD.Ridder_00-0038122            -0.038031429\nD.Samuel_00-0035719            -0.003292566\nD.Singletary_00-0035250         0.010763326\nD.Thompson-Robinson_00-0038583 -0.267392910\nD.Watson_00-0033537            -0.066060401\nD.Wicks_00-0038393              0.004902220\nE.Stick_00-0035282             -0.002559001\nG.Minshew_00-0035289            0.001078419\nG.Smith_00-0030565              0.063016302\nG.Wilson_00-0037740            -0.003232878\nH.Hooker_00-0038550             0.005340321\nJ.Allen_00-0034857              0.136924504\nJ.Brissett_00-0033119          -0.024119403\nJ.Browning_00-0035100           0.085301190\nJ.Burrow_00-0036442             0.130931167\nJ.Chase_00-0036900             -0.013499650\nJ.Coker_00-0039491              0.007494027\nJ.Daniels_00-0039910            0.115063119\nJ.Dobbs_00-0033949             -0.065886373\nJ.Driskel_00-0032436           -0.040781183\nJ.Fields_00-0036945             0.026888566\nJ.Flacco_00-0026158             0.003335069\nJ.Fox_00-0035156                0.021803519\nJ.Garoppolo_00-0031345         -0.004504616\nJ.Goff_00-0033106               0.180202174\nJ.Haener_00-0038998            -0.043659241\nJ.Hall_00-0038598              -0.018250736\nJ.Hekker_00-0028872            -0.048175478\nJ.Herbert_00-0036355            0.088486825\nJ.Hurts_00-0036389              0.115486127\nJ.Jefferson_00-0036322          0.015117480\nJ.Johnson_00-0026300           -0.005510041\nJ.Love_00-0036264               0.090283070\nJ.McKinnon_00-0031376           0.006231036\nJ.Meyers_00-0034960             0.003592254\nJ.Milton_00-0039398             0.047835434\nJ.Mixon_00-0033897             -0.005032779\nJ.Reeves-Maybin_00-0033557      0.024912839\nJ.Scott_00-0034162             -0.017212752\nJ.Smith_00-0033858             -0.005867248\nJ.Smith-Njigba_00-0038543       0.013231429\nJ.Stidham_00-0035264            0.043488303\nJ.Winston_00-0031503           -0.060927839\nK.Allen_00-0030279             -0.016238386\nK.Allen_00-0034577              0.008243373\nK.Bourne_00-0033307            -0.008684812\nK.Cousins_00-0029604            0.063098242\nK.Gainwell_00-0036919           0.007025370\nK.Murray_00-0035228             0.033295115\nK.Pickett_00-0038102           -0.055517203\nK.Toney_00-0036913             -0.003310436\nK.Trask_00-0036928             -0.010799878\nL.Cooke_00-0034437              0.015204166\nL.Jackson_00-0034796            0.220721604\nL.Woodside_00-0034438          -0.053455241\nM.Jones_00-0036972             -0.087874472\nM.Killebrew_00-0032399         -0.017035100\nM.Mariota_00-0032268            0.087476721\nM.Nabers_00-0039337            -0.006493952\nM.Penix_00-0039917              0.039436189\nM.Rudolph_00-0034771            0.010298562\nM.Stafford_00-0026498           0.072236664\nM.Trubisky_00-0033869          -0.029010535\nM.White_00-0034401             -0.089366717\nM.Willis_00-0038128             0.133856393\nN.Mullens_00-0033319            0.073570390\nP.Mahomes_00-0033873            0.065559552\nP.Walker_00-0033275            -0.085391908\nR.Dixon_00-0032943             -0.012243981\nR.Pearsall_00-0039916          -0.003832464\nR.Tannehill_00-0029701          0.011709751\nR.Wilson_00-0029263             0.031395476\nS.Clifford_00-0038391           0.012616529\nS.Darnold_00-0034869            0.105987934\nS.Diggs_00-0031588              0.016425221\nS.Howell_00-0037077            -0.103176367\nS.Rattler_00-0039376           -0.144835737\nS.Thompson_00-0037327          -0.034110806\nT.Atwell_00-0036849            -0.003710240\nT.Bagent_00-0038416            -0.084925944\nT.Boyd_00-0033009              -0.043678860\nT.Boyle_00-0034177             -0.155153890\nT.DeVito_00-0038476            -0.047507102\nT.Heinicke_00-0031800          -0.023228317\nT.Hill_00-0033357              -0.007443771\nT.Huntley_00-0035993           -0.010809721\nT.Lance_00-0037012             -0.058684277\nT.Lawrence_00-0036971           0.009027494\nT.McKee_00-0038400              0.071034205\nT.Morstead_00-0027114           0.015859297\nT.Siemian_00-0032156           -0.172370590\nT.Tagovailoa_00-0036212         0.177228789\nT.Taylor_00-0028118             0.057330276\nT.Townsend_00-0035889           0.014437035\nW.Levis_00-0039152             -0.030351674\nZ.Wilson_00-0037013            -0.090027787\n\nwith conditional variances for \"passer_name_id\" \n\n\nYou can see this returns a list of the individual effects for each QB. Note, that these values alone are NOT the mean intercept for each QB in the dataset. Instead, you must add the fixed effect intercept to these values to get the QB-specific intercepts.\nIn order to make a process like that easier, it can be helpful to use the broom.mixed package which has convenient helper functions for tidying the lme4 model output. We can extract the random effects from the model using this package with tidy(lmer_model, effects = \"ran_vals\"), and store the values in a table:\n\nlibrary(broom.mixed)\n\nWarning: package 'broom.mixed' was built under R version 4.2.3\n\nqb_ranef &lt;- tidy(epa_lmm, effects = \"ran_vals\")\n# View the dataset\nqb_ranef\n\n# A tibble: 141 × 6\n   effect   group          level                   term       estimate std.error\n   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;                   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n 1 ran_vals passer_name_id A.Cole_00-0035190       (Intercep…  0.0261     0.121 \n 2 ran_vals passer_name_id A.Dalton_00-0027973     (Intercep… -0.0587     0.0790\n 3 ran_vals passer_name_id A.Lazard_00-0034521     (Intercep… -0.00678    0.121 \n 4 ran_vals passer_name_id A.McCarron_00-0031288   (Intercep… -0.0218     0.119 \n 5 ran_vals passer_name_id A.Mitchell_00-0039890   (Intercep…  0.0145     0.121 \n 6 ran_vals passer_name_id A.O'Connell_00-0038579  (Intercep… -0.00854    0.0564\n 7 ran_vals passer_name_id A.Richardson_00-0039164 (Intercep… -0.0776     0.0683\n 8 ran_vals passer_name_id A.Rodgers_00-0023459    (Intercep…  0.0148     0.0563\n 9 ran_vals passer_name_id A.St. Brown_00-0036963  (Intercep…  0.0100     0.121 \n10 ran_vals passer_name_id B.Allen_00-0032434      (Intercep… -0.0689     0.111 \n# ℹ 131 more rows\n\n\nWe can visualize the distribution of the QB random effects to see how they are centered around zero below:\n\nqb_ranef |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(color = \"black\", fill = \"blue\", alpha = 0.5) +\n  labs(x = \"QB random effect\", y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can add a column to this table with the intercepts for each QB by simply adding the fixed effect intercept (grabbed with fixef(epa_lmm)) to the estimate column in the dataset above:\n\nqb_ranef &lt;- qb_ranef |&gt;\n  mutate(q_intercept = estimate + as.numeric(fixef(epa_lmm)))\n\nqb_ranef\n\n# A tibble: 141 × 7\n   effect   group          level            term  estimate std.error q_intercept\n   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;            &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n 1 ran_vals passer_name_id A.Cole_00-00351… (Int…  0.0261     0.121       0.118 \n 2 ran_vals passer_name_id A.Dalton_00-002… (Int… -0.0587     0.0790      0.0335\n 3 ran_vals passer_name_id A.Lazard_00-003… (Int… -0.00678    0.121       0.0854\n 4 ran_vals passer_name_id A.McCarron_00-0… (Int… -0.0218     0.119       0.0704\n 5 ran_vals passer_name_id A.Mitchell_00-0… (Int…  0.0145     0.121       0.107 \n 6 ran_vals passer_name_id A.O'Connell_00-… (Int… -0.00854    0.0564      0.0836\n 7 ran_vals passer_name_id A.Richardson_00… (Int… -0.0776     0.0683      0.0145\n 8 ran_vals passer_name_id A.Rodgers_00-00… (Int…  0.0148     0.0563      0.107 \n 9 ran_vals passer_name_id A.St. Brown_00-… (Int…  0.0100     0.121       0.102 \n10 ran_vals passer_name_id B.Allen_00-0032… (Int… -0.0689     0.111       0.0233\n# ℹ 131 more rows\n\n\nThe following figure now displays the QB intercepts, which is effectively the same figure as before but now the center is shifted based on the fixed effect intercept:\n\nqb_ranef |&gt;\n  ggplot(aes(x = q_intercept)) +\n  geom_histogram(color = \"black\", fill = \"blue\", alpha = 0.5) +\n  labs(x = \"QB intercept estimate\", y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "demos/08-random-effects-pooling.html#demonstration-of-pooling-for-intercepts",
    "href": "demos/08-random-effects-pooling.html#demonstration-of-pooling-for-intercepts",
    "title": "Lecture 9: Random effects and pooling",
    "section": "Demonstration of pooling for intercepts",
    "text": "Demonstration of pooling for intercepts\nTo demonstrate the role of pooling, we can compare the QB intercepts from the multilevel model above versus the traditional regression approach by fitting separate intercepts for each QB. For instance, the following code chunk fits an intercept-only regression model without random effects (note the use of -1 to remove the global intercept here):\n\nnaive_epa_lm &lt;- lm(epa ~ -1 + passer_name_id, data = nfl_passing_data)\nsummary(naive_epa_lm)\n\n\nCall:\nlm(formula = epa ~ -1 + passer_name_id, data = nfl_passing_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.7826  -0.8049  -0.2045   0.8486   8.6575 \n\nCoefficients:\n                                              Estimate Std. Error t value\npasser_name_idA.Cole_00-0035190               4.333918   1.537894   2.818\npasser_name_idA.Dalton_00-0027973            -0.009980   0.104159  -0.096\npasser_name_idA.Lazard_00-0034521            -1.010796   1.537894  -0.657\npasser_name_idA.McCarron_00-0031288          -0.635195   0.687767  -0.924\npasser_name_idA.Mitchell_00-0039890           2.445659   1.537894   1.590\npasser_name_idA.O'Connell_00-0038579          0.081281   0.063639   1.277\npasser_name_idA.Richardson_00-0039164        -0.021729   0.082678  -0.263\npasser_name_idA.Rodgers_00-0023459            0.111017   0.063584   1.746\npasser_name_idA.St. Brown_00-0036963          1.724116   1.537894   1.121\npasser_name_idB.Allen_00-0032434             -0.347815   0.280780  -1.239\npasser_name_idB.Anger_00-0029692             -2.843511   1.087456  -2.615\npasser_name_idB.Gabbert_00-0027948           -0.398919   0.259952  -1.535\npasser_name_idB.Hoyer_00-0026625             -0.175023   0.237302  -0.738\npasser_name_idB.Mann_00-0036313               4.209327   1.537894   2.737\npasser_name_idB.Mayfield_00-0034855           0.247128   0.045649   5.414\npasser_name_idB.Nix_00-0039732                0.104614   0.064643   1.618\npasser_name_idB.Purdy_00-0037834              0.353536   0.051521   6.862\npasser_name_idB.Rypien_00-0034955            -0.315971   0.249479  -1.267\npasser_name_idB.Young_00-0039150             -0.011576   0.050981  -0.227\npasser_name_idB.Zappe_00-0038108             -0.222412   0.098860  -2.250\npasser_name_idC.Beathard_00-0033936           0.120642   0.211246   0.571\npasser_name_idC.Godwin_00-0033921            -0.711173   1.537894  -0.462\npasser_name_idC.Keenum_00-0028986            -0.210342   0.211246  -0.996\npasser_name_idC.Kirk_00-0034775              -0.878299   1.087456  -0.808\npasser_name_idC.Rush_00-0033662              -0.007626   0.084530  -0.090\npasser_name_idC.Stroud_00-0039163             0.205317   0.048059   4.272\npasser_name_idC.Sutton_00-0034348             3.745369   1.087456   3.444\npasser_name_idC.Tune_00-0038582              -0.946147   0.320673  -2.951\npasser_name_idC.Wentz_00-0032950              0.283670   0.234527   1.210\npasser_name_idC.Williams_00-0039918           0.115350   0.065104   1.772\npasser_name_idC.Wilson_00-0034418             2.034914   1.537894   1.323\npasser_name_idCo.Heyward_00-0037304          -0.252610   1.537894  -0.164\npasser_name_idD.Brown_00-0036626             -0.367877   1.087456  -0.338\npasser_name_idD.Carr_00-0031280               0.168777   0.053478   3.156\npasser_name_idD.Henry_00-0032764              1.507470   0.887904   1.698\npasser_name_idD.Hopkins_00-0030564           -0.418015   1.537894  -0.272\npasser_name_idD.Jones_00-0035710              0.004361   0.068984   0.063\npasser_name_idD.Lock_00-0035704              -0.015583   0.096118  -0.162\npasser_name_idD.London_00-0037238             1.844015   1.537894   1.199\npasser_name_idD.Maye_00-0039851               0.121127   0.083774   1.446\npasser_name_idD.Mills_00-0036898             -0.148779   0.177581  -0.838\npasser_name_idD.Montgomery_00-0035685         1.519149   1.537894   0.988\npasser_name_idD.Mooney_00-0036309            -0.423818   1.537894  -0.276\npasser_name_idD.Moore_00-0034827             -0.447272   1.537894  -0.291\npasser_name_idD.Prescott_00-0033077           0.224927   0.052020   4.324\npasser_name_idD.Ridder_00-0038122             0.041075   0.070938   0.579\npasser_name_idD.Samuel_00-0035719            -0.443188   1.537894  -0.288\npasser_name_idD.Singletary_00-0035250         1.842297   1.537894   1.198\npasser_name_idD.Thompson-Robinson_00-0038583 -0.364731   0.101850  -3.581\npasser_name_idD.Watson_00-0033537            -0.001534   0.078277  -0.020\npasser_name_idD.Wicks_00-0038393              0.889282   1.537894   0.578\npasser_name_idE.Stick_00-0035282              0.087233   0.116924   0.746\npasser_name_idG.Minshew_00-0035289            0.093481   0.054612   1.712\npasser_name_idG.Smith_00-0030565              0.164707   0.046993   3.505\npasser_name_idG.Wilson_00-0037740            -0.433483   1.537894  -0.282\npasser_name_idH.Hooker_00-0038550             0.193411   0.512631   0.377\npasser_name_idJ.Allen_00-0034857              0.250001   0.047258   5.290\npasser_name_idJ.Brissett_00-0033119           0.046764   0.113684   0.411\npasser_name_idJ.Browning_00-0035100           0.234211   0.098656   2.374\npasser_name_idJ.Burrow_00-0036442             0.243980   0.048296   5.052\npasser_name_idJ.Chase_00-0036900             -2.102857   1.537894  -1.367\npasser_name_idJ.Coker_00-0039491              1.310709   1.537894   0.852\npasser_name_idJ.Daniels_00-0039910            0.246146   0.070342   3.499\npasser_name_idJ.Dobbs_00-0033949              0.003300   0.071472   0.046\npasser_name_idJ.Driskel_00-0032436           -0.202069   0.301606  -0.670\npasser_name_idJ.Fields_00-0036945             0.127270   0.066802   1.905\npasser_name_idJ.Flacco_00-0026158             0.096710   0.072336   1.337\npasser_name_idJ.Fox_00-0035156                3.637429   1.537894   2.365\npasser_name_idJ.Garoppolo_00-0031345          0.084195   0.106378   0.791\npasser_name_idJ.Goff_00-0033106               0.297997   0.045609   6.534\npasser_name_idJ.Haener_00-0038998            -0.132382   0.246260  -0.538\npasser_name_idJ.Hall_00-0038598              -0.073534   0.343884  -0.214\npasser_name_idJ.Hekker_00-0028872            -2.551041   0.887904  -2.873\npasser_name_idJ.Herbert_00-0036355            0.195611   0.049713   3.935\npasser_name_idJ.Hurts_00-0036389              0.228451   0.051320   4.451\npasser_name_idJ.Jefferson_00-0036322          1.328790   1.087456   1.222\npasser_name_idJ.Johnson_00-0026300           -0.210135   0.887904  -0.237\npasser_name_idJ.Love_00-0036264               0.197026   0.048584   4.055\npasser_name_idJ.McKinnon_00-0031376           1.105347   1.537894   0.719\npasser_name_idJ.Meyers_00-0034960             0.289277   0.887904   0.326\npasser_name_idJ.Milton_00-0039398             0.406576   0.285580   1.424\npasser_name_idJ.Mixon_00-0033897             -0.726146   1.537894  -0.472\npasser_name_idJ.Reeves-Maybin_00-0033557      4.143004   1.537894   2.694\npasser_name_idJ.Scott_00-0034162             -2.706606   1.537894  -1.760\npasser_name_idJ.Smith_00-0033858             -0.861830   1.537894  -0.560\npasser_name_idJ.Smith-Njigba_00-0038543       2.243609   1.537894   1.459\npasser_name_idJ.Stidham_00-0035264            0.242151   0.189302   1.279\npasser_name_idJ.Winston_00-0031503            0.002465   0.083160   0.030\npasser_name_idK.Allen_00-0030279             -0.798762   0.887904  -0.900\npasser_name_idK.Allen_00-0034577              1.432553   1.537894   0.932\npasser_name_idK.Bourne_00-0033307            -1.319965   1.537894  -0.858\npasser_name_idK.Cousins_00-0029604            0.168733   0.055859   3.021\npasser_name_idK.Gainwell_00-0036919           1.234506   1.537894   0.803\npasser_name_idK.Murray_00-0035228             0.132145   0.054136   2.441\npasser_name_idK.Pickett_00-0038102            0.012086   0.080497   0.150\npasser_name_idK.Toney_00-0036913             -0.446093   1.537894  -0.290\npasser_name_idK.Trask_00-0036928             -0.791246   1.087456  -0.728\npasser_name_idL.Cooke_00-0034437              2.564376   1.537894   1.667\npasser_name_idL.Jackson_00-0034796            0.351465   0.050566   6.951\npasser_name_idL.Woodside_00-0034438          -2.120861   0.768947  -2.758\npasser_name_idM.Jones_00-0036972             -0.019086   0.062421  -0.306\npasser_name_idM.Killebrew_00-0032399         -2.677720   1.537894  -1.741\npasser_name_idM.Mariota_00-0032268            0.393844   0.189302   2.081\npasser_name_idM.Nabers_00-0039337            -0.963732   1.537894  -0.627\npasser_name_idM.Penix_00-0039917              0.192313   0.150083   1.281\npasser_name_idM.Rudolph_00-0034771            0.108047   0.088939   1.215\npasser_name_idM.Stafford_00-0026498           0.175709   0.047826   3.674\npasser_name_idM.Trubisky_00-0033869           0.027656   0.133857   0.207\npasser_name_idM.White_00-0034401             -0.846692   0.372994  -2.270\npasser_name_idM.Willis_00-0038128             0.592669   0.200217   2.960\npasser_name_idN.Mullens_00-0033319            0.245545   0.125989   1.949\npasser_name_idP.Mahomes_00-0033873            0.166766   0.044884   3.715\npasser_name_idP.Walker_00-0033275            -0.118658   0.146632  -0.809\npasser_name_idR.Dixon_00-0032943             -1.898686   1.537894  -1.235\npasser_name_idR.Pearsall_00-0039916          -0.530975   1.537894  -0.345\npasser_name_idR.Tannehill_00-0029701          0.112192   0.101850   1.102\npasser_name_idR.Wilson_00-0029263             0.130108   0.055172   2.358\npasser_name_idS.Clifford_00-0038391           2.143627   1.537894   1.394\npasser_name_idS.Darnold_00-0034869            0.227250   0.063368   3.586\npasser_name_idS.Diggs_00-0031588              2.762919   1.537894   1.797\npasser_name_idS.Howell_00-0037077            -0.037628   0.061467  -0.612\npasser_name_idS.Rattler_00-0039376           -0.155761   0.102074  -1.526\npasser_name_idS.Thompson_00-0037327          -0.108968   0.267713  -0.407\npasser_name_idT.Atwell_00-0036849            -0.511101   1.537894  -0.332\npasser_name_idT.Bagent_00-0038416            -0.087392   0.127715  -0.684\npasser_name_idT.Boyd_00-0033009              -3.480742   1.087456  -3.201\npasser_name_idT.Boyle_00-0034177             -0.261962   0.137007  -1.912\npasser_name_idT.DeVito_00-0038476             0.010094   0.103217   0.098\npasser_name_idT.Heinicke_00-0031800           0.041949   0.130443   0.322\npasser_name_idT.Hill_00-0033357               0.004545   0.397083   0.011\npasser_name_idT.Huntley_00-0035993            0.071036   0.118300   0.600\npasser_name_idT.Lance_00-0037012             -0.197803   0.240179  -0.824\npasser_name_idT.Lawrence_00-0036971           0.102932   0.052843   1.948\npasser_name_idT.McKee_00-0038400              0.418308   0.229256   1.825\npasser_name_idT.Morstead_00-0027114           2.670900   1.537894   1.737\npasser_name_idT.Siemian_00-0032156           -0.262247   0.124331  -2.109\npasser_name_idT.Tagovailoa_00-0036212         0.299401   0.049765   6.016\npasser_name_idT.Taylor_00-0028118             0.196781   0.109850   1.791\npasser_name_idT.Townsend_00-0035889           2.439641   1.537894   1.586\npasser_name_idW.Levis_00-0039152              0.052977   0.065339   0.811\npasser_name_idZ.Wilson_00-0037013            -0.037704   0.080497  -0.468\n                                             Pr(&gt;|t|)    \npasser_name_idA.Cole_00-0035190              0.004834 ** \npasser_name_idA.Dalton_00-0027973            0.923665    \npasser_name_idA.Lazard_00-0034521            0.511018    \npasser_name_idA.McCarron_00-0031288          0.355721    \npasser_name_idA.Mitchell_00-0039890          0.111784    \npasser_name_idA.O'Connell_00-0038579         0.201531    \npasser_name_idA.Richardson_00-0039164        0.792697    \npasser_name_idA.Rodgers_00-0023459           0.080823 .  \npasser_name_idA.St. Brown_00-0036963         0.262258    \npasser_name_idB.Allen_00-0032434             0.215448    \npasser_name_idB.Anger_00-0029692             0.008931 ** \npasser_name_idB.Gabbert_00-0027948           0.124893    \npasser_name_idB.Hoyer_00-0026625             0.460791    \npasser_name_idB.Mann_00-0036313              0.006202 ** \npasser_name_idB.Mayfield_00-0034855          6.21e-08 ***\npasser_name_idB.Nix_00-0039732               0.105596    \npasser_name_idB.Purdy_00-0037834             6.90e-12 ***\npasser_name_idB.Rypien_00-0034955            0.205335    \npasser_name_idB.Young_00-0039150             0.820371    \npasser_name_idB.Zappe_00-0038108             0.024469 *  \npasser_name_idC.Beathard_00-0033936          0.567937    \npasser_name_idC.Godwin_00-0033921            0.643774    \npasser_name_idC.Keenum_00-0028986            0.319394    \npasser_name_idC.Kirk_00-0034775              0.419289    \npasser_name_idC.Rush_00-0033662              0.928118    \npasser_name_idC.Stroud_00-0039163            1.94e-05 ***\npasser_name_idC.Sutton_00-0034348            0.000573 ***\npasser_name_idC.Tune_00-0038582              0.003175 ** \npasser_name_idC.Wentz_00-0032950             0.226462    \npasser_name_idC.Williams_00-0039918          0.076441 .  \npasser_name_idC.Wilson_00-0034418            0.185783    \npasser_name_idCo.Heyward_00-0037304          0.869530    \npasser_name_idD.Brown_00-0036626             0.735145    \npasser_name_idD.Carr_00-0031280              0.001601 ** \npasser_name_idD.Henry_00-0032764             0.089557 .  \npasser_name_idD.Hopkins_00-0030564           0.785770    \npasser_name_idD.Jones_00-0035710             0.949598    \npasser_name_idD.Lock_00-0035704              0.871207    \npasser_name_idD.London_00-0037238            0.230516    \npasser_name_idD.Maye_00-0039851              0.148222    \npasser_name_idD.Mills_00-0036898             0.402143    \npasser_name_idD.Montgomery_00-0035685        0.323252    \npasser_name_idD.Mooney_00-0036309            0.782870    \npasser_name_idD.Moore_00-0034827             0.771180    \npasser_name_idD.Prescott_00-0033077          1.54e-05 ***\npasser_name_idD.Ridder_00-0038122            0.562575    \npasser_name_idD.Samuel_00-0035719            0.773212    \npasser_name_idD.Singletary_00-0035250        0.230951    \npasser_name_idD.Thompson-Robinson_00-0038583 0.000343 ***\npasser_name_idD.Watson_00-0033537            0.984363    \npasser_name_idD.Wicks_00-0038393             0.563101    \npasser_name_idE.Stick_00-0035282             0.455631    \npasser_name_idG.Minshew_00-0035289           0.086957 .  \npasser_name_idG.Smith_00-0030565             0.000457 ***\npasser_name_idG.Wilson_00-0037740            0.778047    \npasser_name_idH.Hooker_00-0038550            0.705960    \npasser_name_idJ.Allen_00-0034857             1.23e-07 ***\npasser_name_idJ.Brissett_00-0033119          0.680817    \npasser_name_idJ.Browning_00-0035100          0.017601 *  \npasser_name_idJ.Burrow_00-0036442            4.40e-07 ***\npasser_name_idJ.Chase_00-0036900             0.171521    \npasser_name_idJ.Coker_00-0039491             0.394067    \npasser_name_idJ.Daniels_00-0039910           0.000467 ***\npasser_name_idJ.Dobbs_00-0033949             0.963173    \npasser_name_idJ.Driskel_00-0032436           0.502877    \npasser_name_idJ.Fields_00-0036945            0.056765 .  \npasser_name_idJ.Flacco_00-0026158            0.181248    \npasser_name_idJ.Fox_00-0035156               0.018026 *  \npasser_name_idJ.Garoppolo_00-0031345         0.428677    \npasser_name_idJ.Goff_00-0033106              6.50e-11 ***\npasser_name_idJ.Haener_00-0038998            0.590877    \npasser_name_idJ.Hall_00-0038598              0.830678    \npasser_name_idJ.Hekker_00-0028872            0.004067 ** \npasser_name_idJ.Herbert_00-0036355           8.34e-05 ***\npasser_name_idJ.Hurts_00-0036389             8.55e-06 ***\npasser_name_idJ.Jefferson_00-0036322         0.221744    \npasser_name_idJ.Johnson_00-0026300           0.812919    \npasser_name_idJ.Love_00-0036264              5.02e-05 ***\npasser_name_idJ.McKinnon_00-0031376          0.472305    \npasser_name_idJ.Meyers_00-0034960            0.744579    \npasser_name_idJ.Milton_00-0039398            0.154546    \npasser_name_idJ.Mixon_00-0033897             0.636809    \npasser_name_idJ.Reeves-Maybin_00-0033557     0.007064 ** \npasser_name_idJ.Scott_00-0034162             0.078426 .  \npasser_name_idJ.Smith_00-0033858             0.575213    \npasser_name_idJ.Smith-Njigba_00-0038543      0.144606    \npasser_name_idJ.Stidham_00-0035264           0.200842    \npasser_name_idJ.Winston_00-0031503           0.976348    \npasser_name_idK.Allen_00-0030279             0.368337    \npasser_name_idK.Allen_00-0034577             0.351600    \npasser_name_idK.Bourne_00-0033307            0.390736    \npasser_name_idK.Cousins_00-0029604           0.002524 ** \npasser_name_idK.Gainwell_00-0036919          0.422139    \npasser_name_idK.Murray_00-0035228            0.014653 *  \npasser_name_idK.Pickett_00-0038102           0.880656    \npasser_name_idK.Toney_00-0036913             0.771766    \npasser_name_idK.Trask_00-0036928             0.466856    \npasser_name_idL.Cooke_00-0034437             0.095432 .  \npasser_name_idL.Jackson_00-0034796           3.70e-12 ***\npasser_name_idL.Woodside_00-0034438          0.005816 ** \npasser_name_idM.Jones_00-0036972             0.759783    \npasser_name_idM.Killebrew_00-0032399         0.081664 .  \npasser_name_idM.Mariota_00-0032268           0.037486 *  \npasser_name_idM.Nabers_00-0039337            0.530888    \npasser_name_idM.Penix_00-0039917             0.200070    \npasser_name_idM.Rudolph_00-0034771           0.224431    \npasser_name_idM.Stafford_00-0026498          0.000239 ***\npasser_name_idM.Trubisky_00-0033869          0.836315    \npasser_name_idM.White_00-0034401             0.023214 *  \npasser_name_idM.Willis_00-0038128            0.003077 ** \npasser_name_idN.Mullens_00-0033319           0.051311 .  \npasser_name_idP.Mahomes_00-0033873           0.000203 ***\npasser_name_idP.Walker_00-0033275            0.418395    \npasser_name_idR.Dixon_00-0032943             0.216987    \npasser_name_idR.Pearsall_00-0039916          0.729900    \npasser_name_idR.Tannehill_00-0029701         0.270667    \npasser_name_idR.Wilson_00-0029263            0.018367 *  \npasser_name_idS.Clifford_00-0038391          0.163365    \npasser_name_idS.Darnold_00-0034869           0.000336 ***\npasser_name_idS.Diggs_00-0031588             0.072414 .  \npasser_name_idS.Howell_00-0037077            0.540425    \npasser_name_idS.Rattler_00-0039376           0.127028    \npasser_name_idS.Thompson_00-0037327          0.683988    \npasser_name_idT.Atwell_00-0036849            0.739636    \npasser_name_idT.Bagent_00-0038416            0.493809    \npasser_name_idT.Boyd_00-0033009              0.001372 ** \npasser_name_idT.Boyle_00-0034177             0.055879 .  \npasser_name_idT.DeVito_00-0038476            0.922098    \npasser_name_idT.Heinicke_00-0031800          0.747763    \npasser_name_idT.Hill_00-0033357              0.990868    \npasser_name_idT.Huntley_00-0035993           0.548190    \npasser_name_idT.Lance_00-0037012             0.410191    \npasser_name_idT.Lawrence_00-0036971          0.051434 .  \npasser_name_idT.McKee_00-0038400             0.068064 .  \npasser_name_idT.Morstead_00-0027114          0.082444 .  \npasser_name_idT.Siemian_00-0032156           0.034929 *  \npasser_name_idT.Tagovailoa_00-0036212        1.80e-09 ***\npasser_name_idT.Taylor_00-0028118            0.073243 .  \npasser_name_idT.Townsend_00-0035889          0.112668    \npasser_name_idW.Levis_00-0039152             0.417480    \npasser_name_idZ.Wilson_00-0037013            0.639509    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.538 on 35846 degrees of freedom\nMultiple R-squared:  0.01868,   Adjusted R-squared:  0.01482 \nF-statistic:  4.84 on 141 and 35846 DF,  p-value: &lt; 2.2e-16\n\n\nWe can use the broom package to quickly grab a table of the QB coefficients:\n\nlibrary(broom)\nqb_naive_coefs &lt;- tidy(naive_epa_lm)\nqb_naive_coefs\n\n# A tibble: 141 × 5\n   term                                  estimate std.error statistic p.value\n   &lt;chr&gt;                                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 passer_name_idA.Cole_00-0035190        4.33       1.54      2.82   0.00483\n 2 passer_name_idA.Dalton_00-0027973     -0.00998    0.104    -0.0958 0.924  \n 3 passer_name_idA.Lazard_00-0034521     -1.01       1.54     -0.657  0.511  \n 4 passer_name_idA.McCarron_00-0031288   -0.635      0.688    -0.924  0.356  \n 5 passer_name_idA.Mitchell_00-0039890    2.45       1.54      1.59   0.112  \n 6 passer_name_idA.O'Connell_00-0038579   0.0813     0.0636    1.28   0.202  \n 7 passer_name_idA.Richardson_00-0039164 -0.0217     0.0827   -0.263  0.793  \n 8 passer_name_idA.Rodgers_00-0023459     0.111      0.0636    1.75   0.0808 \n 9 passer_name_idA.St. Brown_00-0036963   1.72       1.54      1.12   0.262  \n10 passer_name_idB.Allen_00-0032434      -0.348      0.281    -1.24   0.215  \n# ℹ 131 more rows\n\n\nIn order to make a plot comparing the coefficients, we can make a modified version of this table containing a column with the passer_name_id and fixed effect version for coefficients:\n\nqb_fixed_eff &lt;- qb_naive_coefs |&gt;\n  dplyr::select(term, estimate) |&gt;\n  # Remove the `passer_name_id` in the strings\n  mutate(term = str_remove(term, \"passer_name_id\")) |&gt;\n  rename(passer_name_id = term,\n         fixed_eff = estimate)\n\nqb_fixed_eff\n\n# A tibble: 141 × 2\n   passer_name_id          fixed_eff\n   &lt;chr&gt;                       &lt;dbl&gt;\n 1 A.Cole_00-0035190         4.33   \n 2 A.Dalton_00-0027973      -0.00998\n 3 A.Lazard_00-0034521      -1.01   \n 4 A.McCarron_00-0031288    -0.635  \n 5 A.Mitchell_00-0039890     2.45   \n 6 A.O'Connell_00-0038579    0.0813 \n 7 A.Richardson_00-0039164  -0.0217 \n 8 A.Rodgers_00-0023459      0.111  \n 9 A.St. Brown_00-0036963    1.72   \n10 B.Allen_00-0032434       -0.348  \n# ℹ 131 more rows\n\n\nWe can now join this table of fixed effect QB estimates to the table containing the random effects via a join function (such as left_join() or inner_join() but my default behavior is to typically use left_join()):\n\nqb_ranef &lt;- qb_ranef |&gt;\n  left_join(qb_fixed_eff,\n            by = c(\"level\" = \"passer_name_id\"))\nqb_ranef\n\n# A tibble: 141 × 8\n   effect   group          level  term  estimate std.error q_intercept fixed_eff\n   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 ran_vals passer_name_id A.Col… (Int…  0.0261     0.121       0.118    4.33   \n 2 ran_vals passer_name_id A.Dal… (Int… -0.0587     0.0790      0.0335  -0.00998\n 3 ran_vals passer_name_id A.Laz… (Int… -0.00678    0.121       0.0854  -1.01   \n 4 ran_vals passer_name_id A.McC… (Int… -0.0218     0.119       0.0704  -0.635  \n 5 ran_vals passer_name_id A.Mit… (Int…  0.0145     0.121       0.107    2.45   \n 6 ran_vals passer_name_id A.O'C… (Int… -0.00854    0.0564      0.0836   0.0813 \n 7 ran_vals passer_name_id A.Ric… (Int… -0.0776     0.0683      0.0145  -0.0217 \n 8 ran_vals passer_name_id A.Rod… (Int…  0.0148     0.0563      0.107    0.111  \n 9 ran_vals passer_name_id A.St.… (Int…  0.0100     0.121       0.102    1.72   \n10 ran_vals passer_name_id B.All… (Int… -0.0689     0.111       0.0233  -0.348  \n# ℹ 131 more rows\n\n\nUsing this table, we can now create a figure that displays the two types of estimates: no pooling (fixed_eff) and partial pooling (q_intercept). The following code chunk shows how to do this using the pivot_longer() function to make the dataset in a long format for ggplot2:\n\nlong_qb_eff_table &lt;- qb_ranef |&gt;\n  dplyr::select(level, q_intercept, fixed_eff) |&gt;\n  pivot_longer(q_intercept:fixed_eff,\n               names_to = \"type\",\n               values_to = \"estimate\") \n\n# Now make the visualization:\nlong_qb_eff_table |&gt;\n  # First recode the name of the estimate types:\n  mutate(type = fct_recode(type, `no pooling` = \"fixed_eff\",\n                           `partial pooling` = \"q_intercept\")) |&gt;\n  ggplot(aes(x = level, y = estimate, color = type)) +\n  geom_point() +\n  # Add horizontal dashed line for fixed effect intercept:\n  geom_hline(yintercept = as.numeric(fixef(epa_lmm)),\n             linetype = \"dashed\", color = \"black\") +\n  labs(x = \"QB\", y = \"Estimate\") +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 90, size = 4),\n        legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nWe can see the noticeable impact from pooling on the QB intercepts, with all of the partial pooling estimates from the multilevel model getting pulled towards average line versus the extreme values based on no pooling.\nTo illustrate this idea more clearly, the following figure zooms in on a sample of QBs (arbitrarily picked by me):\n\nlong_qb_eff_table |&gt;\n  filter(str_detect(level, \"(Purdy)|(Mahomes)|(Fields)|(J\\\\.Daniels)|(Hurts)|(B\\\\.Young)\")) |&gt;\n  mutate(type = fct_recode(type, `no pooling` = \"fixed_eff\",\n                           `partial pooling` = \"q_intercept\")) |&gt;\n  ggplot(aes(x = level, y = estimate, color = type)) +\n  geom_point() +\n  # Add horizontal dashed line for fixed effect intercept:\n  geom_hline(yintercept = as.numeric(fixef(epa_lmm)),\n             linetype = \"dashed\", color = \"black\") +\n  labs(x = \"QB\", y = \"Estimate\") +\n  theme_bw() +\n  coord_flip() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "demos/08-random-effects-pooling.html#comparison-of-regression-lines",
    "href": "demos/08-random-effects-pooling.html#comparison-of-regression-lines",
    "title": "Lecture 9: Random effects and pooling",
    "section": "Comparison of regression lines",
    "text": "Comparison of regression lines\nAs we discussed in previous lectures and demo material, we can add in other covariates as fixed effects. The use of varying intercepts will effectively lead to a distribution of regression lines for each passer in the dataset that is centered around the average passer line. The following code chunk first fits the updated lmer model with air yards as an additional feature:\n\nair_epa_lmm &lt;- lmer(epa ~ air_yards + (1 | passer_name_id), \n                    data = nfl_passing_data, REML = TRUE)\n\nsummary(air_epa_lmm)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: epa ~ air_yards + (1 | passer_name_id)\n   Data: nfl_passing_data\n\nREML criterion at convergence: 132840.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-8.3328 -0.5391 -0.0849  0.5736  5.3048 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.01414  0.1189  \n Residual                   2.34071  1.5299  \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n              Estimate Std. Error t value\n(Intercept) -0.0383751  0.0178653  -2.148\nair_yards    0.0169528  0.0007922  21.400\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.342\n\n\nSimilar to before, we can grab the random intercepts for each passer:\n\nupd_qb_ranef &lt;- tidy(air_epa_lmm, effects = \"ran_vals\")\n# View the dataset\nupd_qb_ranef\n\n# A tibble: 141 × 6\n   effect   group          level                   term       estimate std.error\n   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;                   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n 1 ran_vals passer_name_id A.Cole_00-0035190       (Intercep…  0.0258     0.119 \n 2 ran_vals passer_name_id A.Dalton_00-0027973     (Intercep… -0.0519     0.0781\n 3 ran_vals passer_name_id A.Lazard_00-0034521     (Intercep… -0.00757    0.119 \n 4 ran_vals passer_name_id A.McCarron_00-0031288   (Intercep… -0.0167     0.117 \n 5 ran_vals passer_name_id A.Mitchell_00-0039890   (Intercep…  0.0155     0.119 \n 6 ran_vals passer_name_id A.O'Connell_00-0038579  (Intercep… -0.00814    0.0559\n 7 ran_vals passer_name_id A.Richardson_00-0039164 (Intercep… -0.118      0.0676\n 8 ran_vals passer_name_id A.Rodgers_00-0023459    (Intercep…  0.0254     0.0558\n 9 ran_vals passer_name_id A.St. Brown_00-0036963  (Intercep…  0.0101     0.119 \n10 ran_vals passer_name_id B.Allen_00-0032434      (Intercep… -0.0684     0.109 \n# ℹ 131 more rows\n\n\nAnd then modify the dataset to include columns for the regression intercepts and slopes based on the fixed effects:\n\nupd_qb_ranef &lt;- upd_qb_ranef |&gt;\n  # Grab the fixed effect estimates and coefficients via 1 for intercept and \n  # 2 for slope:\n  mutate(q_intercept = estimate + as.numeric(fixef(air_epa_lmm))[1],\n         q_slope = as.numeric(fixef(air_epa_lmm))[2])\n\nWith this dataset, we can now make a visualization that has a regression line for every QB given their respective intercepts (and shared slope):\n\nupd_qb_ranef |&gt;\n  ggplot() +\n  geom_abline(aes(slope = q_slope, intercept = q_intercept),\n              alpha = 0.1) +\n  scale_y_continuous(limits = c(-2, 2)) +\n  scale_x_continuous(limits = c(-5,\n                                max(nfl_passing_data$air_yards))) +\n  labs(x = \"Air yards of pass attempt\", y = \"Expected points added\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nFor reference we will also add the “center” regression line on top of the distribution of regression lines just based on the fixed effects. You can see in the figure below that this average line (in dashed red) aligns closely with the thick black line from the previous figure that represents the mode of the regression lines:\n\nupd_qb_ranef |&gt;\n  ggplot() +\n  geom_abline(aes(slope = q_slope, intercept = q_intercept),\n              alpha = 0.1) +\n  geom_abline(slope = as.numeric(fixef(air_epa_lmm))[2],\n              intercept = as.numeric(fixef(air_epa_lmm))[1],\n              color = \"red\", linetype = \"dashed\") +\n  scale_y_continuous(limits = c(-2, 2)) +\n  scale_x_continuous(limits = c(-5,\n                                max(nfl_passing_data$air_yards))) +\n  labs(x = \"Air yards of pass attempt\", y = \"Expected points added\") +\n  theme_bw()"
  },
  {
    "objectID": "demos/00-into-tidyverse.html",
    "href": "demos/00-into-tidyverse.html",
    "title": "Demo 01: Into the tidyverse",
    "section": "",
    "text": "(Broadly speaking) EDA = questions about data + wrangling + visualization\nR for Data Science: “EDA is a state of mind”, an iterative cycle:\n\ngenerate questions\nanswer via transformations and visualizations\n\nExample of questions?\n\nWhat type of variation do the variables display?\nWhat type of relationships exist between variables?\n\nGoal: develop understanding and become familiar with your data\n\nEDA is NOT a replacement for statistical inference and learning\nEDA is an important and necessary step to build intuition\n\nWe tackle the challenges of EDA with a data science workflow. An example of this according to Hadley Wickham in R for Data Science:\n\n\n\n\n\nAspects of data wrangling:\n\nimport: reading in data (e.g., read_csv())\ntidy: rows = observations, columns = variables (i.e. tabular data)\ntransform: filter observations, create new variables, summarize, etc."
  },
  {
    "objectID": "demos/00-into-tidyverse.html#what-is-exploratory-data-analysis-eda",
    "href": "demos/00-into-tidyverse.html#what-is-exploratory-data-analysis-eda",
    "title": "Demo 01: Into the tidyverse",
    "section": "",
    "text": "(Broadly speaking) EDA = questions about data + wrangling + visualization\nR for Data Science: “EDA is a state of mind”, an iterative cycle:\n\ngenerate questions\nanswer via transformations and visualizations\n\nExample of questions?\n\nWhat type of variation do the variables display?\nWhat type of relationships exist between variables?\n\nGoal: develop understanding and become familiar with your data\n\nEDA is NOT a replacement for statistical inference and learning\nEDA is an important and necessary step to build intuition\n\nWe tackle the challenges of EDA with a data science workflow. An example of this according to Hadley Wickham in R for Data Science:\n\n\n\n\n\nAspects of data wrangling:\n\nimport: reading in data (e.g., read_csv())\ntidy: rows = observations, columns = variables (i.e. tabular data)\ntransform: filter observations, create new variables, summarize, etc."
  },
  {
    "objectID": "demos/00-into-tidyverse.html#working-with-penguins",
    "href": "demos/00-into-tidyverse.html#working-with-penguins",
    "title": "Demo 01: Into the tidyverse",
    "section": "Working with penguins",
    "text": "Working with penguins\nIn R, there are many libraries or packages/groups of programs that are not permanently stored in R, so we have to load them when we want to use them. You can load an R package by typing library(package_name). (Sometimes we need to download/install the package first, as described in HW0.)\nThroughout this demo we will use the palmerpenguins dataset. To access the data, you will need to install the palmerpenguins package:\n\ninstall.packages(\"palmerpenguins\")\n\nImport the penguins dataset by loading the palmerpenguins package using the library function and then access the data with the data() function:\n\nlibrary(palmerpenguins) \ndata(penguins)\n\nView some basic info about the penguins dataset:\n\n# displays same info as c(nrow(penguins), ncol(penguins))\ndim(penguins) \n\n[1] 344   8\n\nclass(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\ntbl (pronounced tibble) is the tidyverse way of storing tabular data, like a spreadsheet or data.frame\nI assure you that you’ll run into errors as you code in R; in fact, my attitude as a coder is that something is wrong if I never get any errors while working on a project. When you run into an error, your first reaction may be to panic and post a question to Piazza. However, checking help documentation in R can be a great way to figure out what’s going wrong. (For good or bad, I end up having to read help documentation almost every day of my life - because, well, I regularly make mistakes in R.)\nLook at the help documentation for penguins by typing help(penguins) in the Console. What are the names of the variables in this dataset? How many observations are in this dataset?\n\nhelp(penguins)\n\nYou should always look at your data before doing anything: view the first 6 (by default) rows with head()\n\nhead(penguins) # Try just typing penguins into your console, what happens?\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nIs our penguins dataset tidy?\n\nEach row = a single penguin\nEach column = different measurement about the penguins (can print out column names directly with colnames(penguins) or names(penguins))\n\nWe’ll now explore differences among the penguins using the tidyverse."
  },
  {
    "objectID": "demos/00-into-tidyverse.html#let-the-data-wrangling-begin",
    "href": "demos/00-into-tidyverse.html#let-the-data-wrangling-begin",
    "title": "Demo 01: Into the tidyverse",
    "section": "Let the data wrangling begin…",
    "text": "Let the data wrangling begin…\nFirst, load the tidyverse for exploring the data - and do NOT worry about the warning messages that will pop-up! Warning messages will tell you when other packages that are loaded may have functions replaced with the most recent package you’ve loaded. In general though, you should just be concerned when an error message pops up (errors are different than warnings!).\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nWe’ll start by summarizing continuous (e.g., bill_length_mm, flipper_length_mm) and categorical (e.g., species, island) variables in different ways.\nWe can compute summary statistics for continuous variables with the summary() function:\n\nsummary(penguins$bill_length_mm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  32.10   39.23   44.45   43.92   48.50   59.60       2 \n\n\nCompute counts of categorical variables with table() function:\n\ntable(\"island\" = penguins$island) # be careful it ignores NA values!\n\nisland\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\nHow do we remove the penguins with missing bill_length_mm values? Within the tidyverse, dplyr is a package with functions for data wrangling (because it’s within the tidyverse that means you do NOT have to load it separately with library(dplyr) after using library(tidyverse)!). It’s considered a “grammar of data manipulation”: dplyr functions are verbs, datasets are nouns.\nWe can filter() our dataset to choose observations meeting conditions:\n\nclean_penguins &lt;- filter(penguins, !is.na(bill_length_mm))\n# Use help(is.na) to see what it returns. And then observe \n# that the ! operator means to negate what comes after it.\n# This means !TRUE == FALSE (i.e., opposite of TRUE is equal to FALSE).\nnrow(penguins) - nrow(clean_penguins) # Difference in rows\n\n[1] 2\n\n\nIf we want to only consider a subset of columns in our data, we can select() variables of interest:\n\nsel_penguins &lt;- select(clean_penguins, species, island, bill_length_mm, flipper_length_mm)\nhead(sel_penguins, n = 3)\n\n# A tibble: 3 × 4\n  species island    bill_length_mm flipper_length_mm\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;             &lt;int&gt;\n1 Adelie  Torgersen           39.1               181\n2 Adelie  Torgersen           39.5               186\n3 Adelie  Torgersen           40.3               195\n\n\nWe can arrange() our dataset to sort observations by variables:\n\nbill_penguins &lt;- arrange(sel_penguins, desc(bill_length_mm)) # use desc() for descending order\nhead(bill_penguins, n = 3)\n\n# A tibble: 3 × 4\n  species   island bill_length_mm flipper_length_mm\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;             &lt;int&gt;\n1 Gentoo    Biscoe           59.6               230\n2 Chinstrap Dream            58                 181\n3 Gentoo    Biscoe           55.9               228\n\n\nWe can summarize() our dataset to one row based on functions of variables:\n\nsummarize(bill_penguins, max(bill_length_mm), median(flipper_length_mm))\n\n# A tibble: 1 × 2\n  `max(bill_length_mm)` `median(flipper_length_mm)`\n                  &lt;dbl&gt;                       &lt;dbl&gt;\n1                  59.6                         197\n\n\nWe can mutate() our dataset to create new variables:\n\nnew_penguins &lt;- mutate(bill_penguins, \n                       bill_flipper_ratio = bill_length_mm / flipper_length_mm,\n                       flipper_bill_ratio = flipper_length_mm / bill_length_mm)\nhead(new_penguins, n = 1)\n\n# A tibble: 1 × 6\n  species island bill_length_mm flipper_length_mm bill_flipper_ratio\n  &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;             &lt;int&gt;              &lt;dbl&gt;\n1 Gentoo  Biscoe           59.6               230              0.259\n# ℹ 1 more variable: flipper_bill_ratio &lt;dbl&gt;\n\n\nHow do we perform several of these actions?\n\nhead(arrange(select(mutate(filter(penguins, !is.na(flipper_length_mm)), bill_flipper_ratio = bill_length_mm / flipper_length_mm), species, island, bill_flipper_ratio), desc(bill_flipper_ratio)), n = 1)\n\n# A tibble: 1 × 3\n  species   island bill_flipper_ratio\n  &lt;fct&gt;     &lt;fct&gt;               &lt;dbl&gt;\n1 Chinstrap Dream               0.320\n\n\nThat’s awfully annoying to do, and also difficult to read…"
  },
  {
    "objectID": "demos/00-into-tidyverse.html#enter-the-pipeline",
    "href": "demos/00-into-tidyverse.html#enter-the-pipeline",
    "title": "Demo 01: Into the tidyverse",
    "section": "Enter the pipeline",
    "text": "Enter the pipeline\nThe |&gt; (pipe) operator is used in the to chain commands together. Note: you can also use the tidyverse pipe %&gt;% (from magrittr), but |&gt; is the built-in pipe that is native to new versions of R without loading the tidyverse.\n|&gt; directs the data analyis pipeline: output of one function pipes into input of the next function\n\npenguins |&gt;\n  filter(!is.na(flipper_length_mm)) |&gt;\n  mutate(bill_flipper_ratio = bill_length_mm / flipper_length_mm) |&gt;\n  select(species, island, bill_flipper_ratio) |&gt;\n  arrange(desc(bill_flipper_ratio)) |&gt;\n  head(n = 5)\n\n# A tibble: 5 × 3\n  species   island bill_flipper_ratio\n  &lt;fct&gt;     &lt;fct&gt;               &lt;dbl&gt;\n1 Chinstrap Dream               0.320\n2 Chinstrap Dream               0.275\n3 Chinstrap Dream               0.270\n4 Chinstrap Dream               0.270\n5 Chinstrap Dream               0.268"
  },
  {
    "objectID": "demos/00-into-tidyverse.html#more-pipeline-actions",
    "href": "demos/00-into-tidyverse.html#more-pipeline-actions",
    "title": "Demo 01: Into the tidyverse",
    "section": "More pipeline actions!",
    "text": "More pipeline actions!\nInstead of head(), we can slice() our dataset to choose the observations based on the position\n\npenguins |&gt;\n  filter(!is.na(flipper_length_mm)) |&gt;\n  mutate(bill_flipper_ratio = bill_length_mm / flipper_length_mm) |&gt;\n  select(species, island, bill_flipper_ratio) |&gt;\n  arrange(desc(bill_flipper_ratio)) |&gt;\n  slice(c(1, 2, 10, 100))\n\n# A tibble: 4 × 3\n  species   island bill_flipper_ratio\n  &lt;fct&gt;     &lt;fct&gt;               &lt;dbl&gt;\n1 Chinstrap Dream               0.320\n2 Chinstrap Dream               0.275\n3 Chinstrap Dream               0.264\n4 Gentoo    Biscoe              0.227"
  },
  {
    "objectID": "demos/00-into-tidyverse.html#grouped-operations",
    "href": "demos/00-into-tidyverse.html#grouped-operations",
    "title": "Demo 01: Into the tidyverse",
    "section": "Grouped operations",
    "text": "Grouped operations\nWe group_by() to split our dataset into groups based on a variable’s values\n\npenguins |&gt;\n  filter(!is.na(flipper_length_mm)) |&gt;\n  group_by(island) |&gt;\n  summarize(n_penguins = n(), #counts number of rows in group\n            ave_flipper_length = mean(flipper_length_mm), \n            sum_bill_depth = sum(bill_depth_mm),\n            .groups = \"drop\") |&gt; # all levels of grouping dropping\n  arrange(desc(n_penguins)) |&gt;\n  slice(1:5)\n\n# A tibble: 3 × 4\n  island    n_penguins ave_flipper_length sum_bill_depth\n  &lt;fct&gt;          &lt;int&gt;              &lt;dbl&gt;          &lt;dbl&gt;\n1 Biscoe           167               210.          2651.\n2 Dream            124               193.          2275.\n3 Torgersen         51               191.           940.\n\n\n\ngroup_by() is only useful in a pipeline (e.g. with summarize()), and pay attention to its behavior\nspecify the .groups field to decide if observations remain grouped or not after summarizing (you can also use ungroup() for this as well)"
  },
  {
    "objectID": "demos/00-into-tidyverse.html#putting-it-all-together",
    "href": "demos/00-into-tidyverse.html#putting-it-all-together",
    "title": "Demo 01: Into the tidyverse",
    "section": "Putting it all together…",
    "text": "Putting it all together…\nAs your own exercise, create a tidy dataset where each row == an island with the following variables:\n\nnumber of penguins,\nnumber of unique species on the island (see help(unique)),\naverage body_mass_g,\nvariance (see help(var)) of bill_depth_mm\n\nPrior to making those variables, make sure to filter missings and also only consider female penguins. Then arrange the islands in order of the average body_mass_g:\n\n# INSERT YOUR CODE HERE"
  },
  {
    "objectID": "demos.html",
    "href": "demos.html",
    "title": "Demos",
    "section": "",
    "text": "Demo\nDate\nTitle\nDemo file\n\n\n\n\n0\nJan 14\nInto the tidyverse\nHTML\n\n\n1\nJan 16\nBuilding an Expected Goals Model\nHTML\n\n\n2\nJan 21\nCalibration and Cross-Validation\nHTML\n\n\n3\nJan 23\nMultinomial Logistic Regression for Expected Points\nHTML\n\n\n4a\nJan 28\nExploring Expected Points Added\nHTML\n\n\n4b\nJan 28\nCompletion Percentage Over Expectation\nHTML\n\n\n5\nJan 30\nIntro to multilevel modeling\nHTML\n\n\n6\nFeb 4\nVarying intercepts and slopes\nHTML\n\n\n7\nFeb 6\nNested and crossed random effects\nHTML\n\n\n8\nFeb 11\nRandom effects and pooling\nHTML\n\n\n9\nFeb 13\nUncertainty about random effects\nHTML\n\n\n10\nFeb 18\nIntroduction to Bayes with a Binomial model\nHTML\n\n\n11\nFeb 20\nBeta-Binomial model for Caitlin Clark’s rookie season\nHTML\n\n\n12\nFeb 25\nIntroduction to Regularized Adjusted Plus-Minus (RAPM)\nHTML\n\n\n13\nMar 11\nMethods for Approximating the Posterior\nHTML\n\n\n14\nMar 18\nIntroduction to Stan\nHTML\n\n\n15\nMar 20\nBayesian RAPM in Stan\nHTML",
    "crumbs": [
      "Demos"
    ]
  }
]