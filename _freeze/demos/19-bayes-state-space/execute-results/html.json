{
  "hash": "2ce4e29651e550a4292faa2356baf468",
  "result": {
    "markdown": "---\ntitle: \"Lecture 21: Bayesian state-space model for NFL team ratings\"\nformat: html\n---\n\n\n## Introduction\n\nThe purpose of this demo is to demonstrate how to fit a simple Bayesian state-space model, following the structure of the famous [Glickman and Stern model (1998, 2017)](http://stat.wharton.upenn.edu/~steele/Resources/FTSResources/StateSpaceModels/KFApplications/GlickmanStern98.pdf). We'll demonstrate this using a dataset of NFL game outcomes during the Patrick Mahomes era (2018 to present, marking the years since Mahomes became the starting QB for Kansas City). You can find this dataset under demos/week12 as `nfl_mahomes_era_games.csv`, with the script to generate the dataset `get_mahomes_era_nfl_games.csv`. The following code chunk reads in the dataset, makes sure that Raiders are labeled as LV, and displays the columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nnfl_games <- read_csv(here::here(\"data/nfl_mahomes_era_games.csv\")) |>\n  # Combine OAK into LV:\n  mutate(home_team = ifelse(home_team == \"OAK\", \"LV\", home_team),\n         away_team = ifelse(away_team == \"OAK\", \"LV\", away_team))\n\nnfl_games\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,942 × 10\n   season game_id      game_type  week home_team away_team home_score away_score\n    <dbl> <chr>        <chr>     <dbl> <chr>     <chr>          <dbl>      <dbl>\n 1   2018 2018_01_ATL… REG           1 PHI       ATL               18         12\n 2   2018 2018_01_BUF… REG           1 BAL       BUF               47          3\n 3   2018 2018_01_PIT… REG           1 CLE       PIT               21         21\n 4   2018 2018_01_CIN… REG           1 IND       CIN               23         34\n 5   2018 2018_01_TEN… REG           1 MIA       TEN               27         20\n 6   2018 2018_01_SF_… REG           1 MIN       SF                24         16\n 7   2018 2018_01_HOU… REG           1 NE        HOU               27         20\n 8   2018 2018_01_TB_… REG           1 NO        TB                40         48\n 9   2018 2018_01_JAX… REG           1 NYG       JAX               15         20\n10   2018 2018_01_KC_… REG           1 LAC       KC                28         38\n# ℹ 1,932 more rows\n# ℹ 2 more variables: game_outcome <dbl>, score_diff <dbl>\n```\n:::\n:::\n\n\n## Model set-up\n\nWe're now going to proceed to set-up the Bayesian state-space model. First, we'll initialize our dataset in the manner appropriate for handling in Stan. This dataset will look similar to the RAPM data, except the indicators are constructed at the team level:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First just get the context: season, week, game_id, and score_diff:\ngames_context <- nfl_games |>\n  dplyr::select(season, week, game_id, score_diff) |>\n  # Make a season index that will be used in Stan:\n  mutate(season_index = season - min(season) + 1)\n\n# Next set-up indicators for home teams:\nhome_teams <- nfl_games |>\n  dplyr::select(game_id, home_team) |>\n  mutate(is_home = 1) |>\n  pivot_wider(id_cols = c(\"game_id\"),\n              names_from = home_team,\n              values_from = is_home,\n              values_fill = 0)\n\n# And now indicators for away teams:\naway_teams <- nfl_games |>\n  dplyr::select(game_id, away_team) |>\n  mutate(is_away = -1) |>\n  pivot_wider(id_cols = c(\"game_id\"),\n              names_from = away_team,\n              values_from = is_away,\n              values_fill = 0)\n\n# Stack the home and away together, take the sum so that we get one row for \n# each game, where home teams are 1 and away teams are -1:\ngames_data <- home_teams |>\n  bind_rows(away_teams) |>\n  group_by(game_id) |>\n  summarize(across(everything(), ~ sum(.x, na.rm = TRUE)),\n            .groups = \"drop\")\n\n# Join this back to the context :\ngames_data <- games_context |>\n  inner_join(games_data, by = c(\"game_id\"))\n\ngames_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,942 × 37\n   season  week game_id    score_diff season_index   PHI   BAL   CLE   IND   MIA\n    <dbl> <dbl> <chr>           <dbl>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1   2018     1 2018_01_A…          6            1     1     0     0     0     0\n 2   2018     1 2018_01_B…         44            1     0     1     0     0     0\n 3   2018     1 2018_01_P…          0            1     0     0     1     0     0\n 4   2018     1 2018_01_C…        -11            1     0     0     0     1     0\n 5   2018     1 2018_01_T…          7            1     0     0     0     0     1\n 6   2018     1 2018_01_S…          8            1     0     0     0     0     0\n 7   2018     1 2018_01_H…          7            1     0     0     0     0     0\n 8   2018     1 2018_01_T…         -8            1     0     0     0     0     0\n 9   2018     1 2018_01_J…         -5            1     0     0     0     0     0\n10   2018     1 2018_01_K…        -10            1     0     0     0     0     0\n# ℹ 1,932 more rows\n# ℹ 27 more variables: MIN <dbl>, NE <dbl>, NO <dbl>, NYG <dbl>, LAC <dbl>,\n#   ARI <dbl>, CAR <dbl>, DEN <dbl>, GB <dbl>, DET <dbl>, LV <dbl>, CIN <dbl>,\n#   ATL <dbl>, BUF <dbl>, NYJ <dbl>, PIT <dbl>, TB <dbl>, TEN <dbl>, WAS <dbl>,\n#   LA <dbl>, SF <dbl>, JAX <dbl>, DAL <dbl>, CHI <dbl>, HOU <dbl>, KC <dbl>,\n#   SEA <dbl>\n```\n:::\n:::\n\n\nNow with the data constructed, we can use Stan to simulate from the posterior distribution for the considered model parameters. \n\nThe following chunk below displays the Stan code that is also available in `bayes_state_space_nfl.stan`. You'll notice that this code relies on for loops to simplify the process at referring to which season for the team rating. The details about this code will be discussed in lecture.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_state_space_model <- \"\ndata{\n  // Set-up the context in terms of dataset size\n  int<lower = 1> N_games; \n  int<lower = 1> N_teams;\n  // Need at least 2 seasons of data here\n  int<lower = 2> N_seasons;\n  // Response vector\n  vector[N_games] y;\n  // Design matrix\n  matrix[N_games, N_teams] X_teams; \n  // Season vector:\n  int<lower = 1, upper = N_seasons> season[N_games];\n}\n\n// The parameters accepted by the model\nparameters {\n  // Matrix of team coefficients\n  matrix[N_seasons, N_teams] thetas;\n  // Game-level variance\n  real<lower = 0> sigma_games;\n  // Team-level variance to start\n  real<lower = 0> sigma_teams;\n  // Season-level innovation variance \n  real<lower = 0> sigma_seasons;\n  // Autoregressive parameter\n  real<lower = 0, upper = 1> gamma;\n}\n\n// The state-space model\nmodel {\n  // Game level data\n  for (i in 1:N_games) {\n    y[i] ~ normal(dot_product(X_teams[i], thetas[season[i]]), sigma_games);\n  }\n  \n  // Team ratings - starting with initial season:\n  for (j in 1:N_teams) {\n    thetas[1, j] ~ normal(0, sigma_teams);\n    // Autoregressive model:\n    for (s in 2:N_seasons) {\n      thetas[s, j] ~ normal(gamma * thetas[s - 1, j], sigma_seasons);\n    }\n  }\n  \n  // Priors:\n  sigma_games ~ normal(0, 5);\n  sigma_teams ~ normal(0, 5);\n  sigma_seasons ~ normal(0, 5);\n  gamma ~ uniform(0, 1);\n  \n}\n\"\n```\n:::\n\n\n\nThe following code chunk sets up the data list and then uses `rstan` to start sampling. __NOTE: this code takes about 30 seconds to run on my computer, fairly quick given the relatively small dataset!__ \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the team indicators as a matrix:\nteam_matrix <- games_data |>\n  dplyr::select(-c(season, week, game_id, score_diff, season_index)) |>\n  as.matrix()\n\n# Set-up the data list for the model:\nbayes_state_space_data <- list(N_games = nrow(games_data),\n                               N_teams = ncol(team_matrix),\n                               N_seasons = max(games_data$season_index),\n                               y = games_data$score_diff,\n                               X_teams = team_matrix,\n                               season = games_data$season_index)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assuming the file is in the right directory, start sampling from the posterior\nlibrary(rstan)\nbayes_state_space_fit <- stan(file = \"demos/week12/bayes_state_space_nfl.stan\", \n                              data = bayes_state_space_data, \n                              chains = 4, iter = 2500 * 2, \n                              cores = 4,\n                              seed = 2025)\n```\n:::\n\n\nThe following code chunk reads in the saved `.rds` object from the Stan model fit (that was created in the `fit_bayes_state_space_nfl.R` script on Canvas):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayes_state_space_fit <- read_rds(here::here(\"data/bayes_state_space_fit.rds\"))\n```\n:::\n\n\nSimilar to before, we should check MCMC diagnostics for our posterior samples. But for now I'll skip that and leave that as an exercise for you to complete.\n\n## Posterior Analysis\n\nWe're now ready to examine the posterior distributions for the parameters. First, we'll create a simple, tidy table that has one column for each parameter (excluding Stan's reported log posterior density). The following code chunk sets up this table with 10,000 rows (one for each sample) and 196 columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_posterior_samples <- as.data.frame(bayes_state_space_fit, \n                                       pars = \"lp__\", include = FALSE) |>\n  as_tibble()\n\nraw_posterior_samples\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10,000 × 228\n   `thetas[1,1]` `thetas[2,1]` `thetas[3,1]` `thetas[4,1]` `thetas[5,1]`\n           <dbl>         <dbl>         <dbl>         <dbl>         <dbl>\n 1          3.69       -1.32          -4.31           2.05         5.58 \n 2          8.47        3.56           0.737          4.44         6.56 \n 3          5.90       -3.98          -5.85           5.14         5.36 \n 4         -6.94       -0.0864        -0.721         -1.62         8.00 \n 5          4.60       -3.66          -8.84           6.45        10.2  \n 6          4.59       -1.68          -5.53           7.03         8.74 \n 7         -1.95        2.61           1.59           3.30        14.3  \n 8          2.90        0.540         -4.56           2.63         0.810\n 9          1.06       -4.72          -0.741          3.94         8.90 \n10          4.43       -0.649         -1.42           1.85         7.06 \n# ℹ 9,990 more rows\n# ℹ 223 more variables: `thetas[6,1]` <dbl>, `thetas[7,1]` <dbl>,\n#   `thetas[1,2]` <dbl>, `thetas[2,2]` <dbl>, `thetas[3,2]` <dbl>,\n#   `thetas[4,2]` <dbl>, `thetas[5,2]` <dbl>, `thetas[6,2]` <dbl>,\n#   `thetas[7,2]` <dbl>, `thetas[1,3]` <dbl>, `thetas[2,3]` <dbl>,\n#   `thetas[3,3]` <dbl>, `thetas[4,3]` <dbl>, `thetas[5,3]` <dbl>,\n#   `thetas[6,3]` <dbl>, `thetas[7,3]` <dbl>, `thetas[1,4]` <dbl>, …\n```\n:::\n:::\n\n\nYou can see that the dataset of posterior samples is quite different looking from the RAPM example. There are columns named `thetas[row_index,col_index]`, these are referring to the matrix of team ratings `thetas` that have one row for each season and one column for each team. So `thetas[1,1]` would provide us with the posterior distribution for the first team in the first year of the dataset, which is 2018. \n\nFor each ease, we'll first separate the variance columns from the team ratings. The code below grabs the variance and autocorrelation posterior distributions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariance_posterior_samples <- raw_posterior_samples |>\n  dplyr::select(-contains(\"thetas\"))\nvariance_posterior_samples\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10,000 × 4\n   sigma_games sigma_teams sigma_seasons gamma\n         <dbl>       <dbl>         <dbl> <dbl>\n 1        12.2        7.29          4.17 0.593\n 2        12.4        4.59          3.90 0.605\n 3        12.5        6.51          4.15 0.635\n 4        12.6        5.03          4.18 0.479\n 5        12.1        5.53          4.79 0.623\n 6        12.4        4.75          4.71 0.607\n 7        12.6        4.21          4.36 0.396\n 8        12.4        5.10          3.63 0.708\n 9        12.2        6.61          3.68 0.764\n10        12.5        5.22          3.26 0.770\n# ℹ 9,990 more rows\n```\n:::\n:::\n\n\nWe can first see what the posterior distribution is for the autoregressive parameter $\\gamma$, with heavy concentration between values of 0.5 to 0.8:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariance_posterior_samples |>\n  ggplot(aes(x = gamma)) +\n  geom_histogram() +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](19-bayes-state-space_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n_What is the interpretation of these range of values in the context of the state-space model?_\n\nWe can also create a display comparing the different variances:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariance_posterior_samples |>\n  dplyr::select(-gamma) |>\n  pivot_longer(cols = everything(),\n               names_to = \"variance\",\n               values_to = \"value\") |>\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(~variance, ncol = 1) +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](19-bayes-state-space_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n_With regards to the model, what is the implication of the differences between these posterior distributions for the different variance terms?_\n\nNow for the ugly part, making a tidy dataset with one posterior sample row for each eam in each season. We'll join over team abbreviations based on the colnames of the original design matrix. The code chunk below demonstrates one way to do this process via `pivot_longer()` and the use of `separate_wider_delim()` to split the `thetas` name based on the season and team indices:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nteam_ids <- tibble(team_id = as.character(1:ncol(team_matrix)),\n                   team_abbr = colnames(team_matrix))\n\nteam_posterior_samples <- raw_posterior_samples |>\n  # First PIVOT!!! the posterior samples for only the thetas \n  dplyr::select(contains(\"thetas\")) |>\n  pivot_longer(cols = everything(),\n               names_to = \"parameter_index\",\n               values_to = \"value\") |>\n  # Just grab the season and team index only \n  mutate(season_team_index = str_remove_all(parameter_index, \n                                            \"(thetas\\\\[)|(\\\\])\")) |>\n  # Use this convenient function to split column into two columns:\n  separate_wider_delim(season_team_index, delim = \",\",\n                       names = c(\"season\", \"team_id\")) |>\n  # Convert the season back:\n  mutate(season = as.numeric(season) - 1 + min(games_data$season)) |>\n  # finally join the team abbreviations\n  left_join(team_ids, by = \"team_id\") |>\n  dplyr::select(-c(parameter_index, team_id))\n\nteam_posterior_samples\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,240,000 × 3\n     value season team_abbr\n     <dbl>  <dbl> <chr>    \n 1  3.69     2018 PHI      \n 2 -1.32     2019 PHI      \n 3 -4.31     2020 PHI      \n 4  2.05     2021 PHI      \n 5  5.58     2022 PHI      \n 6  0.0247   2023 PHI      \n 7 11.5      2024 PHI      \n 8  8.82     2018 BAL      \n 9  6.13     2019 BAL      \n10  4.45     2020 BAL      \n# ℹ 2,239,990 more rows\n```\n:::\n:::\n\n\nWith this table on hand, we can do a variety of different tasks - such as creating our usual type of posterior distribution summaries:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nteam_summary <- team_posterior_samples |>\n  group_by(season, team_abbr) |>\n  summarize(posterior_mean = mean(value), \n            posterior_median = median(value),\n            # 50% credible interval:\n            lower_50 = quantile(value, 0.25),\n            upper_50 = quantile(value, 0.75),\n            .groups = \"drop\")\nteam_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 224 × 6\n   season team_abbr posterior_mean posterior_median lower_50 upper_50\n    <dbl> <chr>              <dbl>            <dbl>    <dbl>    <dbl>\n 1   2018 ARI               -7.68            -7.64    -9.50    -5.83 \n 2   2018 ATL               -0.497           -0.485   -2.29     1.27 \n 3   2018 BAL                5.97             5.96     4.22     7.70 \n 4   2018 BUF               -3.46            -3.43    -5.27    -1.65 \n 5   2018 CAR               -1.01            -0.992   -2.77     0.774\n 6   2018 CHI                4.41             4.38     2.65     6.14 \n 7   2018 CIN               -4.08            -4.05    -5.86    -2.28 \n 8   2018 CLE               -1.24            -1.21    -3.03     0.554\n 9   2018 DAL                1.10             1.09    -0.560    2.76 \n10   2018 DEN               -0.965           -0.985   -2.74     0.823\n# ℹ 214 more rows\n```\n:::\n:::\n\n\nThe code chunk below demonstrates how you could make a graphic that includes the 50% credible intervals for each team's season rating, broken up by division with the appropriate team color displayed (note for other sports you could use the [`teamcolors` package](https://github.com/beanumber/teamcolors)):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nflreadr)\nnfl_team_colors <- load_teams() |>\n  dplyr::select(team_abbr, team_division, team_color)\n\n# Join the colors:\nteam_summary <- team_summary |>\n  inner_join(nfl_team_colors, by = \"team_abbr\")\n\n# Get the vector of colors:\nteam_color_vector <- team_summary |>\n  dplyr::select(team_abbr, team_color) |>\n  distinct() |>\n  arrange(team_abbr) |>\n  pull(team_color)\n\n# Create ribbon plots with all in gray to start:\nteam_summary |>\n  ggplot(aes(x = season)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +\n  geom_line(aes(y = posterior_median, group = team_abbr,\n                color = team_abbr)) +\n  geom_ribbon(aes(ymin = lower_50, ymax = upper_50, group = team_abbr,\n                  color = team_abbr, fill = team_abbr), alpha = 0.25) +\n  facet_wrap(~ team_division, ncol = 4) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +\n  scale_color_manual(values = team_color_vector, guide = \"none\") +\n  scale_fill_manual(values = team_color_vector, guide = \"none\") +\n  labs(x = \"Season\",\n       y = \"Posterior team rating, following Glickman & Stern (1998, 2017)\",\n       title = \"Is this the end for the era of KC dominance?\",\n       subtitle = \"Posterior median team ratings, with ribbons for 50% credible intervals\") +\n  theme_bw() +\n  theme(strip.background = element_blank(),\n        axis.text.x = element_text(size = 8),\n        plot.title = element_text(size = 20),\n        plot.subtitle = element_text(size = 16))\n```\n\n::: {.cell-output-display}\n![](19-bayes-state-space_files/figure-html/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\nAs an exercise for yourself, pick two teams and generate a distribution of potential score differentials based on their posterior distribution following the 2024 season. Remember, you'll also want to sample the game-level variance `sigma_games` when generating the predicted value using the `rnorm` function. For example, the following code displays a distribution for the posterior predicted score differential between KC and PHI (with respect to KC):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2024)\n# Create a table that has the posterior samples we want to use for prediction:\nexample_predictions <- \n  tibble(kc_rating = pull(filter(team_posterior_samples,\n                                 team_abbr == \"KC\", season == 2024), value),\n         phi_rating = pull(filter(team_posterior_samples, \n                                 team_abbr == \"PHI\", season == 2024), value),\n         game_sd = variance_posterior_samples$sigma_games) |>\n  # Generate the predictions:\n  mutate(score_diff = rnorm(n(), mean = kc_rating - phi_rating, sd = game_sd))\n\n# Display the distribution:\nexample_predictions |>\n  ggplot(aes(x = score_diff)) +\n  geom_histogram() +\n  geom_vline(xintercept = 0, color = \"white\", linetype = \"dashed\") +\n  # With the actual score diff:\n  geom_vline(xintercept = -18, color = \"red\") +\n  labs(x = \"KC points - PHI points\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](19-bayes-state-space_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\nWith a distribution like this available, you can also estimate probabilities of each team winning as well - but I'll leave that as an exercise for you to complete...\n\n\n\n\n",
    "supporting": [
      "19-bayes-state-space_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}