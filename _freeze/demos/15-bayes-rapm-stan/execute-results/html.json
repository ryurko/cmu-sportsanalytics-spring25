{
  "hash": "0ad2fbe537f45ae3819de01f4e55ab97",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 16: Bayesian RAPM in Stan\"\nformat: html\n---\n\n\n\n\n## Introduction\n\nThe purpose of this demo is demonstrate how to fit and examine the posterior distributions for a __Bayesian regularized adjusted plus-minus (RAPM) model__, in order to estimate the impact of basketball players when they are on the court, while adjusting for the quality of their teammates and opponents. We will use the same dataset from the `intro_rapm.qmd` demo. As a reminder, you can find the script (`init_nba_rapm_data.R`) for initializing this dataset on Canvas using the [`hoopR` package](https://hoopr.sportsdataverse.org/).\n\nThe following code chunk reads in the wide data (assuming it is in the correct directory):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# Load the data\nnba_rapm_data <- read_csv(here::here(\"data/nba_2324_season_rapm_data.csv.gz\"))\nnba_rapm_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 31,885 × 579\n   game_id    stint_id n_pos home_points away_points minutes  margin `203484`\n   <chr>         <dbl> <dbl>       <dbl>       <dbl>   <dbl>   <dbl>    <dbl>\n 1 0022300061        1    27          20          16   5.88    14.8         1\n 2 0022300061        2    14           9           2   3.29    50           1\n 3 0022300061        3     8           2           2   2.16     0           0\n 4 0022300061        4    11          11           4   3.2     63.6         0\n 5 0022300061        6     2           0           2   0.400 -100           1\n 6 0022300061        7     7           3           6   1.55   -42.9         1\n 7 0022300061        8     2           2           0   0.25   100           1\n 8 0022300061        9    12           7           8   2.43    -8.33        1\n 9 0022300061       10     9           6           6   1.76     0           1\n10 0022300061       11    34          15          19   7.39   -11.8         1\n# ℹ 31,875 more rows\n# ℹ 571 more variables: `203932` <dbl>, `203999` <dbl>, `1627750` <dbl>,\n#   `1629008` <dbl>, `202704` <dbl>, `1630192` <dbl>, `1631128` <dbl>,\n#   `1631212` <dbl>, `1629618` <dbl>, `1630296` <dbl>, `1631221` <dbl>,\n#   `101108` <dbl>, `201939` <dbl>, `202691` <dbl>, `203952` <dbl>,\n#   `1626172` <dbl>, `1630228` <dbl>, `203967` <dbl>, `1627780` <dbl>,\n#   `1630541` <dbl>, `202709` <dbl>, `1628380` <dbl>, `1629640` <dbl>, …\n```\n\n\n:::\n:::\n\n\n\n\nIn this dataset, we have 31,885 unique shifts/stints with 572 players represented by the indicator variables (+1 if on court for home team, -1 if on court for away team, and 0 if not on court). Additional context is captured by the following variables:\n\n| Variable | Description |\n|----|-------------|\n| `game_id` |\tUnique game ID |\n| `stint_id` |\tUnique identifier within a game for a stint for particular combination of home and away lineup (in appearance of order, where 1 is the first stint in the game) |\n| `n_pos` |\tNumber of possessions (combined for both home and away) during the observed stint |\n| `home_points` |\tNumber of points scored by the home team during the stint |\n| `away_points` |\tNumber of points scored by the away team during the stint |\n| `minutes` |\tLength of the stint in terms of minutes played |\n| `margin` | Common response for RAPM models defined as: (`home_points` - `away_points`) / `n_pos` * 100 |\n\n\n## Model set-up\n\nWe're now going to proceed to set-up the Bayesian RAPM model. First, we'll initialize our dataset in the manner appropriate for handling in Stan. This is similar to the `intro_rapm.qmd` demo since it is just based on creating a matrix for the players with a numeric vector for the response variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Now for ease, create a dataset that only has the response and player columns:\nnba_margin_apm_model_data <- nba_rapm_data |>\n  dplyr::select(-c(game_id, stint_id, n_pos, home_points, away_points, minutes))\n\n# Next set-up the design matrix of player indicators\nplayer_matrix <- nba_margin_apm_model_data |>\n  dplyr::select(-margin) |>\n  as.matrix()\n\n# And vector for the response\nmargin_response <- nba_margin_apm_model_data$margin\n```\n:::\n\n\n\n\nNow with the data constructed, we can use Stan to simulate from the posterior distribution for the considered model parameters. \n\nThe following chunk below displays the Stan code that is also available in `bayes_ridge_rapm.stan`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_ridge_model <- \"\ndata{\n  // Set-up the context in terms of dataset size\n  int<lower = 0> N_shifts; \n  int<lower = 1> N_players;\n  vector[N_shifts] y;\n  matrix[N_shifts, N_players] X_players; \n}\n\n// Now define the parameters we'll consider, with the player betas and two\n// variance components:\nparameters{\n  // Shift-level variance\n  real<lower=0> sigma_shifts;\n  // Player-level variance\n  real<lower=0> sigma_players; \n  // Vector of coefficients for players\n  vector[N_players] beta; \n}\n\n// And now write out the model\nmodel{\n  \n  // Observation-level\n  y ~ normal(X_players * beta, sigma_shifts);\n  \n  // Player level effects\n  beta ~ normal(0, sigma_players);\n  \n  // Priors for the variances:\n  sigma_shifts ~ cauchy(0, 5);\n  sigma_players ~ cauchy(0, 5);\n\n}\n\"\n```\n:::\n\n\n\n\nCompared to the `intro_stan.qmd` code, there are more components here for the input. We need to tell Stan how many observations we've observed (`N_shifts`) and the number of player coefficients (`N_players`), as well as the actual data input: the response vector (`y`) and the design matrix with the player indicators (`X_players`). \n\nThe following code chunk sets up the data list and then uses `rstan` to start sampling. __NOTE: this code takes about 30 minutes to run on my laptop, so do NOT try and knit this file with the code chunk evaluated!__ \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Construct the data list\nbayes_ridge_rapm_data <- list(N_shifts = nrow(player_matrix),\n                              N_players = ncol(player_matrix),\n                              y = margin_response,\n                              X_players = player_matrix)\n\n# Use rstan to start sampling - where we'll use 4 chain with 5000 iterations,\n# where 2500 are burn-in, and speed things up with the 4 chains in parallel:\nlibrary(rstan)\nbayes_ridge_rapm_fit <- stan(model_code = stan_ridge_model, \n                             data = bayes_ridge_rapm_data, \n                             chains = 4, iter = 2500 * 2, \n                             cores = 4,\n                             seed = 2024)\n# Or you could use the following if the bayes_ridge_rapm.stan file is in the\n# current directory:\n# bayes_ridge_rapm_fit <- stan(file = \"bayes_ridge_rapm.stan\", \n#                              data = bayes_ridge_rapm_data, \n#                              chains = 4, iter = 2500 * 2, \n#                              cores = 4,\n#                              seed = 2024)\n```\n:::\n\n\n\n\nSince this code takes a decent amount of time to run, the following code chunk reads in the saved `.rds` object from the Stan model fit (that was created in the `fit_bayes_ridge_rapm.R` script on Canvas):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayes_ridge_rapm_fit <- \n  read_rds(here::here(\"data/bayes_ridge_rapm_fit.rds\"))\n```\n:::\n\n\n\n\nSimilar to the `intro_stan.qmd` demo, we should check MCMC diagnostics for our posterior samples. We can again view the trace plots for parameters - BUT we have to deal with the fact that we have hundreds of parameters! The following displays the trace plots for just two of the players, with their parameters designated by just the index in the Stan `beta` vector:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bayesplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis is bayesplot version 1.11.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- Online documentation and vignettes at mc-stan.org/bayesplot\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- bayesplot theme set to bayesplot::theme_default()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n   * Does _not_ affect other ggplot2 plots\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n   * See ?bayesplot_theme_set for details on theme setting\n```\n\n\n:::\n\n```{.r .cell-code}\nmcmc_trace(bayes_ridge_rapm_fit, pars = c(\"beta[15]\", \"beta[25]\"), \n           facet_args = list(ncol = 1, strip.position = \"left\"))\n```\n\n::: {.cell-output-display}\n![](15-bayes-rapm-stan_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\nFor a quick glance, we can also compute the various diagnostics that we discussed in the `intro_stan.qmd` demo. For instance, we can compute the `rhat` values for each of the parameters to assess the stability. I decided to be lazy and just used the `hist()` function to create a base `R` histogram displaying that none of the `rhat` values concerning (i.e., noticeably greater than 1). \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrapm_rhats <- rhat(bayes_ridge_rapm_fit)\nhist(rapm_rhats)\n```\n\n::: {.cell-output-display}\n![](15-bayes-rapm-stan_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\nSimilarly, we can also compute the `neff_ratio` for all of the parameters:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrapm_neff_ratio <- neff_ratio(bayes_ridge_rapm_fit)\nhist(rapm_neff_ratio)\n```\n\n::: {.cell-output-display}\n![](15-bayes-rapm-stan_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nThe strange behavior of this distribution is discussed in lecture...\n\n## Posterior analysis\n\nWe're now ready to examine the posterior distributions for the parameters. First, we'll create a simple, tidy table that has one column for each parameter (excluding Stan's reported log posterior density). The following code chunk sets up this table with 10,000 rows (one for each sample) and 574 columns (one for each parameter):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_sample <- as.data.frame(bayes_ridge_rapm_fit, pars = \"lp__\", include = FALSE) |>\n  as_tibble()\n\nposterior_sample\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10,000 × 574\n   sigma_shifts sigma_players `beta[1]` `beta[2]` `beta[3]` `beta[4]` `beta[5]`\n          <dbl>         <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n 1         69.7          2.10    0.773     0.731       2.88     2.09      0.708\n 2         69.7          2.08    0.258    -1.65        5.31     1.95      0.663\n 3         70.0          2.09    4.35     -1.13        1.94    -1.92      1.39 \n 4         69.7          2.15   -0.626     0.0126      6.30     3.16     -1.17 \n 5         70.0          2.17    4.60     -0.886       2.24    -1.73      1.15 \n 6         69.8          2.32    2.72     -0.538       6.43     0.561     2.68 \n 7         69.8          2.27    2.40     -0.874       6.31     0.950    -2.05 \n 8         70.0          2.18   -0.0970    0.113       6.13     0.601     2.57 \n 9         70.1          2.19    2.65     -1.52        6.70     2.17      1.22 \n10         70.2          2.28    2.79     -1.22        6.14     1.34      0.488\n# ℹ 9,990 more rows\n# ℹ 567 more variables: `beta[6]` <dbl>, `beta[7]` <dbl>, `beta[8]` <dbl>,\n#   `beta[9]` <dbl>, `beta[10]` <dbl>, `beta[11]` <dbl>, `beta[12]` <dbl>,\n#   `beta[13]` <dbl>, `beta[14]` <dbl>, `beta[15]` <dbl>, `beta[16]` <dbl>,\n#   `beta[17]` <dbl>, `beta[18]` <dbl>, `beta[19]` <dbl>, `beta[20]` <dbl>,\n#   `beta[21]` <dbl>, `beta[22]` <dbl>, `beta[23]` <dbl>, `beta[24]` <dbl>,\n#   `beta[25]` <dbl>, `beta[26]` <dbl>, `beta[27]` <dbl>, `beta[28]` <dbl>, …\n```\n\n\n:::\n:::\n\n\n\n\nWe can start by visualizing the posterior distributions of the variance terms, such as the shift/stint level variance:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_sample |>\n  ggplot(aes(x = sigma_shifts)) +\n  geom_histogram() +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](15-bayes-rapm-stan_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\nAs well as the between player variance:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_sample |>\n  ggplot(aes(x = sigma_players)) +\n  geom_histogram() +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](15-bayes-rapm-stan_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\nAnd similarly, we can use these quantities to display the posterior distribution for the ICC! Which we only had access to before in terms of one number, but now we have a full posterior distribution:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_sample |>\n  mutate(icc = sigma_players / (sigma_players + sigma_shifts)) |>\n  ggplot(aes(x = icc)) +\n  geom_histogram() +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](15-bayes-rapm-stan_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\nNow, in order to compare the players - we need to replace the arbitrary index values with the original player IDs. The following code does this by first grabbing the columns for the players and then replacing the column names with the original design matrix column names:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First just grab the players\nplayer_posterior_samples <- posterior_sample |>\n  dplyr::select(-sigma_shifts, -sigma_players)\n\n# And now change the column names:\ncolnames(player_posterior_samples) <- colnames(player_matrix)\n```\n:::\n\n\n\n\nFor ease, we'll then convert this to a long table with one row per player-sample. And borrowing our code from the `intro_rapm.qmd` demo, we'll join the player names based on the IDs from the `nba_2324_player_table.csv` table:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First load the player table\nnba_player_table <- read_csv(here::here(\"data/nba_2324_player_table.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 572 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): player_name\ndbl (1): player_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Now create a long player posterior sample and join the player names:\nlong_player_posterior_samples <- player_posterior_samples |>\n  pivot_longer(cols = everything(),\n               names_to = \"player_id\",\n               values_to = \"beta\") |>\n  mutate(player_id = as.numeric(player_id)) |>\n  left_join(nba_player_table, by = c(\"player_id\"))\nlong_player_posterior_samples\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5,720,000 × 3\n   player_id    beta player_name             \n       <dbl>   <dbl> <chr>                   \n 1    203484  0.773  Kentavious Caldwell-Pope\n 2    203932  0.731  Aaron Gordon            \n 3    203999  2.88   Nikola Jokić            \n 4   1627750  2.09   Jamal Murray            \n 5   1629008  0.708  Michael Porter Jr.      \n 6    202704  2.83   Reggie Jackson          \n 7   1630192 -3.79   Zeke Nnaji              \n 8   1631128 -1.13   Christian Braun         \n 9   1631212 -0.0339 Peyton Watson           \n10   1629618  0.310  Jalen Pickett           \n# ℹ 5,719,990 more rows\n```\n\n\n:::\n:::\n\n\n\n\nWith this long table, we can once again compute various summaries such as the posterior mean and 80% credible intervals for each player:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplayer_summary <- long_player_posterior_samples |>\n  group_by(player_id, player_name) |>\n  summarize(posterior_mean = mean(beta), \n            posterior_median = median(beta),\n            # 80% credible interval:\n            lower_80 = quantile(beta, 0.1),\n            upper_80 = quantile(beta, 0.9),\n            .groups = \"drop\") |>\n  arrange(desc(posterior_mean))\nplayer_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 572 × 6\n   player_id player_name       posterior_mean posterior_median lower_80 upper_80\n       <dbl> <chr>                      <dbl>            <dbl>    <dbl>    <dbl>\n 1    203999 Nikola Jokić                4.88             4.81    2.58      7.28\n 2   1629029 Luka Dončić                 4.49             4.45    2.30      6.76\n 3   1628973 Jalen Brunson               4.28             4.25    2.02      6.55\n 4    203954 Joel Embiid                 3.72             3.68    1.32      6.18\n 5   1626164 Devin Booker                3.59             3.55    1.39      5.82\n 6   1626157 Karl-Anthony Tow…           3.50             3.49    1.25      5.80\n 7   1628374 Lauri Markkanen             3.38             3.35    1.02      5.75\n 8   1630198 Isaiah Joe                  3.05             3.03    0.823     5.29\n 9   1630581 Josh Giddey                 3.01             3.00    0.754     5.29\n10   1628401 Derrick White               2.93             2.92    0.635     5.29\n# ℹ 562 more rows\n```\n\n\n:::\n:::\n\n\n\n\nWe can see that the top 10 players match what we observed using ridge regression (with slightly more penalized values than what we say with frequentist ridge...) - but now we have full posterior distributions for each player. In the above table, you can see the 80% credible intervals that we can use for comparisons of player effects. Instead of just reporting intervals, we can also display full distributions using something like [`ggridges`](https://cran.r-project.org/web/packages/ggridges/vignettes/introduction.html). For instance, the code chunk below displays the posterior distributions for the top 10 and bottom 10 players based on the Bayesian RAPM model (sorted by posterior means):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Grab the players\ntop_10_players <- player_summary |>\n  slice_head(n = 10) |>\n  pull(player_name)\nbottom_10_players <- player_summary |>\n  slice_tail(n = 10) |>\n  pull(player_name)\n\n# And now display ridges for them:\nlibrary(ggridges)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggridges' was built under R version 4.2.3\n```\n\n\n:::\n\n```{.r .cell-code}\nlong_player_posterior_samples |>\n  filter(player_name %in% c(top_10_players, bottom_10_players)) |>\n  mutate(player_name = factor(player_name, levels = c(top_10_players,\n                                                      bottom_10_players))) |>\n  ggplot(aes(x = beta, y = player_name)) +\n  geom_density_ridges(rel_min_height = 0.05) +\n  theme_bw() +\n  labs(x = \"Bayesian RAPM posterior beta\",\n       y = \"Player\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nPicking joint bandwidth of 0.256\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](15-bayes-rapm-stan_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "15-bayes-rapm-stan_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}