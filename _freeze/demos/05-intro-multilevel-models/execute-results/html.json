{
  "hash": "dcca5fc1e95d4b4be275b6c721d0086d",
  "result": {
    "markdown": "---\ntitle: \"Lecture 6: Intro to multilevel modeling\"\nformat: html\n---\n\n\n## Introduction\n\nThe goal of this demo is to walk through the initial steps of __multilevel modeling__ in the context of modeling pass completion probability. We'll continue where we left off in the `cpoe.qmd` demo, using a dataset corresponding to pass attempts in NFL regular season games during the 2023 and 2024 seasons. You can find the dataset and code to create the data (`init_nfl_passing_data.R`) on Canvas. \n\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nnfl_passing_data <- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   <chr>             <dbl> <dbl> <chr>   <chr>   <chr>        <chr>             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id <chr>, complete_pass <dbl>,\n#   pass_location <chr>, air_yards <dbl>, qb_hit <dbl>, epa <dbl>,\n#   yardline_100 <dbl>, down <dbl>, ydstogo <dbl>, is_home <dbl>\n```\n:::\n:::\n\n\n## Modeling completion probability with logistic regression\n\nIn the previous demo, we fit a logistic regression model to estimate the probability of a complete pass (i.e., when `complete_pass == 1`) based on a few variables:\n\n1. `pass_location`: a categorical variable denoting which side of the field the ball was thrown to, either `left`, `middle`, or `right` (based on manually charted data). We're going to be lazy and treat `left` as the reference level, but one should think more carefully about which level is more appropriate.\n\n2. `air_yards`: a quantitative variable indicating how many yards the ball traveled in the air _perpendicular_ to the line of scrimmage. This does not measure the actual distance traveled by the ball (e.g., if the QB throws the ball across the field but only to the line of scrimmage then it has traveled 0 air yards), but still provides measure for the length of the pass.\n\n3. `qb_hit`: a binary indicator variable denoting whether or not the QB was hit on the play, serving as a proxy for plays where the QB observes pressure (i.e., a tougher situation to make a throw).\n\nThe following code chunk fits this logistic regression model on all of the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogit_completion <- glm(complete_pass ~ pass_location + air_yards + qb_hit,\n                        data = nfl_passing_data, family = \"binomial\")\n\nsummary(logit_completion)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = complete_pass ~ pass_location + air_yards + qb_hit, \n    family = \"binomial\", data = nfl_passing_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1567  -1.1713   0.7187   0.8481   2.3971  \n\nCoefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          1.221994   0.021886  55.834  < 2e-16 ***\npass_locationmiddle  0.164057   0.032141   5.104 3.32e-07 ***\npass_locationright  -0.090248   0.026235  -3.440 0.000582 ***\nair_yards           -0.058879   0.001203 -48.957  < 2e-16 ***\nqb_hit              -1.080257   0.038836 -27.816  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46543  on 35986  degrees of freedom\nResidual deviance: 42900  on 35982  degrees of freedom\nAIC: 42910\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n\n## Multiple levels in the data\n\nIn the previous logistic regression model, we naively ignored the structure of the data: there are repeated pass attempts by quarterbacks (QBs, `passer_name_id`), repeatedly to a set of receivers (`receiver_name_id`), against different defenses (`defteam`). For the sake of this intro demo, we will just focus on QBs and will return to handling receivers and defenses later. \n\nIgnoring receivers and defenses, there are two __levels__ in the dataset:\n\n1. __Level One__: individual pass attempts, which are the the simplest and most frequent unit of observation in the dataset. For each pass attempt we have information describing the pass such as the `pass_location`, `air_yards`, and if the QB was hit on the play `qb_hit`.\n\n2. __Level Two__: the QB attempting the pass, which is a __larger observational unit__. In other words, we observe the same QB across multiple pass attempts - which should make us think the outcome of such attempts are correlated with each other.\n \nWhen we think about performing preliminary exploratory data analysis (EDA), we should consider it at both levels of the data. This includes starting with a basic summary of the response at the pass level:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnfl_passing_data |>\n  ggplot(aes(x = as.factor(complete_pass))) +\n  geom_bar() +\n  scale_x_discrete(labels = c(\"Incomplete\", \"Complete\")) +\n  labs(x = \"Pass outcome\", y = \"Number of passes\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nAs well seeing how the outcome varies as a function of the different variables, such as the pass location:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnfl_passing_data |>\n  ggplot(aes(x = pass_location,\n             fill = as.factor(complete_pass))) +\n  geom_bar() +\n  ggthemes::scale_fill_colorblind(labels = c(\"Incomplete\", \"Complete\")) +\n  labs(x = \"Pass location\", y = \"Number of passes\",\n       fill = \"Pass outcome\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nAnd by making an empirical logit plot (similar to the `logit_expected_goals.qmd` demo) to view the relationship between the response with the air yards variable:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnfl_passing_data |>\n  mutate(air_yards_bin = cut_number(air_yards, 10)) |>\n  group_by(air_yards_bin) |>\n  summarize(cp = mean(complete_pass),\n            air_yards_midpoint = median(air_yards),\n            .groups = \"drop\") |>\n  mutate(cp = pmax(cp, 0.0001),\n         emp_logit = log(cp / (1 - cp))) |>\n  ggplot(aes(x = air_yards_midpoint, y = emp_logit)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x = \"Air yards (midpoint of bins)\",\n       y = \"Empirical logits\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nIn order to consider EDA for Level Two, we can start by making a summary dataset with one row for each QB in the data along with appropriate summaries of the different considered explanatory variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Start with the basic summary:\nqb_summary <- nfl_passing_data |>\n  group_by(passer_name_id) |>\n  summarize(n_passes = n(),\n            cp = mean(complete_pass),\n            fraction_hit = mean(qb_hit),\n            fraction_left = mean(pass_location == \"left\"),\n            fraction_middle = mean(pass_location == \"middle\"),\n            fraction_right = mean(pass_location == \"right\"),\n            ave_air_yards = mean(air_yards),\n            .groups = \"drop\")\n```\n:::\n\n\nAnd then we can repeat the EDA process at this level, such as viewing the distribution of completion percentages for each QB:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqb_summary |>\n  ggplot(aes(x = cp)) +\n  geom_histogram(breaks = seq(0, 1, by = 0.05), closed = \"left\") +\n  labs(x = \"Completion %\",\n       y = \"Number of QBs\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nAs well as relationships between completion percentages with the different variables, such as average air yards:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqb_summary |>\n  ggplot(aes(x = ave_air_yards, y = cp)) +\n  geom_point(aes(size = n_passes), alpha = 0.25) +\n  labs(x = \"Average air yards thrown each pass\",\n       y = \"Completion %\",\n       size = \"# passes\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nTo make this easier to see, here is the same plot but for passers with at least 100 attempts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqb_summary |>\n  filter(n_passes >= 100) |>\n  ggplot(aes(x = ave_air_yards, y = cp)) +\n  geom_point(aes(size = n_passes), alpha = 0.25) +\n  labs(x = \"Average air yards thrown each pass\",\n       y = \"Completion %\",\n       size = \"# passes\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nWe can also view the Level One EDA for each observation unit in Level Two. For instance, the code chunk below displays the empirical logit plots for the nine QBs with the most passing attempts: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_attempt_qbs <- qb_summary |>\n  arrange(desc(n_passes)) |>\n  slice(1:9) |>\n  pull(passer_name_id)\n\nnfl_passing_data |>\n  filter(passer_name_id %in% top_attempt_qbs) |>\n  mutate(air_yards_bin = cut_number(air_yards, 10)) |>\n  group_by(passer_name_id, air_yards_bin) |>\n  summarize(cp = mean(complete_pass),\n            air_yards_midpoint = median(air_yards),\n            .groups = \"drop\") |>\n  mutate(cp = pmax(cp, 0.0001),\n         emp_logit = log(cp / (1 - cp))) |>\n  ggplot(aes(x = air_yards_midpoint, y = emp_logit)) +\n  geom_point() +\n  # Add a smooth trend line\n  geom_smooth(se = FALSE) +\n  # Facet by QB:\n  facet_wrap(~passer_name_id, ncol = 3) +\n  labs(x = \"Air yards (midpoint of bins)\",\n       y = \"Empirical logits\") +\n  theme_bw() +\n  theme(strip.background = element_blank())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nFrom this we can see slight differences in the relationship with air yards across the small sample of QBs. Patrick Mahomes displays a relatively monotone relationships, while players such as Geno Smith and Josh Allen display a clear nonlinear relationship between the empirical logit and air yards.\n\n## Modeling strategies\n\nWhen handling data of this structure, we have a few different options for how to approach modeling the data. For ease, we'll only consider the `air_yards` variable as a coefficient in the following models below. But the same ideas can be applied to models with more features.\n\n### 1) Naive Level One Model\n\nOur starting point, is the model we already considered that completely ignores the QB-level of the data. The following code chunk fits this logistic regression model as a function of the `air_yards` plus an intercept:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninit_logit <- glm(complete_pass ~ air_yards,\n                  data = nfl_passing_data, family = \"binomial\")\n\nsummary(init_logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = complete_pass ~ air_yards, family = \"binomial\", \n    data = nfl_passing_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1115  -1.2496   0.7541   0.8767   2.1930  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.11219    0.01529   72.75   <2e-16 ***\nair_yards   -0.05900    0.00119  -49.57   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46543  on 35986  degrees of freedom\nResidual deviance: 43746  on 35985  degrees of freedom\nAIC: 43750\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nHowever, this completely ignores the correlated structure of the data and we ideally like to somehow account for the QB in the model.\n\n### 2) Two-Stage Modeling Approach\n\nAlternatively, __since we believe QBs are independent of each other__, we can fit separate logistic regression models for each QB in the dataset. For example, the code chunk below fits the same logistic regression model as above but only for pass attempts by Patrick Mahomes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmahomes_passes <- nfl_passing_data |>\n  filter(str_detect(passer_name_id, \"Mahomes\"))\n\nmahomes_logit <- glm(complete_pass ~ air_yards,\n                     data = mahomes_passes, family = \"binomial\")\n\nsummary(mahomes_logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = complete_pass ~ air_yards, family = \"binomial\", \n    data = mahomes_passes)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0991  -1.1114   0.6825   0.8297   2.3811  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.263493   0.084389   14.97   <2e-16 ***\nair_yards   -0.074776   0.007257  -10.30   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1479.8  on 1173  degrees of freedom\nResidual deviance: 1349.3  on 1172  degrees of freedom\nAIC: 1353.3\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nIf we compare the Mahomes' model to the naive model, we notice some slight differences in the intercept and coefficient estimates as well as larger standard errors (due to the smaller sized dataset).\n\nWe can repeat this for every single QB in the dataset, storing the intercept and coefficients in a table. For simplicity, we'll only do this with the `air_yards` variable since the categorical variables require observing the different levels at least once. You can ignore the warning messages that are popping up for players with only one observation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqb_coef_table <- \n  map_dfr(unique(nfl_passing_data$passer_name_id),\n          function(qb_i) {\n            \n            qb_i_data <- nfl_passing_data |>\n              filter(passer_name_id == qb_i)\n            \n            qb_i_model <- glm(complete_pass ~ air_yards,\n                              data = qb_i_data, family = \"binomial\")\n            \n            # Return the tidy coefficient table:\n            broom::tidy(qb_i_model) |>\n              mutate(qb = qb_i)\n          })\n# Ignore the warning messages that are displayed\n```\n:::\n\n\nWe can visualize what the distribution for the intercepts and coefficients looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqb_coef_table |>\n  ggplot(aes(x = estimate)) +\n  geom_histogram() +\n  facet_wrap(~term, ncol = 1, scales = \"free_x\") +\n  labs(x = \"Estimate value\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 40 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n:::\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nThere are so notable extreme values making this figure difficult to read. We can zoom in on the relevant portions with appropriate filters:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqb_coef_table |>\n  # First filter for the Intercept condition, based on reasonable cutoff\n  filter((term == \"(Intercept)\" & abs(estimate) <= 3) |\n           # And then for air_yards:\n           (term == \"air_yards\" & abs(estimate) <= .5)) |>\n  ggplot(aes(x = estimate)) +\n  geom_histogram() +\n  facet_wrap(~term, ncol = 1, scales = \"free_x\") +\n  labs(x = \"Estimate value\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](05-intro-multilevel-models_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nBased on this plot, we may decide to try modeling the intercepts and slopes at the QB level _via their own regression models_. In other words, we can treat the intercepts and slopes as the response variable, and fit a regression model (maybe as a function of QB level variables) to model the coefficients.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First filter to create separate datasets for each term:\nintercept_data <- qb_coef_table |>\n  filter(term == \"(Intercept)\")\nslope_data <- qb_coef_table |>\n  filter(term == \"air_yards\")\n\n# And now fit intercept-only models:\nintercept_lm <- lm(estimate ~ 1, data = intercept_data)\nslope_lm <- lm(estimate ~ 1, data = slope_data)\n```\n:::\n\n\nThe summary of these models provide us the averages and estimates for the variances of their respective distributions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(intercept_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = estimate ~ 1, data = intercept_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-190.02   -5.94   -5.61   -4.75  570.27 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)    6.734      4.495   1.498    0.136\n\nResidual standard error: 53.37 on 140 degrees of freedom\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(slope_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = estimate ~ 1, data = slope_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-45.606   0.480   0.497   0.506  16.270 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)  -0.5565     0.5413  -1.028    0.306\n\nResidual standard error: 5.44 on 100 degrees of freedom\n  (40 observations deleted due to missingness)\n```\n:::\n:::\n\n\nThere are clear limitations with this type of approach:\n\n1. __We are completely ignoring the number of observations (in this case pass attempts) for each QB__, treating QBs with only a small number of attempts the same as QBs with many attempts.\n\n2. __We drop players with insufficient number of observations for slopes__.\n\n3. __We are not sharing information across the QBs when modeling the relationship between air yards and completion probability__. Ideally, we want to leverage the information across the full dataset in order to provide better estimates for the relationships.\n\nThis leads us to the ideal approach for modeling such data...\n\n### 3) Unified Multilevel Model\n\nIn order to fit multilevel models in `R`, we need to use the [`lme4` package](https://cran.r-project.org/web/packages/lme4/index.html), which follows a unique syntax that we'll breakdown in the lectures ahead. First install the package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"lme4\")\n```\n:::\n\n\nThen we can fit a generalized linear multilevel model (GLMM) using the `glmer()` function in the package, which is analogous to the `glm()` function in `R`. Note that in Homework 2 you will use the `lmer()` function which is used for modeling continuous data under the assumption of Gaussian errors. In this problem, we are modeling completion probability so we are relying on a linear model for the log odds function. The following code chunk demonstrates how to fit a GLMM for completion probability with __random effects__ for QB intercepts and air yards slopes, along with a __fixed effect__ for air yards:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'lme4' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'Matrix' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'Matrix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n:::\n\n```{.r .cell-code}\nglmm_completion <- glmer(complete_pass ~ air_yards + (air_yards | passer_name_id),\n                         family = binomial, data = nfl_passing_data)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nboundary (singular) fit: see help('isSingular')\n```\n:::\n\n```{.r .cell-code}\nsummary(glmm_completion)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ air_yards + (air_yards | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43704.2  43746.6 -21847.1  43694.2    35982 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0276 -1.0727  0.5727  0.6774  4.8845 \n\nRandom effects:\n Groups         Name        Variance  Std.Dev. Corr\n passer_name_id (Intercept) 0.0000000 0.00000      \n                air_yards   0.0001159 0.01077   NaN\nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.114817   0.016567   67.29   <2e-16 ***\nair_yards   -0.062080   0.001886  -32.91   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.412\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n```\n:::\n:::\n\n\n_(You can ignore the warning messages for now...)_\n\nWe will break down the steps for building multilevel models in the lectures ahead, starting with simple varying intercepts models in the next lecture.\n\n",
    "supporting": [
      "05-intro-multilevel-models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}