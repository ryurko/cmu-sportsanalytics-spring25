{
  "hash": "04fced417bcb986464d34f23c04ff90d",
  "result": {
    "markdown": "---\ntitle: 'Lecture 2: Building an Expected Goals Model'\nsubtitle: 'An Introduction to Generalized Linear Models'\nformat: html\n---\n\n\n## Introduction\n\nThe goal of this demo is to introduce the basic steps of building an expected goals model with logistic regression in `R`. In this demo, we'll use a dataset of NHL shot attempts during the 2023-2024 NHL season (accessed via [`hockeyR`](https://hockeyr.netlify.app/)) to build an expected goals model for hockey. The code used to create this dataset is available on Canvas. The following code chunk reads in the data (**notice the use of the [`here`](https://here.r-lib.org/index.html) package for reading in the data**) and displays a subset of the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# This assumes the dataset is saved within the data folder of the directory this\n# file is loaded in, you can change this depending on where you save the data!\nmodel_nhl_shot_data <- read_csv(here::here(\"data/model_nhl_shot_data.csv\"))\nhead(model_nhl_shot_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 11\n    game_id period shooting_player shooting_team goalie_name goalie_team x_fixed\n      <dbl>  <dbl> <chr>           <chr>         <chr>       <chr>         <dbl>\n1    2.02e9      1 Bryan Rust      Pittsburgh P… Petr Mrazek Chicago Bl…     -51\n2    2.02e9      1 Kevin Korchins… Chicago Blac… Tristan Ja… Pittsburgh…     -55\n3    2.02e9      1 Noel Acciari    Pittsburgh P… Petr Mrazek Chicago Bl…      75\n4    2.02e9      1 Wyatt Kaiser    Chicago Blac… Tristan Ja… Pittsburgh…     -39\n5    2.02e9      1 Alex Vlasic     Chicago Blac… Tristan Ja… Pittsburgh…     -36\n6    2.02e9      1 Marcus Petters… Pittsburgh P… Petr Mrazek Chicago Bl…      32\n# ℹ 4 more variables: y_fixed <dbl>, shot_distance <dbl>, shot_angle <dbl>,\n#   is_goal <dbl>\n```\n:::\n:::\n\n\n_NOTE: For hockey fans, for simplicity we are only considering even-strength shot attempts with a goalie in net that were either goals or saved by the goalie (i.e., not considering shots blocked by non-goalie defenders or shots that missed wide of the net)._\n\nBefore diving into any modeling, we should always start with exploratory data analysis (EDA), and visualize the data! The following figure displays the scatterplot of the shot attempts using the provided x (`x_fixed`) and y (`y_fixed`) coordinates, colored by the shot outcome (`is_goal`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_nhl_shot_data |>\n  # Make a scatterplot of the shot attempts\n  ggplot(aes(x = x_fixed, y = y_fixed, color = as.factor(is_goal))) +\n  # Make sure to modify the alpha!\n  geom_point(alpha = .25) +\n  labs(x = \"x coordinate\", y = \"y coordinate\", \n       color = \"Shot outcome\") +\n  # Use the ggthemes package for colorblind friendly palette\n  ggthemes::scale_color_colorblind(labels = c(\"Save\", \"Goal\")) +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](01-logit-expected-goals_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\nFrom this figure, we can see a higher density of shots that were goals (indicated by orange color) closer to the two empty spaces along the endpoints of the horizontal line where `y = 0` corresponding to the locations of the nets. We also see that the goals tend to be more directly in front of these locations relative to the sides. The figure provides us with some evidence that both the shot distance and angle are likely useful in predicting the probability of a goal.\n\n## Simple logistic regression model of distance\n\nWe'll start with a simple logistic regression model to estimate the goal probability of a shot as just a function of the shot distance (in feet). More specifically, we model the log-odds of a goal with a linear model:\n\n$$\n\\log \\Big[ \\frac{Pr(S = 1 |\\ distance)}{Pr(S = 0 |\\ distance)} \\Big] = \\beta_0 + \\beta_1 \\cdot distance\n$$\n\nBefore we fit this model, we'll continue with some basic EDA by visualizing the relationship between the shot outcome (`is_goal`) and the distance (`shot_distance`). The following figure displays a stacked histogram of the shot distance by outcome, indicating that the majority of goals occur at much shorter distances. While the majority of shot attempts do not result in a goal, we can imagine that the probability of goal increases as the shot distance decreases. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_nhl_shot_data |>\n  ggplot(aes(x = shot_distance, fill = as.factor(is_goal))) +\n  geom_histogram() + \n  labs(x = \"Shot distance (in feet)\",\n       y = \"Count\", fill = \"Shot outcome\") +\n  ggthemes::scale_fill_colorblind(labels = c(\"Save\", \"Goal\")) +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](01-logit-expected-goals_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nNext, we're going to create an __empirical logit plot__ to assess the linearity assumption of the logistic regression model, i.e., to check if the log(odds) is a linear function of distance. To do this, we need to bin the continuous variable of distance and then compute the log(odds) (or equivalently log(goals / saves)) within each bin. The following code chunk uses the `cut_number()` function to divide the `shot_distance` variable into bins with approximately equal number of observations. _NOTE: Due to the potential for the observed proportion to be 0, in order to avoid log(0) we set a floor of 0.0001 using the `pmax()` function._\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshot_distance_summary <- model_nhl_shot_data |>\n  mutate(dist_bin = cut_number(shot_distance, 10)) |>\n  group_by(dist_bin) |>\n  summarize(goal_p = mean(is_goal),\n            n_shots = n(),\n            dist_midpoint = median(shot_distance),\n            .groups = \"drop\") |>\n  mutate(goal_p = pmax(goal_p, 0.0001),\n         emp_logit = log(goal_p / (1 - goal_p)))\nshot_distance_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 5\n   dist_bin     goal_p n_shots dist_midpoint emp_logit\n   <fct>         <dbl>   <int>         <dbl>     <dbl>\n 1 [1,9.1]     0.134      9822           7.2     -1.86\n 2 (9.1,13.9]  0.107      9848          11.2     -2.12\n 3 (13.9,20.4] 0.0931     9633          17.1     -2.28\n 4 (20.4,27.2] 0.0778     9898          24       -2.47\n 5 (27.2,33.2] 0.0599     9745          30.4     -2.75\n 6 (33.2,39.1] 0.0374     9789          36.2     -3.25\n 7 (39.1,45.9] 0.0232     9640          42.2     -3.74\n 8 (45.9,54.5] 0.0162     9800          50       -4.10\n 9 (54.5,62.6] 0.0156     9908          58.5     -4.14\n10 (62.6,189]  0.00450    9551          69.4     -5.40\n```\n:::\n:::\n\n\nNext, we can make a simple plot with the empirical logit values along the y-axis against the shot distance (via the midpoints of the bins) on the x-axis. We can use `geom_smooth()` to fit a flexible trend to help us determine if the relationship is linear or not.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshot_distance_summary |>\n  ggplot(aes(x = dist_midpoint, y = emp_logit)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x = \"Shot distance (midpoint of bins)\",\n       y = \"Empirical logits\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](01-logit-expected-goals_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\nThis figure looks reasonable in terms of indicating a linear relationship between the log(odds) of a goal and the shot distance. We see that the log(odds) decreases as the shot distance increases, i.e., the probability of a goal decreases as the shot distance increases.\n\nWith the assumption of a linear relationship checked off, we'll now fit the logistic regression model using the `glm()` function in `R`. This is the general use function for fitting any generalized linear model (GLM) in `R`, where you just need to specify the distribution with the `family` argument. Although in this case we are technically modeling a variable (`is_goal`) that follows the Bernoulli distribution, we set `family = \"binomial\"` to fit the logistic regression model (since it's a Binomial distribution with $n = 1$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninit_logit <- glm(is_goal ~ shot_distance, data = model_nhl_shot_data,\n                  family = \"binomial\")\n```\n:::\n\n\nWe can then view the summary of the model including coefficient estimates, deviance, etc. via the `summary()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(init_logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = is_goal ~ shot_distance, family = \"binomial\", data = model_nhl_shot_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.6258  -0.4144  -0.2786  -0.1774   4.1872  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -1.4826561  0.0246069  -60.25   <2e-16 ***\nshot_distance -0.0483940  0.0009567  -50.58   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 42736  on 97633  degrees of freedom\nResidual deviance: 39264  on 97632  degrees of freedom\nAIC: 39268\n\nNumber of Fisher Scoring iterations: 6\n```\n:::\n:::\n\n\n\nUsing this model, we can create a figure displaying the predicted probability of a goal as a function of shot distance. We view this figure below, with the observed goals and saves marked as points at one and zero respectively. As expected, the probability of a goal is highest for the shortest shots. And we can clearly see that the vast majority of goals are within seventy-five feet, while saved shots span the entire range. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_nhl_shot_data |>\n  mutate(xg = init_logit$fitted.values)  |>\n  ggplot(aes(x = shot_distance)) +\n  geom_jitter(aes(y = is_goal,\n                  color = as.factor(is_goal)), \n              width = 0, height = .01,\n             size = .5, alpha = 0.15) +\n  geom_line(aes(y = xg), color = \"blue\") +\n  ggthemes::scale_color_colorblind(guide = \"none\") +\n  labs(x = \"Shot distance (in feet)\",\n       y = \"Predicted probability of goal (aka expected goals)\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](01-logit-expected-goals_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n## Likelihood-based approaches for model evaluation and comparison\n\nWe begin to assess this fit using traditional approaches based on likelihood criterion. Using the __deviance__, there are two tests we can consider:\n\n1. __Goodness-of-Fit__ test: $H_0$: fitted model vs $H_A$: saturated model\n\n2. __Drop-in-Deviance__ test: $H_0$: reduced model vs $H_A$: larger model (where reduced model is __nested__ within larger model, e.g., reduced model contains subset of larger model predictors)\n\nWe'll start with the goodness-of-fit test, which is testing the null hypothesis that the current model under consideration is a __good fit__. If we have evidence to suggest the null hypothesis is rejected, then we may be observing a __lack-of-fit__. We can perform this test easily in `R` using the `pchisq()` function to compution the appropriate p-value based on the assumption that under the null hypothesis, the residual deviance $\\sim \\chi^2$ distribution with $n - p$ degrees of freedom:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pchisq(init_logit$deviance, init_logit$df.residual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n:::\n\n\nBased on this result, we have insufficient evidence to suggest a lack-of-fit. If the p-value was below an error rate threshold (e.g., 0.05) then we would reject the null, but we would not know what is driving the lack-of-fit. It may be that we're missing important covariates and interactions, suffering from outliers, or other concerns with the distribution fit. Just because we fail to reject the null hypothesis in this example does NOT mean our model is optimal! There are other ways we will be able to improve this model, and the use of the $\\chi^2$ distribution is just an approximation (not guaranteed to be correct...).\n\nWe can use drop-in-deviance test to compare the fitted model against the null model (intercept-only), using the same function. Under the null, the difference in the reduced model deviance and larger model deviance follows a $\\chi^2$ distribution with degrees of freedom equal to the difference in the degrees of freedom between the two models. In other words, the degrees of freedom for this test is simply the number of parameters in the larger model that are not in the reduced model. The following code chunk shows how to perform this test using the `pchisq` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pchisq(init_logit$null.deviance - init_logit$deviance, \n           init_logit$df.null - init_logit$df.residual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nBased on this p-value, we have evidence in favor of the model with the shot distance variable.\n\nAnother way we can perform this test is to initially fit an intercept-only model (the null model) and then use the `anova()` function with `test = \"Chisq\"` specified to achieve the same result:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_logit <- glm(is_goal ~ 1, data = model_nhl_shot_data, family = \"binomial\")\nanova(null_logit, init_logit, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel 1: is_goal ~ 1\nModel 2: is_goal ~ shot_distance\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1     97633      42736                          \n2     97632      39264  1   3471.9 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nWe can use this same test to compare the fit of a model with another variable, such as `shot_angle`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist_angle_logit <- glm(is_goal ~ shot_distance + shot_angle, \n                        data = model_nhl_shot_data, family = \"binomial\")\nanova(init_logit, dist_angle_logit, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel 1: is_goal ~ shot_distance\nModel 2: is_goal ~ shot_distance + shot_angle\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1     97632      39264                          \n2     97631      38620  1   644.38 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nBased on this test, we have sufficient evidence to suggest the larger model with both distance and angle is _a better fit_ than the model with only shot distance.\n\nThe drop-in-deviance test is only appropriate for evaluating models that are nested within another. It is not an approach we can take for general comparison when considering non-nested models (e.g., two models with distinct, non-overlapping features). However, we can use __information criteria__ measures when comparing non-nested models which consider the model's likelihood penalized by the number of parameters in some way (i.e., penalty for model complexity). The two common information criterions are:\n\n1. __Akaike Information Criterion (AIC)__ = $-2 \\times$ log(Lik) $+ 2p$, i.e., the more variables we use the higher the AIC\n\n2. __Bayesian Information Criterion (BIC)__ = $-2 \\times$ log(Lik) $+ p \\log(n)$, i.e., log of number of observations places greater penalty on each additional variable\n\nIn these forms, for both AIC and BIC, __lower values are better__.\n\nBy default, the AIC is reported in the `summary()` output for GLMs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(dist_angle_logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = is_goal ~ shot_distance + shot_angle, family = \"binomial\", \n    data = model_nhl_shot_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.8111  -0.3907  -0.2648  -0.1798   4.1795  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -0.8914673  0.0326450  -27.31   <2e-16 ***\nshot_distance -0.0513284  0.0009580  -53.58   <2e-16 ***\nshot_angle    -0.0146870  0.0006025  -24.38   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 42736  on 97633  degrees of freedom\nResidual deviance: 38620  on 97631  degrees of freedom\nAIC: 38626\n\nNumber of Fisher Scoring iterations: 6\n```\n:::\n:::\n\n\nYou can also use the `AIC()` and `BIC()` functions to return the respective values for a given model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(dist_angle_logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38625.64\n```\n:::\n:::\n\n\nThe above output matches the previous summary display. And below we can see how the model with both features has a better BIC than the model with only distance:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBIC(init_logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 39287\n```\n:::\n\n```{.r .cell-code}\nBIC(dist_angle_logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38654.11\n```\n:::\n:::\n\n\n## Recap\n\n+ Covered basics of fitting logistic regression in `R` using `glm()`\n\n+ Evaluated and compared models using likelihood-based approaches\n",
    "supporting": [
      "01-logit-expected-goals_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}