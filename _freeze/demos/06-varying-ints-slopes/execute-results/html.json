{
  "hash": "fdead51b21eaba33e87b45f1460f0732",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 7: Varying intercepts and slopes\"\nformat: html\n---\n\n\n\n\n## Introduction\n\nThe purpose of this demo is to walk through fitting and interpreting the output of __varying intercepts and slopes__ multilevel models in the context of modeling pass completion probability. We'll continue to use a dataset corresponding to pass attempts in NFL regular season games during the 2023 and 2024 seasons from last week. You can find the dataset and code to create the data (`init_nfl_passing_data.R`) on Canvas in the demos/week3 folder. \n\nThe following code chunk reads in the relevant dataset (assuming it is in the correct directory) of passing plays:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nnfl_passing_data <- read_csv(here::here(\"data/nfl_passing_data.csv\"))\nnfl_passing_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 35,987 × 17\n   game_id         play_id drive posteam defteam posteam_type passer_name_id    \n   <chr>             <dbl> <dbl> <chr>   <chr>   <chr>        <chr>             \n 1 2023_01_ARI_WAS      77     1 WAS     ARI     home         S.Howell_00-00370…\n 2 2023_01_ARI_WAS     124     1 WAS     ARI     home         S.Howell_00-00370…\n 3 2023_01_ARI_WAS     147     1 WAS     ARI     home         S.Howell_00-00370…\n 4 2023_01_ARI_WAS     172     1 WAS     ARI     home         S.Howell_00-00370…\n 5 2023_01_ARI_WAS     197     1 WAS     ARI     home         S.Howell_00-00370…\n 6 2023_01_ARI_WAS     220     1 WAS     ARI     home         S.Howell_00-00370…\n 7 2023_01_ARI_WAS     332     2 ARI     WAS     away         J.Dobbs_00-0033949\n 8 2023_01_ARI_WAS     357     2 ARI     WAS     away         J.Dobbs_00-0033949\n 9 2023_01_ARI_WAS     380     2 ARI     WAS     away         J.Dobbs_00-0033949\n10 2023_01_ARI_WAS     526     3 WAS     ARI     home         S.Howell_00-00370…\n# ℹ 35,977 more rows\n# ℹ 10 more variables: receiver_name_id <chr>, complete_pass <dbl>,\n#   pass_location <chr>, air_yards <dbl>, qb_hit <dbl>, epa <dbl>,\n#   yardline_100 <dbl>, down <dbl>, ydstogo <dbl>, is_home <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n## Initial model: varying intercepts only\n\nThe first model we will consider is an __unconditional means__ or __random intercepts__ model, i.e., we do not include any predictor variables at either level of the data (pass attempts or QBs). \n\nIn order to fit this model, we will use the [`lme4` package](https://cran.r-project.org/web/packages/lme4/index.html). The code chunk below demonstrates how to fit a logistic regression model with __random intercepts__ for QBs using the `glmer()` function. Note that in the `lme4` model syntax, we specify __random effects__ via terms inside parentheses `()`. In this example, we specify that the model will have random intercepts (or varying intercepts) for QBs via `(1 | passer_name_id)` where you can think of the `1` denoting an intercept with the `| passer_name_id` indicating the intercept will vary by `passer_name_id`. We can display the `summary()` output for this generalized linear multilevel model (GLMM) in the usual manner:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\ninit_glmm <- glmer(complete_pass ~ (1 | passer_name_id),\n                   family = binomial, data = nfl_passing_data)\n\nsummary(init_glmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ (1 | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 46485.3  46502.3 -23240.7  46481.3    35985 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.5198 -1.3170  0.6966  0.7439  0.8887 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.02014  0.1419  \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.58502    0.02144   27.29   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nFor this model, we do not see the reported effects for the individual QBs (we will return to that later). Instead, we observe the reported variance for the QB distribution (under `Random effects` as `Variance`) as well as the usual intercept (under `Fixed effects`).\n\n## Intraclass correlation coefficient\n\nWhile the above displays the output for a _logistic regression_ model with random intercepts, for comparison we will explore the output for modeling a continuous response: expected points added (EPA). If we decide to assume that the Level One variance of EPA follows a Normal distribution, then we can model the data using the `lmer()` function instead of `glmer()` with the same syntax for the random intercepts. _Note: the code chunk below sets `REML = FALSE` to ensure we are using the maximum likelihood estimate, which is something we'll return to later._\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepa_lmm <- lmer(epa ~ (1 | passer_name_id), \n                data = nfl_passing_data, REML = FALSE)\n\nsummary(epa_lmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: epa ~ (1 | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n133282.7 133308.1 -66638.3 133276.7    35984 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-8.3024 -0.5206 -0.1421  0.5542  5.6369 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.01431  0.1196  \n Residual                   2.37037  1.5396  \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  0.09255    0.01689    5.48\n```\n\n\n:::\n:::\n\n\n\n\nUnlike the logistic regression model, we now have two variance estimates in the `Random effects` section: one for the QBs and another the `Residual` which corresponds to the *within-QB variability*. We can extract the relevant variances from this model using the `VarCorr()` function in `lme4`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The following is a way to print out both the Variance and Std Dev:\nprint(VarCorr(epa_lmm), comp = c(\"Variance\", \"Std.Dev.\"), digits = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.01431  0.1196  \n Residual                   2.37037  1.5396  \n```\n\n\n:::\n:::\n\n\n\n\nFrom this, we can also compute the __intraclass correlation coefficient (ICC)__ for the random intercepts. You could do this manually by just grabbing the variance values from the summary:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n0.01431 / (0.01431 + 2.37037)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.006000805\n```\n\n\n:::\n:::\n\n\n\n\nOr by converting the `VarCorr()` output to a tibble, which gives us the variances and then provides an easy way to compute the ICC values for each random effect (note the residual ICC row is NOT an ICC value):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVarCorr(epa_lmm) |> \n  as_tibble() |> \n  mutate(icc = vcov / sum(vcov)) |> \n  dplyr::select(grp, icc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  grp                icc\n  <chr>            <dbl>\n1 passer_name_id 0.00600\n2 Residual       0.994  \n```\n\n\n:::\n:::\n\n\n\n\nReturning back to model for compleition probability: in order to compute the ICC for the logistic regression model we need to manually compute the ICC based on the variance for errors that following a [Logistic distribution](https://en.wikipedia.org/wiki/Logistic_distribution) with a mean of 0 and variance of $\\pi^2 / 3$. This comes from a [__latent response model__](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3426610/) representation of the logistic regression model, which allows us to replace the residual variance from the `lmer()` model with $\\pi^2 / 3$ for the logistic regression model fit with `glmer()`.\n\nYou can compute the ICC value for the pass completion probability model manually, based on the summary output:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n0.02014 / (0.02014 + (pi^2 / 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.006084577\n```\n\n\n:::\n:::\n\n\n\n\nOr by grabbing the variance term from the model in a way that is similar to the code from before for the `lmer()` model that relies on using `VarCorr()`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVarCorr(init_glmm) |>\n  as_tibble() |>\n  # Note the use of sum(vcov) to work later with multiple levels\n  mutate(icc = vcov / (sum(vcov) + (pi^2 / 3))) |>\n  dplyr::select(grp, icc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  grp                icc\n  <chr>            <dbl>\n1 passer_name_id 0.00608\n```\n\n\n:::\n:::\n\n\n\n\n## Next step: including covariates and varying slopes\n\nThe next model to consider is one that accounts for Level One covariates. For instance, we can account for the air yards of the pass attempt in our model as a __fixed effect__:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nair_glmm <- glmer(complete_pass ~ air_yards + (1 | passer_name_id),\n                  family = binomial, data = nfl_passing_data)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(air_glmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ air_yards + (1 | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43702.9  43728.3 -21848.4  43696.9    35984 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7393 -1.0676  0.5669  0.6809  3.6699 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n passer_name_id (Intercept) 0.02087  0.1445  \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.070637   0.024260   44.13   <2e-16 ***\nair_yards   -0.059134   0.001196  -49.46   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.406\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\n```\n\n\n:::\n:::\n\n\n\n\nCompared to before, we now observe the `Fixed effects` estimates for the `air_yards` variable, as well as a slight change in the variance estimate for the QB random intercepts. For comparison purposes, the following code chunk displays the model summary output for the `glm()` without random intercepts:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nair_glm <- glm(complete_pass ~ air_yards,\n               family = binomial, data = nfl_passing_data)\n\nsummary(air_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = complete_pass ~ air_yards, family = binomial, data = nfl_passing_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1115  -1.2496   0.7541   0.8767   2.1930  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.11219    0.01529   72.75   <2e-16 ***\nair_yards   -0.05900    0.00119  -49.57   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46543  on 35986  degrees of freedom\nResidual deviance: 43746  on 35985  degrees of freedom\nAIC: 43750\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\nRelative to the output from the `glmer()` model, we can see that the fixed effect coefficient estimates change slightly with larger standard errors in the `glmer()` model.\n\nInstead of modeling completion probability with varying intercepts, we can instead use __varying slopes__ (aka __random slopes__) which allows the coefficient for a variable of interest to vary with each QB. This is similar to thinking about the interaction between categorical variables and quantitative variables, except with the assumption that the effect for the levels of a categorical variable follow some distribution. \n\nIn terms of the `lme4` syntax, in order to specify __random slopes__ WITHOUT including random intercepts, you need to use `(0 + air_yards | passer_name_id)` in the formula - which you can think of saying: vary the slopes for `air_yards` by `passer_name_id` but do not touch the intercept term (hence the 0 instead of 1). \n\nThe following code chunk fits and reports the summary for the random slopes model:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nair_slopes_glmm <- glmer(complete_pass ~ 1 + air_yards + (0 + air_yards | passer_name_id),\n                         family = binomial, data = nfl_passing_data)\n\nsummary(air_slopes_glmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ 1 + air_yards + (0 + air_yards | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43700.2  43725.6 -21847.1  43694.2    35984 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0276 -1.0727  0.5727  0.6774  4.8845 \n\nRandom effects:\n Groups         Name      Variance  Std.Dev.\n passer_name_id air_yards 0.0001159 0.01077 \nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.114822   0.015335   72.70   <2e-16 ***\nair_yards   -0.062080   0.001885  -32.94   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.429\n```\n\n\n:::\n:::\n\n\n\n\nUnlike the random intercepts model from before, we can no longer report the ICC value with random slopes. However, we can still view the random slopes variance, as well as make comparisons across model fits using the AIC or BIC that are reported near the top of the summary. Relative to the other models, this random slopes model appear to display the best AIC and BIC values (lower is better).\n\n## Both: Varying intercepts and varying slopes\n\nNow that we built up fitting of varying intercepts and varying slopes, we can return to the model in our previous demo which consists of both. In terms of the `lme4` syntax, we can specify a model with both varying intercepts and slopes with `(air_yards | passer_name_id)`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nair_both_glmm <- glmer(complete_pass ~ air_yards + (air_yards | passer_name_id),\n                       family = binomial, data = nfl_passing_data)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nboundary (singular) fit: see help('isSingular')\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(air_both_glmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: complete_pass ~ air_yards + (air_yards | passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43704.2  43746.6 -21847.1  43694.2    35982 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0276 -1.0727  0.5727  0.6774  4.8845 \n\nRandom effects:\n Groups         Name        Variance  Std.Dev. Corr\n passer_name_id (Intercept) 0.0000000 0.00000      \n                air_yards   0.0001159 0.01077   NaN\nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.114817   0.016567   67.29   <2e-16 ***\nair_yards   -0.062080   0.001886  -32.91   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.412\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n```\n\n\n:::\n:::\n\n\n\n\nCompared to the previous model, we see that bot the AIC and BIC are worse (i.e., higher values). There are supposed to be two variances reported for both the random intercepts and slopes under the `Random effects` section, along with the estimate for the correlation between the random effects under `Corr`. However, the variance for the random intercepts is reported to be 0 and the resulting correlation between the intercepts and slopes is missing!\n\n**We could make the assumption that the correlation between the random effects is zero** and explicitly force that in our model (meaning we would not have to estimate one parameter from the last model). In terms of the code syntax, this requires inputting the random effects separately for the intercepts `(1 | passer_name_id)` and slopes `(0 + air_yards | passer_name_id)`. The code chunk below fits this model with uncorrelated random intercept and slopes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nair_both_indep_glmm <- \n  glmer(complete_pass ~ 1 + (1 | passer_name_id) + air_yards + (0 + air_yards | passer_name_id),\n        family = binomial, data = nfl_passing_data)\n\nsummary(air_both_indep_glmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: \ncomplete_pass ~ 1 + (1 | passer_name_id) + air_yards + (0 + air_yards |  \n    passer_name_id)\n   Data: nfl_passing_data\n\n     AIC      BIC   logLik deviance df.resid \n 43685.0  43719.0 -21838.5  43677.0    35983 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7454 -1.0687  0.5667  0.6798  4.3269 \n\nRandom effects:\n Groups           Name        Variance  Std.Dev.\n passer_name_id   (Intercept) 1.452e-02 0.120510\n passer_name_id.1 air_yards   7.944e-05 0.008913\nNumber of obs: 35987, groups:  passer_name_id, 141\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.083996   0.022897   47.34   <2e-16 ***\nair_yards   -0.060852   0.001741  -34.95   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nair_yards -0.384\n```\n\n\n:::\n:::\n\n\n\n\nFrom the output, this results in a noticeably different model! The variance for the random intercepts is no longer estimated to be 0 and is now even estimated to be larger than the variance for the random slopes. Notice that the correlation between the random effects is no longer reported, since it is assumed to be 0. We can also see that this model has the best AIC and BIC values among the considered models in this demo. This result should be an indication to you that we often need to be careful with the default implementation of software since they often come with model assumptions that may or may not be ideal.\n\n\n## Recap:\n\n+ You have seen how to fit multilevel models with varying intercepts and varying slopes, either separately or at the same time. You just need to pay attention to the syntax regarding the random effects in parentheses.\n\n+ The [`sjstats`](https://cran.r-hub.io/web/packages/sjstats/vignettes/mixedmodels-statistics.html) package is a resource with a variety of other built-in evaluation metrics for `lme4` models.  \n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}